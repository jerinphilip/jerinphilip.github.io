<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Jerin Philip's blog</title>
    <link href="http://jerinphilip.github.io/atom.xml" rel="self" />
    <link href="http://jerinphilip.github.io" />
    <id>http://jerinphilip.github.io/atom.xml</id>
    <author>
        <name>Jerin Philip</name>
        <email>jerinphilip@live.in</email>
    </author>
    <updated>2023-09-19T00:00:00Z</updated>
    <entry>
    <title>PostmarketOS: Hello world!</title>
    <link href="http://jerinphilip.github.io/posts/postmarketos-hello-world.html" />
    <id>http://jerinphilip.github.io/posts/postmarketos-hello-world.html</id>
    <published>2023-09-19T00:00:00Z</published>
    <updated>2023-09-19T00:00:00Z</updated>
    <summary type="html"><![CDATA[<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta property="og:title" content="PostmarketOS: Hello world!" />
        <meta property="og:url" content="http://jerinphilip.github.io/posts/postmarketos-hello-world.html" />
        <title>PostmarketOS: Hello world!</title>
        <link rel="shortcut icon" href="../static/images/favicon.ico" type="image/x-icon">
        <link rel="stylesheet" href="../static/css/hack.css" />
        <link rel="stylesheet" href="../static/css/open-sans.css">
        <link rel="stylesheet" href="../static/css/font-awesome.min.css">
        <link rel="stylesheet" href="../static/css/tether.min.css" />
        <link rel="stylesheet" href="../static/css/bootstrap.min.css" />
        <link rel="stylesheet" href="../static/css/custom.css" />
        <link rel="stylesheet" href="../static/css/kate.css" />
        <link rel="stylesheet" href="../static/css/ekko-lightbox.css" />
        <script type="text/javascript" src="../static/js/jquery.min.js"></script>
        <script type="text/javascript" src="../static/js/tether.min.js"></script>
        <script type="text/javascript" src="../static/js/anchor.min.js"></script>
        <script type="text/javascript" src="../static/js/ekko-lightbox.min.js"></script>
        <script type="text/javascript" src="../static/js/bootstrap.min.js"></script>
        <script type="text/x-mathjax-config" src="../static/js/mathjax-config.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML"></script>
    </head>
    <body>
            <div class="container">
                <div class="row">
                    <div class="col">
                        <header>
    <span><a href="../">/home/jerin</a> </span>
    <!--
    <span><a href="/archive.html">posts</a></span>,
    <span><a href="/contact.html">contact</a></span>
    -->
</header>

                    </div>
                </div>
                <div class="row">
                    <div class="col">
                        <h1>PostmarketOS: Hello world!</h1>
                        <div class="row mb-4">
    <div class="post-info col">
        <div>Sep 19, 2023</div>

         

         
            <div><a href="../tags/posts/linux.html">linux</a>, <a href="../tags/posts/os.html">os</a>, <a href="../tags/posts/postmarketos.html">postmarketos</a></div>
         
    </div>
</div>

<div class="row">
    <div class="toc col-md-4 col-sm-12 order-md-second"><h6>Outline</h6><ul>
<li><a href="#bootloader-unlock">Bootloader unlock</a></li>
<li><a href="#postmarketos">PostmarketOS</a><ul>
<li><a href="#booting">Booting</a></li>
<li><a href="#usb-ethernet-troubles">USB Ethernet troubles</a></li>
<li><a href="#console">Console</a></li>
<li><a href="#display">Display</a></li>
<li><a href="#reverse-tethering">Reverse Tethering</a></li>
</ul></li>
<li><a href="#desktop-environment">Desktop Environment</a></li>
<li><a href="#thoughts-and-next-steps">Thoughts and next steps</a></li>
<li><a href="#acknowledgements">Acknowledgements</a></li>
</ul></div><div class="col-md-8 col-sm-12 post-content order-md-first"><p>A week ago, from what was originally started as some minor smartphone hacking, I started going down the rabbit-hole of PostmarketOS porting.</p>
<h2 id="bootloader-unlock">Bootloader unlock</h2>
<p>If you take a pass at the <a href="../posts/smartphone-hacking.html">previous post</a>, you’ll notice that I tried all sorts of things to unlock a bootloader, despair that followed and almost giving up. The following methods all failed on me:</p>
<ol style="list-style-type: decimal">
<li>Windows: <a href="https://github.com/bkerler/mtkclient">Official MiUnlock</a></li>
<li>Linux:
<ol style="list-style-type: lower-alpha">
<li><a href="https://github.com/Canny1913/miunlock">Canny1913/miunlock</a></li>
<li><a href="https://github.com/RohitVerma882/termux-miunlock">RohitVerma882/termux-miunlock</a></li>
<li><a href="https://www.xiaomitool.com/V2/">XiaomiToolV2</a></li>
<li><a href="https://github.com/bkerler/mtkclient">bkerler/mtkclient</a></li>
</ol></li>
</ol>
<p>I think my issues were from a broken fastboot. I was almost about to give-up and try something else, until ultimately through <a href="https://github.com/RohitVerma882/termux-miunlock">RohitVerma882/termux-unlock</a> I managed to get a 512 byte token. I tried writing this directly onto <code>devinfo</code> partition which failed, but taking a closer look at the issue comments <a href="https://github.com/bkerler/mtkclient/issues/110#issuecomment-975299392">#1</a> and <a href="https://github.com/bkerler/mtkclient/issues/110#issuecomment-975433985">#2</a>, I realized that I was writing to the beginning instead of the end.</p>
<p>So, I quickly <a href="https://github.com/jerinphilip/pm-tooling/blob/main/src/write_token.c">scripted a program in C</a>, and wrote a binary to be copied as-is to the <code>devinfo</code> partition, flashed it using <code>mtkclient</code> and, to my surprise… <em>it unlocked!</em></p>
<p>Never did I think a day will come when I start writing one-off tools in C, of all languages.</p>
<h2 id="postmarketos">PostmarketOS</h2>
<p>The previous post touched parts of building the operating-system using the OEM kernel adapted to PostmarketOS (which runs AlpineLinux) and Alpine’s packages. This build-install-image process does not require the original device to be a host, it could have been done on my laptop, or even GitHub CI (<code>x86_64</code>) cross-compiling into the target architecture (<code>armv7</code>). A successful build via <code>pmbootstrap</code> lead ends at the following instructions:</p>
<p><strong>Flashing Information</strong></p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="ex">pmbootstrap</span> flasher flash_rootfs
<span class="co">#  Flashes the generated rootfs image to your device:</span>
<span class="co">#</span>
<span class="co">#  ws/chroot_native/home/pmos/rootfs/xiaomi-cereus.img</span>
<span class="co">#  (</span><span class="al">NOTE</span><span class="co">: This file has a partition table, which contains /boot and /</span>
<span class="co">#  subpartitions. That way we don't need to change the partition layout on your</span>
<span class="co">#  device.)</span>
<span class="co">#</span>
$ <span class="ex">pmbootstrap</span> flasher flash_kernel
<span class="co">#  Flashes the kernel + initramfs to your device:</span>
<span class="co">#</span>
<span class="co">#  /ws/chroot_rootfs_xiaomi-cereus/boot</span></code></pre></div>
<p>Since my <code>fastboot</code> was broken and I did not trust it enough, I chose to continue the flashing process with <code>mtkclient</code>.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="ex">pmbootstrap</span> flasher flash_rootfs 
<span class="co"># [22:15:03] (native) flash rootfs image</span>
<span class="co"># [22:15:05] (native) install mtkclient android-tools</span>
<span class="co"># MTK Flash/Exploit Client V1.6.3 (c) B.Kerler 2018-2023</span>
<span class="co"># ...</span>
<span class="co"># Progress: |██████████████████████████████████████████████████| 100.0% Write (Sector 0x240000 of 0x240000, ) 8.75 MB/s.50 MB/sB/s</span>
<span class="co"># Wrote /home/pmos/rootfs/xiaomi-cereus.img to sector 9797632 with sector count 112224223.</span>
<span class="co"># [22:17:08] </span><span class="al">NOTE</span><span class="co">: chroot is still active (use 'pmbootstrap shutdown' as necessary)</span>
<span class="co"># [22:17:08] DONE!</span>

$ <span class="ex">pmbootstrap</span> flasher flash_kernel
<span class="co"># [22:17:12] (rootfs_xiaomi-cereus) install device-xiaomi-cereus</span>
<span class="co"># [22:17:20] (rootfs_xiaomi-cereus) install postmarketos-mkinitfs</span>
<span class="co"># [22:17:23] (rootfs_xiaomi-cereus) mkinitfs xiaomi-cereus</span>
<span class="co"># [22:17:26] </span><span class="al">WARNING</span><span class="co">: config-xiaomi-cereus.armv7 isn't configured properly (postmarketOS), run 'pmbootstrap kconfig check' for details!</span>
<span class="co"># [22:17:26] (native) flash kernel xiaomi-cereus</span>
<span class="co"># [22:17:27] (native) install mtkclient android-tools</span>
<span class="co"># MTK Flash/Exploit Client V1.6.3 (c) B.Kerler 2018-2023</span>
<span class="co"># ....</span>
<span class="co"># Progress: |██████████████████████████████████████████████████| 100.0% Write (Sector 0x503C of 0x503C, ) 0.58 MB/s</span>
<span class="co"># Wrote /mnt/rootfs_xiaomi-cereus/boot/boot.img to sector 1065984 with sector count 131072.</span>
<span class="co"># [22:17:29] You will get an IP automatically assigned to your USB interface shortly.</span>
<span class="co"># [22:17:29] Then you can connect to your device using ssh after pmOS has booted:</span>
<span class="co"># [22:17:29] ssh jerin@172.16.42.1</span>
<span class="co"># [22:17:29] </span><span class="al">NOTE</span><span class="co">: If you enabled full disk encryption, you should make sure that osk-sdl has been properly configured for your device</span>
<span class="co"># [22:17:29] </span><span class="al">NOTE</span><span class="co">: chroot is still active (use 'pmbootstrap shutdown' as necessary)</span>
<span class="co"># [22:17:29] DONE!</span></code></pre></div>
<h3 id="booting">Booting</h3>
<p>The expectation is that an SSH-daemon would be available to connect via a network enabled through the USB-cable. Instructions for this were also given.</p>
<p><strong>SSH daemon information</strong></p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="co"># SSH daemon is enabled (disable with --no-sshd).</span>
<span class="co"># Login as 'jerin' with the password given during installation.</span></code></pre></div>
<p>After flashing the built PostmarketOS image this time, and the phone started booting with the PostmarketOS bootsplash.</p>
<div class="row">
<div class="col-sm-12 col-md-6">
<div class="figure">
<img src="../static/images/pmos/hung-splash.jpg" alt="Loading… bootsplash. (hung)" />
<p class="caption">Loading… bootsplash. (hung)</p>
</div>
</div>
</div>
<p>Eventually I figured I only had the bootsplash logo, with no Desktop Environment (DE). The frozen screen points to something is wrong underneath. The standard check is to go look at <code>lsusb</code> and <code>dmesg</code>.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="ex">lsusb</span>
<span class="co"># Bus 004 Device 001: ID 1d6b:0003 Linux Foundation 3.0 root hub</span>
<span class="co"># Bus 003 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub</span>
<span class="co"># Bus 002 Device 001: ID 1d6b:0003 Linux Foundation 3.0 root hub</span>
<span class="co"># Bus 001 Device 003: ID 06cb:00bd Synaptics, Inc. Prometheus MIS Touch Fingerprint Reader</span>
<span class="co"># Bus 001 Device 002: ID 13d3:56bb IMC Networks Integrated Camera</span>
<span class="co"># Bus 001 Device 074: ID 18d1:d001 Google Inc. Nexus 4 (fastboot)</span>
<span class="co"># Bus 001 Device 004: ID 8087:0aaa Intel Corp. Bluetooth 9460/9560 Jefferson Peak (JfP)</span>
<span class="co"># Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="fu">dmesg</span> 
<span class="co"># [26685.693978] usb 1-3: new high-speed USB device number 74 using xhci_hcd</span>
<span class="co"># [26685.836233] usb 1-3: New USB device found, idVendor=18d1, idProduct=d001, bcdDevice= 4.09</span>
<span class="co"># [26685.836249] usb 1-3: New USB device strings: Mfr=1, Product=2, SerialNumber=3</span>
<span class="co"># [26685.836254] usb 1-3: Product: Xiaomi Redmi 6</span>
<span class="co"># [26685.836258] usb 1-3: Manufacturer: Xiaomi</span>
<span class="co"># [26685.836261] usb 1-3: SerialNumber: postmarketOS</span></code></pre></div>
<p>Since <code>SerialNumber: postmarketOS</code> appeared, this meant the device had booted. However, my laptop’s kernel was failing to detect it as a USB tethering device.</p>
<h3 id="usb-ethernet-troubles">USB Ethernet troubles</h3>
<p>For some reason, my laptop was not recognizing it as an RNDIS host. RNDIS host is a term associated with when a phone is connected to the computer and internet and the computer uses internet via phone - a more popular term is <em>USB Tethering</em>. Except in our case, there was no internet, this was just a local network from the phone so that we could drop into an SSH shell within the phone.</p>
<p>Initially I thought this issue was due to me manipulating <a href="https://github.com/bkerler/mtkclient/tree/c6389116d84a36ad33c95a3284d9311ec8fc5dfa/Setup/Linux">udev rules</a> for <a href="https://github.com/bkerler/mtkclient">mtkclient</a>. However, I noticed RNDIS recognition was working on my Desktop (<code>linux-6.4.x</code>) but not on my Laptop (<code>linux-6.1.x-lts</code>). The ArchLinux channel suggested upgrading kernel, which I did - and things were working from my laptop.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="fu">dmesg</span> (truncated)
<span class="co"># [26685.693978] usb 1-3: new high-speed USB device number 74 using xhci_hcd</span>
<span class="co"># [26685.836233] usb 1-3: New USB device found, idVendor=18d1, idProduct=d001, bcdDevice= 4.09</span>
<span class="co"># [26685.836249] usb 1-3: New USB device strings: Mfr=1, Product=2, SerialNumber=3</span>
<span class="co"># [26685.836254] usb 1-3: Product: Xiaomi Redmi 6</span>
<span class="co"># [26685.836258] usb 1-3: Manufacturer: Xiaomi</span>
<span class="co"># [26685.836261] usb 1-3: SerialNumber: postmarketOS</span>
<span class="co"># [26685.840481] rndis_host 1-3:1.0 usb0: register 'rndis_host' at usb-0000:00:14.0-3, RNDIS device, c6:1a:27:dd:a2:dc</span>
<span class="co"># [26686.514605] rndis_host 1-3:1.0 enp0s20f0u3: renamed from usb0</span></code></pre></div>
<p>While the issue and fix appears trivial, it took me a while to figure out the simple fix - some time went down the drain. Initially I was suspecting postmarketOS machinery failure as well.</p>
<h3 id="console">Console</h3>
<p>With USB network connectivity between the devices, I could now SSH into the phone.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="fu">ssh</span> jerin@172.16.42.1
<span class="co"># Welcome to postmarketOS! o/</span>
<span class="co"># </span>
<span class="co"># This distribution is based on Alpine Linux.</span>
<span class="co"># First time using postmarketOS? Make sure to read the cheatsheet in the wiki:</span>
<span class="co"># </span>
<span class="co"># -&gt; https://postmarketos.org/cheatsheet</span>
<span class="co"># </span>
<span class="co"># You may change this message by editing /etc/motd.</span>
<span class="co"># xiaomi-cereus:~$ </span></code></pre></div>
<p>I could pretty much use the compute on the device from here. A lot of hardware (telephony, WiFi, display) all were not working. This is only console UI, so I can try on thing or the other.</p>
<h3 id="display">Display</h3>
<p>Now that I had a shell that I could issue commands using the laptop, I went looking for logs that could provide a clue as to what is happening. To be honest, I wasn’t entirely sure if the boot process was working because the screen still appeared to be bootlooping. Toward this I managed to wander around using different test-probles like <code>maximum-attention</code> and <code>debug-shell</code>.</p>
<p>I tried some variations in DEs in the created images and flashing, out of which <a href="https://sxmo.org/deviceprofile">sxmo</a> gave me a first draw before crashing and rebooting, consistently over and over again. Other DEs were just hung on a blank screen.</p>
<div class="row">
<div class="col-sm-12 col-md-6">
<div class="figure">
<img src="../static/images/pmos/sxmo.jpg" alt="SXMO (Frozen display)" />
<p class="caption">SXMO (Frozen display)</p>
</div>
</div>
<div class="col-sm-12 col-md-6">
<div class="figure">
<img src="../static/images/pmos/xfce.jpg" alt="XFCE (Frozen display)" />
<p class="caption">XFCE (Frozen display)</p>
</div>
</div>
</div>
<p>Eventually after doing things with OpenRC to enable and disable stuff, I ended up with first-draws for XFCE, and even some touch-interaction responses before hang. Since this was a first-draw problem searching would lead me to:</p>
<ul>
<li><a href="https://wiki.postmarketos.org/wiki/Troubleshooting:display#Generic_troubleshooting_(any_manufacturer)">Troubleshooting:display#Generic_troubleshooting_(any_manufacturer)</a>.</li>
</ul>
<p>I was ignoring content despite the headline because <code>msm</code> (Qualcomm?), but this was actually generic. Applying the fix fixed my display problem.</p>
<h3 id="reverse-tethering">Reverse Tethering</h3>
<p>I hoped WiFi would work so I won’t have to stay tethered to the Laptop, but the WiFi situation is pretty bad. <a href="https://wiki.postmarketos.org/wiki/USB_Internet">Reverse Tethering</a> - in my case, using laptop’s connection by the phone through the tether was turning out to be the easy option.</p>
<p>On the phone (guest), the instructions are to issue the following.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">route</span> add default gw 172.16.42.2

<span class="co"># Make the above change permanent.</span>
<span class="bu">echo</span> <span class="st">'route add default gw 172.16.42.2'</span> <span class="kw">|</span> <span class="fu">sudo</span> tee /etc/local.d/usb_internet.start
<span class="fu">chmod</span> +x /etc/local.d/usb_internet.start

<span class="co"># Manually add nameserver</span>
<span class="bu">echo</span> nameserver 1.1.1.1 <span class="kw">|</span> <span class="fu">sudo</span> tee /etc/resolv.conf</code></pre></div>
<p>The wiki suggests it’s possible to redirect output, but I had to issue <code>sudo tee</code> as user.</p>
<p>For my archlinux on laptop (host), I had to issue the following:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">iptables</span> -A FORWARD -m conntrack --ctstate ESTABLISHED,RELATED -j ACCEPT
<span class="ex">iptables</span> -A FORWARD -s 172.16.42.0/24 -j ACCEPT
<span class="ex">iptables</span> -A POSTROUTING -t nat -j MASQUERADE -s 172.16.42.0/24
<span class="ex">iptables-save</span> </code></pre></div>
<h2 id="desktop-environment">Desktop Environment</h2>
<p>With this, I had internet, and could try and swap out Desktop Environments without having to flash over and over again. One could use <a href="https://wiki.postmarketos.org/wiki/Category:Interface">Category:Interfaces</a> as a start-point. Quick status updates on these are:</p>
<ul>
<li>GNOME Mobile: fail</li>
<li>KDE Plasma Mobile: fail</li>
<li>sxmo: Works, unusable.</li>
<li>XFCE4: Works, usable.</li>
</ul>
<p>I haven’t tried much further, just trying out applications and other things on top with XFCE4 for now. I saw a few videos of patched GNOME Mobile shells, which appear nice, and also <a href="https://puri.sm/posts/phosh-overview/">Phosh</a>. There is an on-screen keyboard (bit ugly). Applications are running.</p>
<div class="row">
<div class="col-sm-12 col-md-6">
<div class="figure">
<img src="../static/images/pmos/xfce-sc-clean.png" alt="XFCE Screenshot (clean)" />
<p class="caption">XFCE Screenshot (clean)</p>
</div>
</div>
<div class="col-sm-12 col-md-6">
<div class="figure">
<img src="../static/images/pmos/xfce-sc-apps.png" alt="XFCE Screenshot (apps)" />
<p class="caption">XFCE Screenshot (apps)</p>
</div>
</div>
</div>
<h2 id="thoughts-and-next-steps">Thoughts and next steps</h2>
<p>While android is still running Linux under the hood, pure Linux on the phone still has a long way to go. It’s really hard to support the fragmented space of devices, if I were to guess why. Most drivers for specialized hardware is in android userland and proprietary - to the point reverse engineering is the favourable option. It will be a while before Linux on the phone takes off. Even if it happens, it’s unlikely the ecosystem of apps that exists on Apple or Android or Windows can be matched.</p>
<p>I’m not sure if there’s much to gain by mainlining kernels for old phones at this stage, but poking in this space, contributing one or the other small patches at the bare minimum scratches an itch to hack and tinker. I have initialized a wiki-page for my phone - <a href="https://wiki.postmarketos.org/wiki/Xiaomi_Redmi_6_(xiaomi-cereus)">Xiaomi_Redmi_6_(xiaomi-cereus)</a>. I have the pmaports diff ready at <a href="https://github.com/jerinphilip/pmaports/pull/1">jerinphilip/pmaports#1</a>, and will slowly work towards getting the port into the main repository and in time hopefully further features working.</p>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>Two PostmarketOS developers/enthusiasts - <a href="https://mstdn.social/@justsoup">@justsoup</a> and <a href="https://mastodon.social/@hexaheximal">@hexaheximal</a> helped a lot during the course of porting. It’s unlikely I would have made progress as fast as I could without these two. I plan to contribute to some their efforts of mainlining MT6765 series of chips.</p></div>
</div>


<div class="row">
    <div class="col">
        <p class="text-muted font-italic"> (Comments disabled. Email me instead.) </p>
    </div>
</div>

                    </div>
                </div>

                <div class="row">
                    <div class="col">
                        
<footer>
    <small>Site generated using <a href="http://jaspervdj.be/hakyll">Hakyll</a></small>
</footer>

                    </div>
                </div>
            </div>
        <script type="text/javascript" src="../static/js/init.js"></script>
    </body>
</html>
]]></summary>
</entry>
<entry>
    <title>Smartphone hacking baby-steps</title>
    <link href="http://jerinphilip.github.io/posts/smartphone-hacking.html" />
    <id>http://jerinphilip.github.io/posts/smartphone-hacking.html</id>
    <published>2023-09-13T00:00:00Z</published>
    <updated>2023-09-13T00:00:00Z</updated>
    <summary type="html"><![CDATA[<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta property="og:title" content="Smartphone hacking baby-steps" />
        <meta property="og:url" content="http://jerinphilip.github.io/posts/smartphone-hacking.html" />
        <title>Smartphone hacking baby-steps</title>
        <link rel="shortcut icon" href="../static/images/favicon.ico" type="image/x-icon">
        <link rel="stylesheet" href="../static/css/hack.css" />
        <link rel="stylesheet" href="../static/css/open-sans.css">
        <link rel="stylesheet" href="../static/css/font-awesome.min.css">
        <link rel="stylesheet" href="../static/css/tether.min.css" />
        <link rel="stylesheet" href="../static/css/bootstrap.min.css" />
        <link rel="stylesheet" href="../static/css/custom.css" />
        <link rel="stylesheet" href="../static/css/kate.css" />
        <link rel="stylesheet" href="../static/css/ekko-lightbox.css" />
        <script type="text/javascript" src="../static/js/jquery.min.js"></script>
        <script type="text/javascript" src="../static/js/tether.min.js"></script>
        <script type="text/javascript" src="../static/js/anchor.min.js"></script>
        <script type="text/javascript" src="../static/js/ekko-lightbox.min.js"></script>
        <script type="text/javascript" src="../static/js/bootstrap.min.js"></script>
        <script type="text/x-mathjax-config" src="../static/js/mathjax-config.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML"></script>
    </head>
    <body>
            <div class="container">
                <div class="row">
                    <div class="col">
                        <header>
    <span><a href="../">/home/jerin</a> </span>
    <!--
    <span><a href="/archive.html">posts</a></span>,
    <span><a href="/contact.html">contact</a></span>
    -->
</header>

                    </div>
                </div>
                <div class="row">
                    <div class="col">
                        <h1>Smartphone hacking baby-steps</h1>
                        <div class="row mb-4">
    <div class="post-info col">
        <div>Sep 13, 2023</div>

         

         
            <div><a href="../tags/posts/android.html">android</a>, <a href="../tags/posts/linux.html">linux</a>, <a href="../tags/posts/postmarketos.html">postmarketos</a></div>
         
    </div>
</div>

<div class="row">
    <div class="toc col-md-4 col-sm-12 order-md-second"><h6>Outline</h6><ul>
<li><a href="#tecno-pova-3">Tecno Pova 3</a><ul>
<li><a href="#removing-bloatware">Removing bloatware</a></li>
<li><a href="#unlocking-bootloader">Unlocking bootloader</a></li>
<li><a href="#backups">Backups</a></li>
<li><a href="#lineageos">LineageOS?</a></li>
<li><a href="#postmarketos-appeal">PostmarketOS appeal</a></li>
</ul></li>
<li><a href="#xiaomi-redmi-6">Xiaomi Redmi 6</a><ul>
<li><a href="#unlocking-bootloader-1">Unlocking bootloader</a></li>
<li><a href="#backups-1">Backups</a></li>
<li><a href="#building-postmarketos">Building PostmarketOS</a><ul>
<li><a href="#extracting-kconfig">Extracting Kconfig</a></li>
<li><a href="#steps">Steps</a></li>
<li><a href="#flashing-boot.img">Flashing <code>boot.img</code></a></li>
</ul></li>
<li><a href="#revenge-of-the-bootloader">Revenge of the bootloader</a></li>
</ul></li>
<li><a href="#restore">Restore</a></li>
<li><a href="#next-steps">Next steps</a></li>
</ul></div><div class="col-md-8 col-sm-12 post-content order-md-first"><p>I have been wanting to get into deeper smartphone hacking for a while. Time and enough spare-devices lying around that I could risk bricking that making it viable had to wait until now.</p>
<p>I purchased my first Smartphone in 2011 or so - it was a tiny <a href="https://www.gsmarena.com/htc_wildfire_s-3777.php">HTC Wildfire S</a>. I think I used it for about 2-3 years or so until I had to abandon it for a more reliable phone when I moved to college. Android at the time was increasing hardware requirements every release, the Wildfire hit its limits quite fast. In order to squeeze some juice out of it I ended up having to flash custom ROMs. If memory serves me right, I successfully flashed a <a href="https://www.clockworkmod.com/">Clockworkmod recovery</a> followed by a Cyanogenmod ROM through a <code>.zip</code> from the recovery. This happened circa 2012-2013. Back then, I was a consumer of what enthusiast people over at <a href="https://forum.xda-developers.com/">XDA</a> did. My uncle had a <a href="https://www.gsmarena.com/nokia_n8-3252.php">Nokia N8</a>, which I would help load multimedia content etc for. But it was painfully obvious Android will take over soon-enough, at least against N8’s <a href="https://en.wikipedia.org/wiki/Symbian">Symbian</a>. I vaguely remember modding the Xperia ZR that I had after the HTC Wildfire S. The strategy so far has been to wait till warranty expires, then do rooting and custom ROMs.</p>
<p>So - this time on, I’m less of a noob considering smartphone hacking. Some operating-system theory and sysadmin practical knowledge over the years equips me to be further <a href="https://drewdevault.com/2018/03/17/Hack-everything-without-fear.html">fearless</a>. The hacker who inspired courage efforts has since <a href="https://drewdevault.com/2023/06/16/Mobile-linux-retrospective.html">thrown in the towel for mobile linux</a>. For the right reasons - I expect significant pain at figuring out the lower-level details that could alternatively be solved spending money instead of time.</p>
<p>One eventual goal is to become a producer in this ecosystem, than just a consumer. Working devices I have in hand currently are a <a href="https://www.gsmarena.com/xiaomi_redmi_6-9237.php">Xiaomi Redmi 6</a> and a <a href="https://www.gsmarena.com/tecno_pova_3-11553.php">Tecno Pova 3</a>. One is an old-abandoned device, the other my daily driver at the moment. I have no plans to use Redmi 6 except for development - can even risk hard-bricking it. So, onward.</p>
<h2 id="tecno-pova-3">Tecno Pova 3</h2>
<p>The Tecno phone in my possession was an experimental buy. This is a 2022 release, and probably didn’t sell well in the Indian market. I googled for phones with maximum battery capacity (7000 mAh) and discovered this Phone. I had the funds to buy a Pixel if I wanted this time, but then I also thought - I can experiment with a mid-range phone, new manufacturer and swap to a Motorola which usually offers less adultered android in case the experiment does not pan out.</p>
<p>Looking back, I did read and ignore warnings about higher ads and bloatware on the Tecno HiOS, which I can confirm now to be true. Then, without much research, I thought I’ll flash LineageOS to get rid of HiOS and have something clean. Successful LineageOS install is proving to be more difficult than I expected, due to Original Equipment Manufacturer (OEM) kernel not being available.</p>
<h3 id="removing-bloatware">Removing bloatware</h3>
<p>I discovered some minimally invasive ideas to remove bloatware from the Tecno Pova 3. Android offers slightly better control without having to flip warranty-breaking switches these days, looks like. Makes sense to exhaust these ideas first.</p>
<p>I started off attempting things from a bunch of YouTube videos of folks describing how they got less ad-ridden phones. The process essentially boils down to:</p>
<ol style="list-style-type: decimal">
<li>Find <code>com.transsion.*</code> apps. <a href="https://play.google.com/store/apps/details?id=com.csdroid.pkg&amp;hl=en&amp;gl=US&amp;pli=1">Package Name Viewer</a> is an option.</li>
<li>Find suspicious apps that we are possibly okay without.
<ol style="list-style-type: lower-alpha">
<li>Clear cache/data for the app.<br />
</li>
<li>Disable (via Android)</li>
<li>Disallow overlays (to prevent banner ads)</li>
<li>Disable Network Access.</li>
</ol></li>
<li>There are non <code>com.transsion.</code> apps as well, offending apps can be found on the internet.</li>
</ol>
<p>These despite promising, did not work in the end. The offending apps were turning settings back on. It’s interesting that this cat-and-mouse game between manufacturer - end-user is still on.</p>
<p>Thankfully, there are still some <code>adb</code> options available. I tried the straightforward way:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="ex">adb</span> uninstall com.transsion.smartpanel
<span class="ex">Failure</span> [DELETE_FAILED_INTERNAL_ERROR]
$ <span class="ex">adb</span> uninstall com.transsion.tecnospot
<span class="ex">Failure</span> [DELETE_FAILED_INTERNAL_ERROR]</code></pre></div>
<p>There are however, some advanced techniques people recommend over on Q&amp;A sites and forums:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="op">&gt;</span> <span class="ex">adb</span> shell

<span class="ex">TECNO-LF7</span>:/ $ pm list packages
<span class="ex">package</span>:com.google.android.networkstack.tethering
<span class="ex">package</span>:com.hilauncherconfig
<span class="ex">package</span>:com.google.android.ext.services
<span class="ex">package</span>:com.google.android.googlequicksearchbox
<span class="ex">...</span>
<span class="ex">package</span>:com.transsion.bluetooth
<span class="ex">package</span>:com.talpa.hiservice
<span class="ex">package</span>:com.transsion.phonemaster
<span class="ex">...</span>

<span class="ex">TECNO-LF7</span>:/ $ pm uninstall --user 0 tech.palm.id
<span class="ex">TECNO-LF7</span>:/ $ pm uninstall --user 0 com.zaz.translat
<span class="ex">TECNO-LF7</span>:/ $ pm uninstall --user 0 com.transsnet.store
<span class="ex">...</span></code></pre></div>
<p>This appears to be working, so mission accomplished, I suppose. I can of-course try and take this further - to get LineageOS, near vanilla android, with much better control.</p>
<h3 id="unlocking-bootloader">Unlocking bootloader</h3>
<p>The first steps towards doing customization these days is unlocking the bootloader. The boot-process is multi-staged and has some verification mechanisms built in. In it’s essence, this is check the hash of the partitions that are involved in the next stage of the boot. Unlocking typically means to tell the software to not check for the hash at some point, so we can boot a partition different from what the vendor packaged.</p>
<p>This was not that hard on the Tecno Pova 3 (LF7). The device comes with <code>fastboot</code>. And all it takes is a command in <code>fastboot</code>.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">fastboot</span> flashing unlock</code></pre></div>
<p>One banking application has since been unhappy with the tampering and refuse to open, they were probably only using <code>WebView</code> to display their web-backend anyway, so meh - will directly use it from Firefox.</p>
<h3 id="backups">Backups</h3>
<p>Having a backup of whatever is in the storage gives some courage to try crazier stuff. This is because if something goes wrong in the non-critical parts, it is possible to just write back whatever existed before to get the functional phone back. I figure there are multiple methods to create such a backup.</p>
<p>The System-on-Chip (SoC) on this phone is MediaTek MT6768/MT6769 (Helio P65/G85 k68v1). The Redmi 6 in my possession also has a MediaTek SoC. I have found MediaTek has some nice tooling - <a href="https://spflashtool.com/">SPFlash tool</a>, and a popular <a href="https://github.com/bkerler/mtkclient"><code>mtkclient</code></a>.</p>
<p>I tried using <code>mtkclient</code>, but it appears I am not able find much success at least for now. I tried a non-invasive <code>printgpt</code> and <code>dump bootrom</code>, but somehow the exploits do not seem to work on the device.</p>
<p><details> <summary><code>mtk printgpt</code></summary></p>
<pre><code>Port - Hint:

Power off the phone before connecting.
For brom mode, press and hold vol up, vol dwn, or all hw buttons and connect usb.
For preloader mode, don't press any hw button and connect usb.
If it is already connected and on, hold power for 10 seconds to reset.


......Port - Device detected :)
Preloader - 	CPU:			MT6768/MT6769(Helio P65/G85 k68v1)
Preloader - 	HW version:		0x0
Preloader - 	WDT:			0x10007000
Preloader - 	Uart:			0x11002000
Preloader - 	Brom payload addr:	0x100a00
Preloader - 	DA payload addr:	0x201000
Preloader - 	CQ_DMA addr:		0x10212000
Preloader - 	Var1:			0x25
Preloader - Disabling Watchdog...
Preloader - HW code:			0x707
Preloader - Target config:		0x5
Preloader - 	SBC enabled:		True
Preloader - 	SLA enabled:		False
Preloader - 	DAA enabled:		True
Preloader - 	SWJTAG enabled:		True
Preloader - 	EPP_PARAM at 0x600 after EMMC_BOOT/SDMMC_BOOT:	False
Preloader - 	Root cert required:	False
Preloader - 	Mem read auth:		False
Preloader - 	Mem write auth:		False
Preloader - 	Cmd 0xC8 blocked:	False
Preloader - Get Target info
Preloader - 	HW subcode:		0x8a00
Preloader - 	HW Ver:			0xca00
Preloader - 	SW Ver:			0x0
Mtk - We're not in bootrom, trying to crash da...
Exploitation - Crashing da...
Preloader
Preloader - [LIB]: upload_data failed with error: DAA_SIG_VERIFY_FAILED (0x7024)
Preloader
Preloader - [LIB]: Error on uploading da data
Preloader - Jumping to 0x0
Preloader - Status: Waiting for PreLoader VCOM, please connect mobile

Port - Hint:

Power off the phone before connecting.
For brom mode, press and hold vol up, vol dwn, or all hw buttons and connect usb.
For preloader mode, don't press any hw button and connect usb.
If it is already connected and on, hold power for 10 seconds to reset.


..........Preloader
Preloader - [LIB]: Status: Handshake failed, retrying...
</code></pre>
<p></details></p>
<p>While the <code>mtkclient</code> efforts are intended to take backups, one idea is to eventually extract the <code>boot.img</code> etc which allows to use <a href="https://github.com/twrpdtgen/twrpdtgen">twrpdtgen</a> to extract the device-tree. It will also allow me to unpack the <code>boot.img</code> to find the <code>KConfig</code> used to compile the kernel. I do not have the source-code, but more clues are hopefully there to find a close relative of a phone. It should also be possible to use the pre-compiled kernel to power a not-so-nice LineageOS installation, I am told.</p>
<p>For now, I’m stuck. I’m trying to correpond with the <code>mtkclient</code> library author for some help at <a href="https://github.com/bkerler/mtkclient/issues/778">bkerler/mtkclient#778</a>. What appears to be more popular - the <a href="https://spflashtool.com/">SPFlashTool</a> requires Windows, I don’t have an installation at the moment.</p>
<p>The Tecno Pova 3 is more usable and less intrusive due to ads now, so I have some degree of success in gaining further control over my device.</p>
<h3 id="lineageos">LineageOS?</h3>
<p>I spent some time in the LineageOS channel trying to setup AOSP a few months back. I tried the basic setup and things - my new machine could compile LineageOS code quite fast. One of the requirements from the LineageOS communities appeared to be the OEM kernel sources. Knowing about the <a href="https://source.android.com/docs/core/architecture/kernel/generic-kernel-image">Generic Kernel Image</a> (GKI) Project could have helped. However, my phone, despite being recent I think shipped with a <code>4.x</code> kernel (GKI applies to devices launching with <code>&gt; 5.4</code>). I find myself at the mercy of the vendor, and when they eventually release the sources.</p>
<p>Let’s hope some open-sourcing eventually happens, I’ll prepare a bit in any case.</p>
<h3 id="postmarketos-appeal">PostmarketOS appeal</h3>
<p>If the device-manufacturer, in my case, <a href="https://www.transsion.com/">Transsion</a> - <a href="https://www.tecno-mobile.in">Tecno</a>, does not provide OEM Kernel sources in open-violation of the GPL, the idea of <a href="https://wiki.postmarketos.org/wiki/Mainlining"><em>mainlining</em></a> suddenly becomes attractive. I’m being naive and optimistic here, as the Tecno phone also has hardware that are unique (front camera LED, Fingerprint sensor) and a newer chip not available in mainline (MT6768/MT6769). The mainline kernel would add support across devices, so if someone else using same SoC releases kernel sources I might be able to use it to boot at least. Telephony and specialized hardware would be far behind still.</p>
<p>Now, porting to a new device walkthrough mentions requiring the downstream kernel <a href="https://wiki.postmarketos.org/wiki/Porting_to_a_new_device#Source_code">source-code</a>. Since I don’t have it for the Pova 3, might as well start with the Xiaomi. This is under an optimistic assumption that eventually I should be able to unlock the bootloader. I expect a few hurdles in compiling the kernel with Postmarket infrastructure, and me learning the parts - so let’s clear that to begin with.</p>
<h2 id="xiaomi-redmi-6">Xiaomi Redmi 6</h2>
<p>Xiaomi Redmi 6 (codename <code>cereus</code>) appears to have been ported to LineageOS and in <a href="https://stats.lineageos.org/model/cereus">use</a>. Makes sense, because Xiaomi has open-sourced the kernel. The following are available online:</p>
<ol style="list-style-type: decimal">
<li><a href="https://github.com/MiCode/Xiaomi_Kernel_OpenSource/tree/cactus-o-oss">Xiaomi_Kernel_OpenSource@cactus-o-oss</a></li>
<li><a href="https://github.com/xiaomi-mt6765/android_kernel_xiaomi_mt6765">xiaomi-mt6765/android_kernel_xiaomi_mt6765</a>
<ol style="list-style-type: lower-alpha">
<li><a href="https://github.com/jerinphilip/android_kernel_xiaomi_mt6765">jerinphilip/android_kernel_xiaomi_mt6765</a></li>
</ol></li>
</ol>
<p>Building LineageOS should be possible. Some high-end machines could help ease the compile, and I have one. PostmarketOS is recent and I’ve been wanting to try out for fun. There are some overlaps in the communities in terms of skill, resources required and possibly enthusiasts.</p>
<p>For a change, I will try how PostmarketOS sees things. The <a href="https://wiki.postmarketos.org/wiki/Porting_to_a_new_device">PostmarkertOS Wiki</a> appears far better and developer-oriented and the community much more welcoming to noob questions on Matrix/IRC.</p>
<h3 id="unlocking-bootloader-1">Unlocking bootloader</h3>
<p>As we saw before during the inspection and backup efforts for the Pova, <code>mtkclient</code> provides a friendly interface to unlock the bootloader across a wide variety of devices with MediaTek SoCs. Redmi 6 is an old phone, and the chip appears to be well supported.</p>
<p>I ran through the instructions in <a href="https://github.com/bkerler/mtkclient#unlock-bootloader">bkerler/mtkclient#unlock-bootloader</a>. Things appear to be going well, on the surface.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="ex">python</span> mtk printgpt 
$ <span class="ex">python</span> mtk e metadata,userdata 
$ <span class="ex">python</span> mtk da seccfg unlock
$ <span class="ex">python</span> mtk reset</code></pre></div>
<h3 id="backups-1">Backups</h3>
<p>Since PostmarketOS installation process will write to <code>boot.img</code> and <code>system.img</code>, sensible thing to do is to take backups in case something goes wrong. It’s risky to use stock-firware found in arbitrary websites on the internet.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="ex">python</span> mtk printgpt</code></pre></div>
<p>This reveals the <code>boot</code>, <code>system</code> and <code>vbmeta</code> partitions (at least). It’s safe to take backups of other partitions as well, just in case. Storage is cheap. But not <code>userdata</code> and <code>cache</code>, that can be wiped and cleaned without risk. These are where data is stored, so it’ll take longer to back this up over the USB-2.0 connection (nearly 4 hours compared to 15 minutes on my setup).</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="va">PARTITIONS=(</span>
    <span class="ex">boot</span>
    <span class="ex">vbmeta</span>
    <span class="ex">system</span>
)

<span class="fu">mkdir</span> -p export
<span class="kw">for</span> <span class="ex">partition</span> in <span class="va">${PARTITIONS[@]}</span><span class="kw">;</span> <span class="kw">do</span>
    <span class="ex">python</span> mtk r <span class="va">$partition</span> export/<span class="va">$partition</span>.img
<span class="kw">done</span>;</code></pre></div>
<h3 id="building-postmarketos">Building PostmarketOS</h3>
<p>The PostmarketOS ecosystem was nicer than I expected it to be - wiki, tooling, matrix channels. I used <code>pmbootstrap</code> to initialize a workspace, new device port according to the instructions.</p>
<h4 id="extracting-kconfig">Extracting Kconfig</h4>
<p>Being a newbie, I started from some config I found in the public source-repository - <a href="https://github.com/xiaomi-mt6765/android_kernel_xiaomi_mt6765">xiaomi-mt6765/android_kernel_xiaomi_mt6765</a> and tried to play around until I got compilation to work. But there is a better way. Given I have <code>mtkclient</code> working for the Redmi 6, I can use it to extract the <code>boot.img</code> partition, and from the compiled kernel the <code>config</code> used to compile. Somebody in <a href="https://matrix.to/#/#porting:postmarketos.org">#porting:postmarketos.org</a> helped me out soon as I supplied the <code>boot.img</code>, for the sake of completeness and my own learning I redo the steps below:</p>
<p><a href="https://github.com/torvalds/linux/blob/master/scripts/extract-ikconfig">extract-ikconfig</a>, a utility available in the linux repository enable inspecting the kernel for the config it was compiled with.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="ex">extract-ikconfig</span> export/boot.img <span class="op">&gt;</span> export/config.linux-xiaomi-cereus.armv7</code></pre></div>
<h4 id="steps">Steps</h4>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="ex">pmbootstrap</span> init
$ <span class="ex">pmbootstrap</span> checksum device-xiaomi-cereus
$ <span class="ex">pmbootstrap</span> checksum linux-xiaomi-cereus
$ <span class="ex">pmbootstrap</span> kconfig check
$ <span class="ex">pmbootstrap</span> kconfig edit
$ <span class="ex">pmbootstrap</span> build linux-xiaomi-cereus
$ <span class="ex">pmbootstrap</span> install</code></pre></div>
<h4 id="flashing-boot.img">Flashing <code>boot.img</code></h4>
<p>To check it suffices to flash <code>boot.img</code> - i.e, overwrite the <code>/boot</code> partition with the generated <code>boot.img</code>.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="ex">python</span> mtk w boot /path/to/boot/boot.img</code></pre></div>
<p>Fingers crossed.</p>
<h3 id="revenge-of-the-bootloader">Revenge of the bootloader</h3>
<p>I powered-up the device. The device started vibrating funny, and long. One person helping me out in the channel hypothesised this could be a positive, since the kernel was designed to light and LED or vibrate indicating it booted. This raised my spirits, but only for a short while. Sadly, turns out I never enabled these hooks - which meant something was <em>very, very wrong</em>.</p>
<p>The standard check is to connect to USB and see if the device is getting recognized:</p>
<pre><code>[246083.382812] usb 1-3: new high-speed USB device number 42 using xhci_hcd
[246083.523263] usb 1-3: New USB device found, idVendor=0e8d, idProduct=0003, bcdDevice= 1.00
[246083.523285] usb 1-3: New USB device strings: Mfr=0, Product=0, SerialNumber=0
[246083.526879] cdc_acm 1-3:1.0: ttyACM0: USB ACM device</code></pre>
<p>This is just MediaTek stuff, nothing regarding the device.</p>
<p>Find the visuals of the phone vibrating:</p>
<iframe width="315" height="560" src="https://www.youtube.com/embed/1JD8ANESalg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen>
</iframe>
<p>This was obviously bad, but silver lining is room for learning more nuances. MediaTek SoCs write the boot logs to a partition called <code>expdb.bin</code>. In order to inspect the <code>expdb.bin</code> without any contaminations from prior boots, I was told I had to first erase it by writing out 0s.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="ex">python</span> mtk e expdb
$ <span class="ex">python</span> mtk reset</code></pre></div>
<p>Now I booted again to see the phone vibrate. Then I got it into bootrom once again. Time to inspect the logs.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="ex">python</span> mtk r expd expdb.bin</code></pre></div>
<p>Poking a bit further, produce the logs to the experts and I got pointed to the offending parts causing the kernel to panic below:</p>
<pre><code>[67] [LK] fdt setup addr:0x47880000 status:0!!!
[67] setup_fdt fail, ret: 0x0!
[67] real mdtbo index=0
[69] fdt_open_into failed 
[69] [SEC_POLICY] reached the end, use default policy
[69] [SEC_POLICY] sboot_state = 0x1
[69] [SEC_POLICY] lock_state = 0x3
[70] [SBC] image dconfig-dt auth init fail (0x6003)
[70] dconfig image cert verify failed
[70] panic (caller 0x48022b8f): ASSERT at (app/mt_boot/bootargs.c:96): fdt_bootargs</code></pre>
<p><code>fdt</code> stands for <em>flattened device tree</em>. This the device tree blob (<code>dtb</code>) and the device tree blob overlay (<code>dtbo</code>) combined. Therefore the bootloader is complaining about something to do with the <code>dtb</code>. I guess the hardware was configured to vibrate in case of an inability to boot.</p>
<p>One suggested way to solve this problem was to get the <code>dtb</code> from the working device and swap-in. However, I had a feeling was this was due to some misconfiguration in the <code>KConfig</code> where I remembered having to make a few more changes than necessary to compile this kernel. I tracked down the problem - I was working with an <code>aarch64</code> config instead of an <code>armv7</code> config, I figured since <a href="https://en.wikichip.org/wiki/mediatek/helio/p22">MT6762</a> supported <code>aarch64</code>, that would be the architecture to compile for - turns out I was wrong.</p>
<p>Having found the root of the problem, I changed the config to <code>armv7</code>, generated a fresh <code>boot.img</code>. Ready for the moment-of-truth.</p>
<div class="row">
<div class="col-md-6 col-sm-12">
<p><img src="../static/images/cereus-system-has-been-destroyed.jpg" width="100%"></p>
</div>
</div>
<p>oops!</p>
<p>Inspecting the <a href="http://ix.io/4GcA">logs</a> this time, we find:</p>
<pre><code>[618] [PROFILE] ::: lvl(2) logo verify takes 53 ms
[618] [SEC_POLICY] reached the end, use default policy
[619] [SEC_POLICY] sboot_state = 0x1
[619] [SEC_POLICY] lock_state = 0x3
....
[926] RSA_padding_check_PKCS1_type_1 failed ret:-1
[926] token sig decrypt failed:-2
...
[935] [SEC_POLICY] sboot_state = 0x1
[935] [SEC_POLICY] lock_state = 0x4
[935] [avb] img_auth_required = 1
[936] avb_slot_verify.c[936] :[936] 637[936] : ERROR: 
[936] vbmeta[936] : Error verifying vbmeta image: [936] OK_NOT_SIGNED[936] 
[936] [avb] boot/recovery vfy time = 6 ms
[936] mblock_create mblock start b9b70000 size: 6400000
[936] [avb] avb_ret = 3
[937] [LK] check_ota_result = 0
[937] [LK] ota-fail
[937] fb dump: 0xff000000, 0xff000000, 0xff000000, 0xff000000
dm-verity error


Android system on your device is corrupted.

Device will boot in %ds

[5939] boot state: red
[5939] fb dump: 0xff000000, 0xff000000, 0xff000000, 0xff000000
Red State</code></pre>
<p>The villain of the Redmi 6 story is the bootloader. Xiaomi has insane protections surrounding bootloader unlock. You are supposed to be using the <a href="https://en.miui.com/unlock/download_en.html">official unlock tool</a>, which works on Windows only. It should be able to support Linux, there are actually a few clients - <a href="https://github.com/francescotescari/XiaoMiToolV2">francescotescari/XiaoMiToolV2</a>, <a href="https://github.com/RohitVerma882/termux-miunlock">RohitVerma882/termux-miunlock</a>.</p>
<p>The Redmi has an account tied to a SIM card that’s not mine. I can access the SIM required from time-to-time, but this makes it tricky to use the Xiaomi official tooling. I figured if there’s some MediaTek generic angles via <code>mtkclient</code>, perhaps that would work?</p>
<p>I was wrong. A deeper search revealed the following issue:</p>
<ul>
<li><a href="https://github.com/bkerler/mtkclient/issues/110">bkerler/mtkclient#110</a>: redmi 6a unlock succees but remain lock</li>
</ul>
<p>I have for now <a href="https://github.com/bkerler/mtkclient/issues/110#issuecomment-1716787319">requested</a> further information.</p>
<p>Judging by existing comments, turns out there’s some mechanism to ensure a unique Xiaomi key unlocks it. I hope I can solve this eventually with the official unlock tool, and if that doesn’t work maybe even try my hands at riskier exploits that could hard-brick the device.</p>
<p>I tried my luck at unlocking use the stock firmware and the <a href="https://en.miui.com/unlock/index.html">official method</a> - the phone never ended up getting recognized on the Windows machine I was trying with.</p>
<p>I managed to use <a href="https://github.com/RohitVerma882/termux-miunlock">termux-unlock</a> at least partially after corresponding with the author (on Linux), I was missing the OTG cable for the two-phone trick. Eventually I got a 512 length unlock-key that I can use, so I’m saving it.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">6540246522D9A2C8EB...</code></pre></div>
<p>I wrote it into a binary-file to try <code>fastboot stage</code>.</p>
<pre><code>$ xxd token.bin 
00000000: 6540 2465 22d9 a2c8 eba3 89ce a2a7 a7ac  e@$e&quot;...........
00000010: f52d 43ff 10fc cb2c fced 2cc7 2cfb 13f7  .-C....,..,.,...
00000020: 658b cbce 9987 cad7 c311 9574 5937 23e2  e..........tY7#.
00000030: e8cb 5ae9 9319 8e76 55fc 0718 b7c6 a10a  ..Z....vU.......
00000040: 3d3a 7eb5 67de a47e 77fa b0b3 d63b 14c1  =:~.g..~w....;..
00000050: dd7a b400 af79 3c5f 429d 1bdd c53b bf0b  .z...y&lt;_B....;..
00000060: d9a5 a2d5 a30b 047d 3f4e 6bc3 e6b0 b0cf  .......}?Nk.....
00000070: b016 abfb 6e3d d457 08f0 afca 5700 4dfa  ....n=.W....W.M.
00000080: cdf0 fa5d 4857 6461 5d88 7fca dd25 6200  ...]HWda]....%b.
00000090: d219 4064 6285 57dc 80cd 0dee 9ca0 bf59  ..@db.W........Y
000000a0: d01a 48d3 e3df fa81 a65f 3ed7 00ba 7798  ..H......_&gt;...w.
000000b0: 6d2f 8f49 640d 262e b13b 1abc 006b b4dc  m/.Id.&amp;..;...k..
000000c0: 8dcb 187b cdb4 a4e0 050e 228d bede 3597  ...{......&quot;...5.
000000d0: 5646 c1ad b4d7 f006 1e74 30ba a444 579e  VF.......t0..DW.
000000e0: 9fa8 de74 eb4a 705b 705c e362 3393 78b9  ...t.Jp[p\.b3.x.
000000f0: 0a5c d72f aa5d 0d77 a2fd 62eb 657a 347f  .\./.].w..b.ez4.</code></pre>
<p>However, <code>fastboot oem unlock</code> still is not working:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="ex">fastboot</span> stage token.bin
<span class="ex">Sending</span> <span class="st">'token.bin'</span> (0 KB)                         <span class="ex">OKAY</span> [  0.005s]
<span class="ex">Finished.</span> Total time: 0.005s

$ <span class="ex">fastboot</span> oem unlock
<span class="ex">FAILED</span> (remote: <span class="st">'Unlock failed - Err:0xffffffff'</span>)
<span class="ex">fastboot</span>: error: Command failed</code></pre></div>
<p>The phone still manages to reboot though. I noticed that this is <code>512</code> bytes, same as <a href="https://github.com/bkerler/mtkclient/issues/110#issuecomment-975433985">bkerler/mtkclient#110 (comment)</a>. Tried overwriting the <code>devinfo</code> partition guessing from the comments, for what it is worth:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="ex">python</span> mtk w devinfo token.bin</code></pre></div>
<p>Not much luck with this either.</p>
<h2 id="restore">Restore</h2>
<p>To restore functionality, it suffices to just flash the previously saved <code>boot.img</code> in the boot partition. I had also overwritten the previous <code>system.img</code> with Postmarket’s built image - so I had to revert that change as well.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="ex">python</span> mtk w boot export/boot.img
$ <span class="ex">python</span> mtk w system export/system.img</code></pre></div>
<p>Hashes for verification match, no android corrupted messages this time on boot. The device lives another day. Further attempts could hard-brick the device, I’ll do it when I’m more informed.</p>
<h2 id="next-steps">Next steps</h2>
<p>What is undertaken here are very early steps. I feel overall better equipped than an enthusiast user who just followed XDA instructions 10 years ago and getting excited about the customizations.</p>
<p>I have collected a few more links for further reading:</p>
<ul>
<li><a href="https://tinyhack.com/2021/01/31/dissecting-a-mediatek-bootrom-exploit/">Dissecting a MediaTek BootROM exploit</a></li>
<li>Jonathan Levin: <a href="https://newandroidbook.com/Articles/aboot.html">Reverse Engineering Android’s Aboot</a></li>
<li>XDA: <a href="https://forum.xda-developers.com/t/info-boot-process-android-vs-linux.3785254/">BOOT PROCESS: ANDROID vs. LINUX</a></li>
<li>Android Image Kitchen: <a href="https://github.com/draekko/AIK-Linux">draekko/AIK-Linux</a></li>
<li><a href="https://android.googlesource.com/platform/external/avb/+/master/README.md">Android Verified Boot 2.0</a></li>
<li><a href="https://www.xda-developers.com/disable-system-app-bloatware-android/">How to disable any pre-installed system app bloatware on Android without root</a></li>
</ul>
<p>With regard to the Tecno Pova 3, I’ve found the following close relatives:</p>
<ul>
<li><a href="https://wiki.postmarketos.org/wiki/Volla_Phone_22_(volla-mimameid)">Volla Phone 22</a>, <a href="https://wiki.postmarketos.org/wiki/Volla_Phone_22_(volla-mimameid)/Hacking">Hacking</a></li>
<li><a href="https://github.com/mt6768-dev/android_kernel_xiaomi_mt6768">mt6768-dev/android_kernel_xiaomi_mt6768</a>
<ul>
<li><a href="https://github.com/Redmi-MT6768/android_kernel_xiaomi_mt6768">Redmi-MT6768/android_kernel_xiaomi_mt6768</a></li>
</ul></li>
</ul>
<p>The PostmarketOS and LineageOS efforts along smartphone hacking is also intended as a vessel to keep operating systems, kernel-engineering and surrounding skills sharp. Some exploitations to compromise devices and such would also be good learning and tools to add to my current arsenal. Expect to see more posts in this space!</p></div>
</div>


<div class="row">
    <div class="col">
        <p class="text-muted font-italic"> (Comments disabled. Email me instead.) </p>
    </div>
</div>

                    </div>
                </div>

                <div class="row">
                    <div class="col">
                        
<footer>
    <small>Site generated using <a href="http://jaspervdj.be/hakyll">Hakyll</a></small>
</footer>

                    </div>
                </div>
            </div>
        <script type="text/javascript" src="../static/js/init.js"></script>
    </body>
</html>
]]></summary>
</entry>
<entry>
    <title>Diagramming</title>
    <link href="http://jerinphilip.github.io/posts/diagramming.html" />
    <id>http://jerinphilip.github.io/posts/diagramming.html</id>
    <published>2023-08-24T00:00:00Z</published>
    <updated>2023-08-24T00:00:00Z</updated>
    <summary type="html"><![CDATA[<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta property="og:title" content="Diagramming" />
        <meta property="og:url" content="http://jerinphilip.github.io/posts/diagramming.html" />
        <title>Diagramming</title>
        <link rel="shortcut icon" href="../static/images/favicon.ico" type="image/x-icon">
        <link rel="stylesheet" href="../static/css/hack.css" />
        <link rel="stylesheet" href="../static/css/open-sans.css">
        <link rel="stylesheet" href="../static/css/font-awesome.min.css">
        <link rel="stylesheet" href="../static/css/tether.min.css" />
        <link rel="stylesheet" href="../static/css/bootstrap.min.css" />
        <link rel="stylesheet" href="../static/css/custom.css" />
        <link rel="stylesheet" href="../static/css/kate.css" />
        <link rel="stylesheet" href="../static/css/ekko-lightbox.css" />
        <script type="text/javascript" src="../static/js/jquery.min.js"></script>
        <script type="text/javascript" src="../static/js/tether.min.js"></script>
        <script type="text/javascript" src="../static/js/anchor.min.js"></script>
        <script type="text/javascript" src="../static/js/ekko-lightbox.min.js"></script>
        <script type="text/javascript" src="../static/js/bootstrap.min.js"></script>
        <script type="text/x-mathjax-config" src="../static/js/mathjax-config.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML"></script>
    </head>
    <body>
            <div class="container">
                <div class="row">
                    <div class="col">
                        <header>
    <span><a href="../">/home/jerin</a> </span>
    <!--
    <span><a href="/archive.html">posts</a></span>,
    <span><a href="/contact.html">contact</a></span>
    -->
</header>

                    </div>
                </div>
                <div class="row">
                    <div class="col">
                        <h1>Diagramming</h1>
                        <div class="row mb-4">
    <div class="post-info col">
        <div>Aug 24, 2023</div>

         

         
            <div><a href="../tags/posts/diagrams.html">diagrams</a>, <a href="../tags/posts/chalk.html">chalk</a>, <a href="../tags/posts/python.html">python</a>, <a href="../tags/posts/viz.html">viz</a></div>
         
    </div>
</div>

<div class="row">
    <div class="toc col-md-4 col-sm-12 order-md-second"><h6>Outline</h6><ul>
<li><a href="#toolbox">Toolbox</a></li>
<li><a href="#what-suits-my-usage">What suits my usage?</a></li>
<li><a href="#chalk-etudes">chalk etudes</a><ul>
<li><a href="#colors">Colors</a></li>
<li><a href="#translation">Translation</a></li>
<li><a href="#llvm-module">LLVM Module</a></li>
<li><a href="#torch-mlir">Torch MLIR</a></li>
</ul></li>
<li><a href="#concluding-thoughts">Concluding thoughts</a></li>
<li><a href="#references">References</a></li>
</ul></div><div class="col-md-8 col-sm-12 post-content order-md-first"><p>Over research spanning nearly 5+ years and programming spanning a decade, I’ve always remained curious and interested in diagrams. My interest, I think is mostly due to the fact that I’m a strong visual learner. It is very likely I have some learning impairment over audio, or that visual learning is, to me much easier and I want to short-circuit through that route. Consequently I find myself drawn to papers, articles or web-pages that <em>illustrate</em> an idea. See below for some illustrations I go wow over:</p>
<ul>
<li><a href="http://blog.ezyang.com/2019/05/pytorch-internals/">Edward Yang: PyTorch Internals</a></li>
<li><a href="https://siboehm.com/articles/22/CUDA-MMM">Simon Boehm: <em>How to Optimize a CUDA Matmul Kernel for cuBLAS-like Performance: a Worklog</em></a></li>
<li><a href="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/ELF_Executable_and_Linkable_Format_diagram_by_Ange_Albertini.png/1600px-ELF_Executable_and_Linkable_Format_diagram_by_Ange_Albertini.png">Wikipedia: ELF Executable and Linkable Format</a></li>
<li><a href="https://nlp.seas.harvard.edu/2018/04/03/attention.html">Alexander Rush: The Annotated Transformer</a></li>
<li><a href="https://minitorch.github.io/">Alexander Rush: Minitorch series</a></li>
<li>Christopher Olah:
<ul>
<li><a href="https://distill.pub/">distill.pub</a></li>
<li><a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTM Networks</a>, and most of his blog.</li>
</ul></li>
<li><a href="http://hendrik.strobelt.com/">Hendrik Strobelt</a>: Papers and demos.</li>
<li><a href="https://jvns.ca/teach-tech-with-cartoons/">Julia Evans: Teach Tech with cartoons</a></li>
</ul>
<p>Converging on a set of tools to visualize things with the polished finish that I desire has been ongoing. Usually, making figures or diagrams are secondary to the main task in hand that generates revenue or reward. This is one reason I haven’t had allocated time or resources to improve this dimension in a while. Where these interest and skills I have and nurture best synergized in the past when I had to make diagrams for publications. I hope to revitalize, continue keeping these skills sharp and useful through posts here.</p>
<h2 id="toolbox">Toolbox</h2>
<p>I have encountered and tried several tools over the years. To enumerate a few notable among these:</p>
<ol style="list-style-type: decimal">
<li>Presentation Software: PowerPoint, <a href="https://slides.google.com">Google Slides</a></li>
<li>Drawing software: <a href="https://xournal.sourceforge.net/">Xournal</a> / <a href="https://xournalpp.github.io/">Xournalpp</a></li>
<li>Declarative:
<ol style="list-style-type: lower-alpha">
<li><a href="https://graphviz.org/">GraphViz</a>, the dot language.</li>
<li><a href="https://archives.haskell.org/projects.haskell.org/diagrams/gallery.html">Diagrams</a>, a haskell library.</li>
<li><a href="https://github.com/chalk-diagrams/chalk">chalk</a>: A python port of diagrams.</li>
<li><a href="http://mermaid.js.org/">Mermaid</a>: Embedded in markdown</li>
<li><a href="https://www.overleaf.com/learn/latex/Pgfplots_package">pgfplots</a>: LaTeX</li>
</ol></li>
<li>Embedding in web-pages: <a href="http://mermaid.js.org/">d3.js</a></li>
<li>Vector Graphics:
<ol style="list-style-type: lower-alpha">
<li><a href="https://inkscape.org/">Inkscape</a></li>
<li><a href="https://excalidraw.com/">Excalidraw</a></li>
<li><a href="https://draw.io">draw.io</a></li>
</ol></li>
</ol>
<p>Note that the above are different from <em>plotting</em>, for plotting I prefer <em>matplotlib</em> with some <a href="https://github.com/jbmouret/matplotlib_for_papers">custom theming</a>, d3.js for web-pages. Feel like trying <a href="https://observablehq.com/">Observable</a> at some point of time.</p>
<h2 id="what-suits-my-usage">What suits my usage?</h2>
<p>It’s unlikely that there is a <em>one size fits all</em> choice. I bin my usages into four categories and explain the reasoning behind my choices below:</p>
<p><strong>Whiteboarding</strong> Sometimes I just want to quick and dirty discuss a concept to a colleague or someone over call. The quality of the figure is not important - the legibility is. The more dimensions I can add (2D, 3D, color) and more primitives I have to work with (freehand pen/paper vs palette with shape primitives). I find <a href="https://xournalpp.github.io/">Xournalpp</a> most convenient here. To be honest any decent drawing application would do - <a href="https://jamboard.google.com/?pli=1">Jamboard</a> during google-meets, <a href="https://apps.microsoft.com/store/detail/microsoft-whiteboard/9MSPC6MP8FM4?hl=en-in&amp;gl=in&amp;rtc=1">Whiteboard</a> on Windows. What actually makes life easy here for me is a pen/canvas equivalent, and higher order primitives. I own a basic Wacom - <a href="https://www.amazon.in/Wacom-CTL-472-6-inch-3-5-inch-Graphic/dp/B078HRR1XV">Wacom CTL 472</a>. An iPad + Pencil would be a decent addition, I think. But I already have a thin laptop and the tablet which suffices, so I never ended up splurging on the iPad. In real-life, at physical meetings a whiteboard with some colored marker pens I have often found convenient in the past.</p>
<p><strong>Web, with animations</strong> I have used <em>d3.js</em> in the past and will find myself picking it up again should the need arises. Animation and dynamic user-interaction is an extra dimension to visualization. I have used the interactivity in the past to inspect translations better than I would be able to do manually on a text-file or pasting these over slides - see <a href="https://jerinphilip.github.io/d3-sandbox/exps/bleu-compare/">bleu-compare</a> for an example. More d3 experiments are present in <a href="https://jerinphilip.github.io/d3-sandbox/">d3-sandbox</a>, feel free to have a look. The diagrams for <a href="../posts/alignment-manipulations-pivoting-mt.html">alignment manipulations</a> is generated by code using <em>d3.js</em>, repurposed from a distill publication.</p>
<p><strong>Publication Grade</strong> One downside of hand-drawings is that they don’t scale well. Vector Graphics however, does. And this is a good to have (I’d claim a <em>necessity</em>) to make polished diagrams. There is usually not much interactivity in diagrams that go on venues that accept papers. My strong preference here used to be inkscape. I have used presentation software for quick and okay before, but inkspace has a nice set of defaults, provides finer control. I am trying to replace this process with <a href="https://github.com/chalk-diagrams/chalk">chalk</a>, followed by manual refining with inkscape.</p>
<p><strong>Programmatic Generation</strong> The above section discusses making static diagrams. Sometimes, this is not a luxury when the diagram is made from a lot of nodes (clusters, computation-graphs, call-graphs). Mostly because layouting can no longer be done manually, and manual command over everything no longer remains an advantage. When it comes to such tasks - I prefer <em>GraphViz</em>’s automatic layouting, or force layout from <code>d3.js</code>. These usually rarely go into papers, sometimes work for web-demos.</p>
<p>The rest of this post is me trying declarative drawing by a combination of chalk-diagrams and possible refinement through inkscape - trying to learn and practice my new preferred tooling.</p>
<h2 id="chalk-etudes">chalk etudes</h2>
<p>Inspired by <a href="https://github.com/norvig/pytudes">pytudes</a>, which in turn is inspired by <a href="https://books.google.com/books/about/Etudes_for_programmers.html?id=u89WAAAAMAAJ">Etudes for Programmers</a> by <a href="https://books.google.com/books/about/Etudes_for_programmers.html?id=u89WAAAAMAAJ">Charles Wetherell</a>, I’m going to set out to try and practice making diagrams. Bunch of them are for future blogposts here. Some just for fun to push the limits.</p>
<h3 id="colors">Colors</h3>
<p>To get some good colors for the boxes which forms diagrams, I need some good color-sets. I’m going to pull it from matplotlib - mostly the <a href="https://matplotlib.org/stable/tutorials/colors/colormaps.html#qualitative">qualitative sets</a>. To verify that the color values pulled render properly, all I had to to do was <code>hcat</code> a few colors and <code>vcat</code> the sets.</p>
<p><img src="../static/images/diagram-etudes/qualitative.svg" width="100%" /></p>
<p>The <em>qualitative</em> colors palette allows for this post to be a little more colorful than usual.</p>
<h3 id="translation">Translation</h3>
<p>I have spent nearly 5 years working adjacent to machine translation. Find below a trip down memory lane touching a few concepts, also intended for a future blogpost.</p>
<p><strong>Encoder Decoder</strong> Below is a more complex rendering via <em>chalk</em> of a sequence-to-sequence translation process diagram. Color palette pulled before helps make it look nicer, or so I claim.</p>
<p><img src="../static/images/diagram-etudes/encdec.svg" width="100%" /></p>
<p>There are repeating elements in this diagram - the decoding process. The code to generate this is a simple for-loop, which is one of the things I like about <em>chalk</em> over inkspace. I can loop to reuse repeating elements, and also control the spacing and positioning to a more exact degree. Usually working with presentation software or inkspace there are the following options that have to be used a lot:</p>
<ol style="list-style-type: decimal">
<li>Align - Left, Right, Top, Bottom</li>
<li>Distribute - Horizontally, Vertically.</li>
</ol>
<p>Moving things around manually sometimes feel repetitive. I chalk, the control over positioning feels like an improvement.</p>
<p><strong>RNNs</strong> There are nice illustrations of variants of RNN by <a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">Chris Olah</a>, that I used to read. I found these very useful when getting started with deep-learning. Below I reproduce two.</p>
<p>The following denotes the time-series unroll of a recurrent neural network.</p>
<p><img src="../static/images/diagram-etudes/rnn_steps.svg" width="100%" /></p>
<p>There are not many elements to loop over, but it’s noticable how this unroll can also be specified by a loop.</p>
<p><strong>Simpler Simple Recurrent Units</strong> I’m not going to redo the existing RNN diagrams. Instead, I render a variant that does not probably have a diagram anywhere to be found online, but is used in models I have worked with for <a href="https://github.com/browsermt/students">Bergamot Project</a>. The equations are available in <span class="citation">Kim et al. (<a href="#ref-kim2019research">2019</a>)</span>.</p>
<p><img src="../static/images/diagram-etudes/ssru.svg" width="100%" /></p>
<p><strong>Attention</strong> The landmark paper <em>Attention is all you need</em> paper (<span class="citation">Vaswani et al. (<a href="#ref-vaswani2017attention">2017</a>)</span>) has two or three nice diagrams. Find <em>Scaled Dot Product Attention</em> (SDPA) and <em>MultiHead Attention</em> (MHA) below, reproduced similar to the rendering in the paper.</p>
<p><img src="../static/images/diagram-etudes/sdpa.svg" width="30%" /> <img src="../static/images/diagram-etudes/mha.svg" width="69%" /></p>
<p>The diagrams are not an exact match, but gets close surprisingly fast. I found adding depth (heads) and configuring same kind of elements together as a whole more convenient than how I would’ve done it in inkscape.</p>
<h3 id="llvm-module">LLVM Module</h3>
<p>I have been trying to read up on compilers space. Sometime back, while reading LLVM, watching videos and <a href="https://github.com/jerinphilip/kaleidoscope/">implementing parts</a> of <a href="https://llvm.org/docs/tutorial/MyFirstLanguageFrontend/index.html"><em>Kaleidoscope</em></a>, the toy compiler, I went on a detour to <a href="https://github.com/jerinphilip/kaleidoscope/blob/a3f941dd1d7d3e79bdd11e7744b290531571114c/scripts/diagrams.py">experiment with a chalk-diagram</a> for <a href="https://youtu.be/m8G_S5LwlTo?t=305">a slide</a> I encountered from an LLVM Talk: <a href="https://youtu.be/m8G_S5LwlTo">2019 EuroLLVM Developers’ Meeting: V. Bridgers &amp; F. Piovezan “LLVM IR Tutorial - Phis, GEPs …”</a></p>
<p><img src="../static/images/diagram-etudes/llvm_skeleton.svg" width="100%" /></p>
<p>Colors could’ve been better, but I did manage to render this fast, which got me hooked on <em>chalk</em> in the first place. Now that we’re here on a bigger blogpost, sharing the origin story seems nice.</p>
<h3 id="torch-mlir">Torch MLIR</h3>
<p>I found <a href="https://github.com/llvm/torch-mlir/blob/main/docs/images/architecture.png">this diagram</a> while reading up on torch-mlir. Few more elements - <em>dashed lines</em>, aligned text on both sides. An attempt to replicate using chalk-diagrams got me as far as below:</p>
<p><img src="../static/images/diagram-etudes/torch_mlir_arch.svg" width="60%" /></p>
<h2 id="concluding-thoughts">Concluding thoughts</h2>
<p>For those who want to take a further dive - please find the source at <a href="https://github.com/jerinphilip/chalk-gallery/">jerinphilip/chalk-gallery</a>. The source is not in the best of states - I’m learning a new library, so best-practices are still iterations away. Excuse the poor quality, I will not let <em>perfect</em> be the enemy of <em>publishing</em>. I will keep the etudes section of this post a live document, and update it with future rendering practices.</p>
<p>I think the <a href="https://en.wikipedia.org/wiki/Kolmogorov_complexity">Kolgomorov complexity</a> for an output diagram like the ones above (which are created using repetition) will be minimal in a programming language - in this case, Python. It’s going to be better than SVG, and therefore using inkscape. The reasoning that follows is that I will be more productive and better equipped here in comparison to inkscape, once I get past the learning curve.</p>
<p>Expect more additions and cleanups to <a href="https://github.com/jerinphilip/chalk-gallery/">jerinphilip/chalk-gallery</a> along with more posts in this blog coming ahead!</p>
<h2 id="references">References</h2>
<p><a href="https://anvaka.github.io/sj/compare/">Imperative vs Declarative drawing API</a></p>
<div id="refs" class="references">
<div id="ref-kim2019research">
<p>Young Jin Kim, Marcin Junczys-Dowmunt, Hany Hassan Awadalla, Alham Fikri Aji, Kenneth Heafield, Roman Grundkiewicz, and Nikolay Bogoychev. 2019. From research to production and back: Ludicrously fast neural machine translation. In <em>Proceedings of the 3rd workshop on neural generation and translation</em>, pages 280–288.</p>
</div>
<div id="ref-vaswani2017attention">
<p>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In <em>Advances in neural information processing systems</em>, pages 5998–6008.</p>
</div>
</div></div>
</div>


<div class="row">
    <div class="col">
        <p class="text-muted font-italic"> (Comments disabled. Email me instead.) </p>
    </div>
</div>

                    </div>
                </div>

                <div class="row">
                    <div class="col">
                        
<footer>
    <small>Site generated using <a href="http://jaspervdj.be/hakyll">Hakyll</a></small>
</footer>

                    </div>
                </div>
            </div>
        <script type="text/javascript" src="../static/js/init.js"></script>
    </body>
</html>
]]></summary>
</entry>
<entry>
    <title>slimt: Making of</title>
    <link href="http://jerinphilip.github.io/posts/making-of-slimt.html" />
    <id>http://jerinphilip.github.io/posts/making-of-slimt.html</id>
    <published>2023-08-12T00:00:00Z</published>
    <updated>2023-08-12T00:00:00Z</updated>
    <summary type="html"><![CDATA[<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta property="og:title" content="slimt: Making of" />
        <meta property="og:url" content="http://jerinphilip.github.io/posts/making-of-slimt.html" />
        <title>slimt: Making of</title>
        <link rel="shortcut icon" href="../static/images/favicon.ico" type="image/x-icon">
        <link rel="stylesheet" href="../static/css/hack.css" />
        <link rel="stylesheet" href="../static/css/open-sans.css">
        <link rel="stylesheet" href="../static/css/font-awesome.min.css">
        <link rel="stylesheet" href="../static/css/tether.min.css" />
        <link rel="stylesheet" href="../static/css/bootstrap.min.css" />
        <link rel="stylesheet" href="../static/css/custom.css" />
        <link rel="stylesheet" href="../static/css/kate.css" />
        <link rel="stylesheet" href="../static/css/ekko-lightbox.css" />
        <script type="text/javascript" src="../static/js/jquery.min.js"></script>
        <script type="text/javascript" src="../static/js/tether.min.js"></script>
        <script type="text/javascript" src="../static/js/anchor.min.js"></script>
        <script type="text/javascript" src="../static/js/ekko-lightbox.min.js"></script>
        <script type="text/javascript" src="../static/js/bootstrap.min.js"></script>
        <script type="text/x-mathjax-config" src="../static/js/mathjax-config.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML"></script>
    </head>
    <body>
            <div class="container">
                <div class="row">
                    <div class="col">
                        <header>
    <span><a href="../">/home/jerin</a> </span>
    <!--
    <span><a href="/archive.html">posts</a></span>,
    <span><a href="/contact.html">contact</a></span>
    -->
</header>

                    </div>
                </div>
                <div class="row">
                    <div class="col">
                        <h1>slimt: Making of</h1>
                        <div class="row mb-4">
    <div class="post-info col">
        <div>Aug 12, 2023</div>

         

         
            <div><a href="../tags/posts/mt.html">mt</a>, <a href="../tags/posts/ml.html">ml</a>, <a href="../tags/posts/bergamot.html">bergamot</a></div>
         
    </div>
</div>

<div class="row">
    <div class="toc col-md-4 col-sm-12 order-md-second"><h6>Outline</h6><ul>
<li><a href="#the-task">The task</a></li>
<li><a href="#approach">Approach</a><ul>
<li><a href="#python">Python</a></li>
<li><a href="#debugger">Debugger</a></li>
<li><a href="#breakthrough-hack">Breakthrough hack</a></li>
<li><a href="#tracing-execution">Tracing execution</a></li>
</ul></li>
<li><a href="#finishing-up">Finishing up</a></li>
<li><a href="#references">References</a></li>
</ul></div><div class="col-md-8 col-sm-12 post-content order-md-first"><p>This post is about the development of <a href="https://github.com/jerinphilip/slimt">slimt</a>, software I have been working on for the past 10-days or so. It’s slim machine-translation (MT) inference code. It was fun doing it, and some bits along the journey documentable.</p>
<p><strong>Flashback</strong> One of the first things I was tasked with starting undergraduate research at university was to move an Optical Character Recognition (OCR) library from C++ to Python. This was circa 2015 - PyTorch was new, TensorFlow was dark magic research seniors rejected in favour of PyTorch. But surprise, what the lab had powering it’s document research efforts was <a href="https://sourceforge.net/p/rnnl/wiki/Home/">rnnlib</a>. Story goes that some researcher managed to get it to work, and it’s been powering text-recognition ever since. Training was on CPUs, the library predated <a href="https://www.image-net.org/challenges/LSVRC/2012/">ImageNet</a>. But Bidirectional LSTMs were the best the lab had back then.</p>
<p>I went ahead, checked the source-code and reported back we should just do it in PyTorch. Back then I’d blame lack of documentation and a missing map to the source-code. My advisor, unsurprisingly held on to the requirement - <em>it’s just a bunch of matrix multiplies, why is it so hard to move from C++ to Python?</em> Basically I had to find the parts where the said matrices showed up in code and use it - except it was taking long. I tried a lot of stuff - used Doxygen to generate diagrams, opened up source files based on names. Tried to step through the GDB debugger to find which lines of source where getting executed. I’d be naive and go back and report these things to my advisor who mostly works in computer vision to see <a href="https://austinhenley.com/blog/lessonsfrommyphd.html#unmotivateddetails">blank faces all the time</a>. The efforts didn’t succeed (or we did not wait for it rather).</p>
<p>On the bright side, I did learn quite a bit of C++ tooling and developed some interest in the area. Fast forward 5 years, I have moved from Python machine learning training to AI inference and learning to write machine learning frameworks and had come full circle to a similar task.</p>
<h2 id="the-task">The task</h2>
<p>A task pending long in my to-do list is polish <a href="https://github.com/jerinphilip/lemonade">lemonade</a>, a translation input method engine for easier use. The blocker was that the input-method kept hanging on language-switches, and I could not reason with the large bergamot-source why it was happening. I was procrastinating diving deeper, until contemporary efforts such as <a href="https://github.com/ggerganov/ggml">ggerganov/ggml</a> and <a href="https://github.com/karpathy/llama2.c">karpathy/llama2.c</a> got me thinking - wouldn’t my translation inference only need specialized code for just one class of models?</p>
<p>The models are transformers with only minor modifications. The <a href="https://github.com/browsermt/students/tree/master/deen">tiny11</a> class of models are actually quite small after 8-bit quantization - <code>ende.student.tiny11</code> is 17MB on my system. marian-dev is source-code I’d been lurking around for about 2 years.</p>
<p>bergamot-translator builds on top of marian-dev and uses the inference code-path from marian-dev. While marian is a a capable neural network library with focus on machine translation, all the bells and whistles that come with it are not necessary to run inference on client-machines (e.g: autograd, multiple sequence-to-sequence architecture support, beam-search). When I started marian used to be a monstrous 30 minute compile on my laptop, which I brought down using ccache and <a href="../posts/ccache.html">wrote about</a> - stripping the code to only inference would make that look lame and useless. I would not even need ccache anymore.</p>
<p>So - write an own transformer forward pass, bring compile-times down like crazy, reduce source-complexity*, minimize dependencies, get something of possible value out of it - lot of boxes were checking themselves. Be a shame if I decided not to give it a go, especially given all the free-time I have.</p>
<p>So, there’s a clear destination - the approach and path still had elements of uncertainties. This is essentially the same task as 7 years ago - produce new inference code for a model trained from a library.</p>
<h2 id="approach">Approach</h2>
<p>I had some angles in mind - (1) inspect the model binary, (2) step through a debugger checking activated paths, understand the logic behind and then implement. Copying code was okay (and a requirement, since the code computing float operations had to match), so we’d have it slightly easier.</p>
<h3 id="python">Python</h3>
<p>I thought of projecting 8-bit <code>int</code> to 32-bit <code>float</code> and doing the operations in PyTorch for a faster first iteration. Once there was clarity in the network architecture and I managed to realize it fast and verify with Python, implementing C++ should be easier - was the thinking.</p>
<p>I <a href="https://gist.github.com/jerinphilip/670495fca010b2cde4f34091fcb1f5d3">wrote a quick script</a> to load the model in Python.</p>
<p><details><summary> <code>model.bin</code> (truncated) </summary></p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">Item(Wemb, intgemm8, Shape([<span class="dv">32000</span>, <span class="dv">256</span>]), <span class="dv">8192256</span>)
Item(Wemb_QuantMultA, intgemm8, Shape([<span class="dv">1</span>, <span class="dv">1</span>]), <span class="dv">256</span>)
Item(decoder_ff_logit_out_b, float32, Shape([<span class="dv">1</span>, <span class="dv">32000</span>]), <span class="dv">128000</span>)
Item(decoder_l1_context_Wk, intgemm8, Shape([<span class="dv">256</span>, <span class="dv">256</span>]), <span class="dv">65792</span>)
...
Item(decoder_l1_ffn_b2, float32, Shape([<span class="dv">1</span>, <span class="dv">256</span>]), <span class="dv">1024</span>)
Item(decoder_l1_ffn_ffn_ln_bias, float32, Shape([<span class="dv">1</span>, <span class="dv">256</span>]), <span class="dv">1024</span>)
Item(decoder_l1_ffn_ffn_ln_scale, float32, Shape([<span class="dv">1</span>, <span class="dv">256</span>]), <span class="dv">1024</span>)
Item(decoder_l1_rnn_W, intgemm8, Shape([<span class="dv">256</span>, <span class="dv">256</span>]), <span class="dv">65792</span>)
Item(decoder_l1_rnn_W_QuantMultA, float32, Shape([<span class="dv">1</span>, <span class="dv">1</span>]), <span class="dv">256</span>)
...
Item(decoder_l2_context_Wq, intgemm8, Shape([<span class="dv">256</span>, <span class="dv">256</span>]), <span class="dv">65792</span>)
Item(decoder_l2_context_Wq_QuantMultA, float32, Shape([<span class="dv">1</span>, <span class="dv">1</span>]), <span class="dv">256</span>)
Item(decoder_l2_context_Wv, intgemm8, Shape([<span class="dv">256</span>, <span class="dv">256</span>]), <span class="dv">65792</span>)
Item(decoder_l2_context_Wv_QuantMultA, float32, Shape([<span class="dv">1</span>, <span class="dv">1</span>]), <span class="dv">256</span>)
Item(decoder_l2_context_bk, float32, Shape([<span class="dv">1</span>, <span class="dv">256</span>]), <span class="dv">1024</span>)
Item(decoder_l2_context_bo, float32, Shape([<span class="dv">1</span>, <span class="dv">256</span>]), <span class="dv">1024</span>)
...
Item(encoder_l1_ffn_W1, intgemm8, Shape([<span class="dv">256</span>, <span class="dv">1536</span>]), <span class="dv">393472</span>)
Item(encoder_l1_ffn_W1_QuantMultA, float32, Shape([<span class="dv">1</span>, <span class="dv">1</span>]), <span class="dv">256</span>)
Item(encoder_l1_ffn_b1, float32, Shape([<span class="dv">1</span>, <span class="dv">1536</span>]), <span class="dv">6144</span>)
...
Item(encoder_l1_ffn_ffn_ln_bias, float32, Shape([<span class="dv">1</span>, <span class="dv">256</span>]), <span class="dv">1024</span>)
Item(encoder_l1_ffn_ffn_ln_scale, float32, Shape([<span class="dv">1</span>, <span class="dv">256</span>]), <span class="dv">1024</span>)
Item(encoder_l1_self_Wk, intgemm8, Shape([<span class="dv">256</span>, <span class="dv">256</span>]), <span class="dv">65792</span>)
Item(encoder_l1_self_Wk_QuantMultA, float32, Shape([<span class="dv">1</span>, <span class="dv">1</span>]), <span class="dv">256</span>)</code></pre></div>
<p></details></p>
<p>Some things make sense. There are attention layers, feed-forward networks, RNNs, and output layer, some layernorm. I have the flat data, not the structure. I was hoping to recover neural network structure from a research or system-description paper of some sort. I checked <span class="citation">Kim et al. (<a href="#ref-kim2019research">2019</a>)</span>, there’s some mention of the RNN (SSRU), but a network diagram is missing. I could do further level searches on papers this paper was referring to. Without the structure, it would be difficult to reproduce in Python. I’ll also need some tooling to verify I’m on the right path. So I decided to see if throwing the debugger at this problem and stepping through would provide some information I could use. After-all, code was <a href="https://www.commitstrip.com/wp-content/uploads/2016/08/Strip-Les-specs-cest-du-code-650-finalenglish.jpg">absolute truth</a>.</p>
<h3 id="debugger">Debugger</h3>
<p>IDEs back in 2015 when I took on the previous porting had as well I’d guess. But back then I knew only <code>gdb</code> and mostly used vim. I still do use vim most of the time, and VSCode with an vim emulation layer. VSCode has a nice debugger. I currently use <a href="https://vscodium.com/">VSCodium</a>, which is a fork. Internally, VSCode uses <code>gdb</code>, but it’s easier to move around and inspect.</p>
<p>Starting with bergamot’s <code>translateBatch</code> entrypoint, I jumped to function definitions and checked a few call-stacks. Created a script to link and save, as I unrolled the code while porting. See a few examples below.</p>
<details><summary> Embedding (index_select) </summary>
<pre>
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/tensors/cpu/tensor_operators.cpp#L565">marian::cpu::CopyRows</a>(marian::Tensor out_, const marian::Tensor in_, const marian::Tensor indices) 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/tensors/tensor_operators.h#L217">marian::CopyRows</a>(marian::Tensor arg1, const marian::Tensor arg2, const marian::Tensor arg3) 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/graph/node_operators_binary.h#L672">marian::RowsNodeOp::forwardOps()::{lambda()#1}::operator()() const</a>(const struct {...} * const __closure) 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/graph/node.h#L64">marian::Node::runForward(std::vector<std::function<void ()>, std::allocator<std::function<void ()> > > const&)</a>(marian::Node * const this, const marian::NodeOps & ops) 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/graph/node.cpp#L67">marian::Node::forward</a>(marian::Node * const this) 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/graph/expression_graph.cpp#L114">marian::ExpressionGraph::forward</a>(marian::ExpressionGraph * const this, std::__cxx11::list<IntrusivePtr<marian::Chainable<IntrusivePtr<marian::TensorBase> > >, std::allocator<IntrusivePtr<marian::Chainable<IntrusivePtr<marian::TensorBase> > > > > & forwardTape, bool finalPass) 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/graph/expression_graph.cpp#L101">marian::ExpressionGraph::forwardNext</a>(marian::ExpressionGraph * const this) 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/graph/expression_graph.h#L246">marian::ExpressionGraph::forward</a>(marian::ExpressionGraph * const this) 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/translator/beam_search.cpp#L451">marian::BeamSearch::search</a>(marian::BeamSearch * const this, marian::Ptr graph, marian::Ptr batch) 
<a href="../home/jerin/code/bergamot-translator/src/translator/translation_model.cpp#L186">marian::bergamot::TranslationModel::translateBatch</a>(marian::bergamot::TranslationModel * const this, marian::bergamot::Workspace & workspace, marian::bergamot::Batch & batch)</pre>
<p></details></p>
<details><summary> Positional Embeddings </summary>
<pre>
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/graph/node_initializers.cpp#L216">marian::inits::sinusoidalPositionEmbeddings</a>(int start) 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/models/transformer.h#L105">marian::Transformer<marian::EncoderBase>::addPositionalEmbeddings</a>(const marian::Transformer<marian::EncoderBase> * const this, marian::Expr input, int start, bool trainPosEmbeddings) 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/models/transformer.h#L117">marian::Transformer<marian::EncoderBase>::addSpecialEmbeddings</a>(const marian::Transformer<marian::EncoderBase> * const this, marian::Expr input, int start) 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/models/transformer.h#L555">marian::EncoderTransformer::apply</a>(marian::EncoderTransformer * const this, marian::Ptr batch) 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/models/transformer.h#L543">marian::EncoderTransformer::build</a>(marian::EncoderTransformer * const this, marian::Ptr graph, marian::Ptr batch) 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/models/encoder_decoder.cpp#L187">marian::EncoderDecoder::startState</a>(marian::EncoderDecoder * const this, marian::Ptr graph, marian::Ptr batch) 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/models/costs.h#L357">marian::models::Stepwise::startState</a>(marian::models::Stepwise * const this, marian::Ptr graph, marian::Ptr batch) 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/translator/scorers.h#L126">marian::ScorerWrapper::startState</a>(marian::ScorerWrapper * const this, marian::Ptr graph, marian::Ptr batch) 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/translator/beam_search.cpp#L280">marian::BeamSearch::search</a>(marian::BeamSearch * const this, marian::Ptr graph, marian::Ptr batch) 
<a href="../home/jerin/code/bergamot-translator/src/translator/translation_model.cpp#L186">marian::bergamot::TranslationModel::translateBatch</a>(marian::bergamot::TranslationModel * const this, marian::bergamot::Workspace & workspace, marian::bergamot::Batch & batch) 
<a href="../home/jerin/code/bergamot-translator/src/translator/service.cpp#L149">operator()</a>(const struct {...} * const __closure)
</pre>
<p></details></p>
<details><summary> Encoder forward </summary>
<pre>
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/models/transformer.h#L548">marian::EncoderTransformer::apply</a>(marian::EncoderTransformer * const this, marian::Ptr batch) 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/models/transformer.h#L540">marian::EncoderTransformer::build</a>(marian::EncoderTransformer * const this, marian::Ptr graph, marian::Ptr batch) 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/models/encoder_decoder.cpp#L187">marian::EncoderDecoder::startState</a>(marian::EncoderDecoder * const this, marian::Ptr graph, marian::Ptr batch) 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/models/costs.h#L357">marian::models::Stepwise::startState</a>(marian::models::Stepwise * const this, marian::Ptr graph, marian::Ptr batch) 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/translator/scorers.h#L126">marian::ScorerWrapper::startState</a>(marian::ScorerWrapper * const this, marian::Ptr graph, marian::Ptr batch) 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/translator/beam_search.cpp#L280">marian::BeamSearch::search</a>(marian::BeamSearch * const this, marian::Ptr graph, marian::Ptr batch) 
<a href="../home/jerin/code/bergamot-translator/src/translator/translation_model.cpp#L186">marian::bergamot::TranslationModel::translateBatch</a>(marian::bergamot::TranslationModel * const this, marian::bergamot::Workspace & workspace, marian::bergamot::Batch & batch) 
<a href="../home/jerin/code/bergamot-translator/src/translator/service.cpp#L149">operator()</a>(const struct {...} * const __closure)
</pre>
<p></details></p>
<details><summary> transposed log mask </summary>
<pre>
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/models/transformer.h#L132">marian::Transformer<marian::EncoderBase>::transposedLogMask</a>(marian::Expr mask) 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/models/transformer.h#L569">marian::EncoderTransformer::apply</a>(marian::EncoderTransformer * const this, marian::Ptr batch) 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/models/transformer.h#L540">marian::EncoderTransformer::build</a>(marian::EncoderTransformer * const this, marian::Ptr graph, marian::Ptr batch) 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/models/encoder_decoder.cpp#L187">marian::EncoderDecoder::startState</a>(marian::EncoderDecoder * const this, marian::Ptr graph, marian::Ptr batch) 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/models/costs.h#L357">marian::models::Stepwise::startState</a>(marian::models::Stepwise * const this, marian::Ptr graph, marian::Ptr batch) 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/translator/scorers.h#L126">marian::ScorerWrapper::startState</a>(marian::ScorerWrapper * const this, marian::Ptr graph, marian::Ptr batch) 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/translator/beam_search.cpp#L280">marian::BeamSearch::search</a>(marian::BeamSearch * const this, marian::Ptr graph, marian::Ptr batch) 
<a href="../home/jerin/code/bergamot-translator/src/translator/translation_model.cpp#L186">marian::bergamot::TranslationModel::translateBatch</a>(marian::bergamot::TranslationModel * const this, marian::bergamot::Workspace & workspace, marian::bergamot::Batch & batch) 
<a href="../home/jerin/code/bergamot-translator/src/translator/service.cpp#L149">operator()</a>(const struct {...} * const __closure)
</pre>
<p></details></p>
<details> <summary> postprocess: Applied after each FFN (Takes care of skip, off dropout and LayerNorm) </summary>
<pre>
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/models/transformer.h#L181">marian::Transformer<marian::EncoderBase>::postProcess</a>(const marian::Transformer<marian::EncoderBase> * const this, std::string prefix, std::string ops, marian::Expr input, marian::Expr prevInput, float dropProb) 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/models/transformer.h#L372">marian::Transformer<marian::EncoderBase>::LayerAttention</a>(marian::Transformer<marian::EncoderBase> * const this, std::string prefix, marian::Expr input, const marian::Expr & keys, const marian::Expr & values, const marian::Expr & mask, int dimHeads, bool cache, bool saveAttentionWeights) 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/models/transformer.h#L575">marian::EncoderTransformer::apply</a>(marian::EncoderTransformer * const this, marian::Ptr batch) 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/models/transformer.h#L540">marian::EncoderTransformer::build</a>(marian::EncoderTransformer * const this, marian::Ptr graph, marian::Ptr batch) 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/models/encoder_decoder.cpp#L187">marian::EncoderDecoder::startState</a>(marian::EncoderDecoder * const this, marian::Ptr graph, marian::Ptr batch) 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/models/costs.h#L357">marian::models::Stepwise::startState</a>(marian::models::Stepwise * const this, marian::Ptr graph, marian::Ptr batch) 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/translator/scorers.h#L126">marian::ScorerWrapper::startState</a>(marian::ScorerWrapper * const this, marian::Ptr graph, marian::Ptr batch) 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/translator/beam_search.cpp#L280">marian::BeamSearch::search</a>(marian::BeamSearch * const this, marian::Ptr graph, marian::Ptr batch) 
<a href="../home/jerin/code/bergamot-translator/src/translator/translation_model.cpp#L186">marian::bergamot::TranslationModel::translateBatch</a>(marian::bergamot::TranslationModel * const this, marian::bergamot::Workspace & workspace, marian::bergamot::Batch & batch) 
<a href="../home/jerin/code/bergamot-translator/src/translator/service.cpp#L149">operator()</a>(const struct {...} * const __closure)
</pre>
<p></details></p>
<p>I quickly discovered the code-paths that were consistently getting activated when I ran input through, and discovered some of the realizations in code of the transformer network discussed in the paper. but this process was slower than what I’d wished for. Success was viable with this particular angle, just not fast enough. I needed something faster.</p>
<h3 id="breakthrough-hack">Breakthrough hack</h3>
<p>During this process, I discovered the <a href="https://github.com/browsermt/marian-dev/blob/aa0221e687fe8b3b69b5bb64279d4349663ad410/src/common/definitions.h#L14"><code>NodeOp</code></a> macro, which looked as follows.</p>
<div class="sourceCode"><pre class="sourceCode cpp"><code class="sourceCode cpp"><span class="pp">#define NodeOp(op) [=]() { op; }</span></code></pre></div>
<p>For some reason, marian was using this to describe forward and backward in the computational graph, mostly consistently. Since searching for, finding the macro, manually putting the breakpoint wasn’t cutting it - I quickly googled if I could programmatically stop for debugger. Turns out, I can - <code>std::raise(SIGTRAP)</code>.</p>
<p>The operating system notifies the debugger on <code>SIGTRAP</code> signal (if no debugger listening to handle, the program simply exits). The debugger can map the instruction pointer to the line in source both ways (provided compiled with <code>-g</code> and ideally, <code>-O0</code>, which is <code>-DCMAKE_BUILD_TYPE=Debug</code>).</p>
<p>I set a programmatic breakpoint and tried to extract call-stack programmatically as well:</p>
<div class="sourceCode"><pre class="sourceCode cpp"><code class="sourceCode cpp"><span class="pp">#define NodeOp(op)                                                  </span>\
<span class="pp">  [=]() {                                                           </span>\
<span class="pp">    std::raise(SIGTRAP);                                            </span>\
<span class="pp">    std::string callstack = marian::getCallStack(/*skipLevels=*/3); </span>\
<span class="pp">    std::cerr &lt;&lt; callstack &lt;&lt; &quot;</span><span class="er">\</span><span class="pp">n&quot;;                                 </span>\
<span class="pp">    std::cerr &lt;&lt; </span><span class="ot">__PRETTY_FUNCTION__</span><span class="pp"> ;                              </span>\
<span class="pp">    std::cerr &lt;&lt; &quot; &quot; &lt;&lt; </span><span class="ot">__FILE__</span><span class="pp"> &lt;&lt; &quot;:&quot;;                            </span>\
<span class="pp">    std::cerr &lt;&lt; </span><span class="ot">__LINE__</span><span class="pp"> &lt;&lt; &quot;</span><span class="er">\</span><span class="pp">n&quot;;                                  </span>\
<span class="pp">    op;                                                             </span>\
<span class="pp">  }</span></code></pre></div>
<p>I quickly realized I no longer needed the <code>SIGTRAP</code> to know which functions where getting called. Dropping it and just using <code>__PRETTY_FUNCTION__</code> information identified ops using <code>NodeOp(...)</code>.</p>
<details> <summary> Ops (click to expand) </summary>
<pre>
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/tensors/cpu/integer_common.h#L46">marian::cpu::integer::fetchAlphaFromModelNodeOp::forwardOps()::&lt;lambda&gt;</a>() 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/graph/node_operators_binary.h#L419">marian::DotBatchedNodeOp::forwardOps()::&lt;lambda&gt;</a>() 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/graph/node_operators_binary.h#L735">marian::GatherNodeOp::forwardOps()::&lt;lambda&gt;</a>() 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/graph/node_operators_binary.h#L1252">marian::HighwayNodeOp::forwardOps()::&lt;lambda&gt;</a>() 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/graph/node_operators_binary.h#L1200">marian::LayerNormalizationOp::forwardOps()::&lt;lambda&gt;</a>() 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/graph/node_operators_unary.h#L450">marian::LogSoftmaxNodeOp::forwardOps()::&lt;lambda&gt;</a>() 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/graph/node_operators_unary.h#L728">marian::NegNodeOp::forwardOps()::&lt;lambda&gt;</a>() 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/graph/node_operators_binary.h#L831">marian::PlusNodeOp::forwardOps()::&lt;lambda&gt;</a>() 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/graph/node_operators_unary.h#L284">marian::ReLUNodeOp::forwardOps()::&lt;lambda&gt;</a>() 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/graph/node_operators_binary.h#L672">marian::RowsNodeOp::forwardOps()::&lt;lambda&gt;</a>() 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/graph/node_operators_unary.h#L42">marian::ScalarAddNodeOp::forwardOps()::&lt;lambda&gt;</a>() 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/graph/node_operators_unary.h#L100">marian::ScalarMultNodeOp::forwardOps()::&lt;lambda&gt;</a>() 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/graph/node_operators_unary.h#L425">marian::SoftmaxNodeOp::forwardOps()::&lt;lambda&gt;</a>() 
<a href="https://github.com/jerinphilip/marian/blob/8c4170fa08c46df1cf4c987e493b7a3772c380b3/src/graph/node_operators_unary.h#L747">marian::TransposeNodeOp::forwardOps()::&lt;lambda&gt;</a>()
</pre>
<p></details></p>
<p>The Ops that the trace rendered first were not exhaustive. There are some functions that simply use a capturing lambda and not the macro. That’s okay, I don’t think the authors of the macro <a href="https://www.hyrumslaw.com/">ever intended it to be used this way</a>. To my surprise, I discovered <code>NodeOp</code> was even <a href="https://marian-nmt.github.io/docs/api">mentioned by a documentation effort</a>. Macros are supposed to be <a href="https://stackoverflow.com/questions/14041453/why-are-preprocessor-macros-evil-and-what-are-the-alternatives">bad and evil</a> per established wisdom.</p>
<p>If as reader, you feel that this article is jumping all around the place - know that it is an accurate reflection my mental state and uncertainty regarding the path at this point. But from here-on, I had clarity.</p>
<h3 id="tracing-execution">Tracing execution</h3>
<p>I’m mostly lurking and operating in the compilers intersection machine-learning space now. So far I’ve also followed the <a href="https://minitorch.github.io/">minitorch</a> tutorial twice - once in Python and once in C++ to know what a computation graph is and how to build autograd. This puts me in place with certain theory and understanding that could make life further simpler for me.</p>
<p>All that aside, we will consider a toy language of data-types being <code>Expr</code>, indicating an expression (more specifically, the result of an expression). We can do the following with <code>Expr</code>s for an example.</p>
<p>We’ll make a simplified definition of <code>Expr</code> as follows:</p>
<div class="sourceCode"><pre class="sourceCode cpp"><code class="sourceCode cpp"><span class="co">// Expr lhs = Op(rhs[0], rhs[1], ...)</span>
<span class="kw">struct</span> Expr { 
   <span class="dt">float</span>* value; <span class="co">// Holds underlying </span>
   storage <span class="dt">size_t</span> size;  <span class="co">// Size of the storage, in count(float).</span>

   <span class="kw">using</span> Operands = <span class="bu">std::</span>vector&lt;Expr&gt;; 
   Operands rhs; <span class="co">// operands that populate the result value.</span>

   <span class="kw">using</span> Op  = <span class="bu">std::</span>function&lt;<span class="dt">void</span>(<span class="dt">void</span>)&gt;; 
   <span class="kw">using</span> Ops = <span class="bu">std::</span>vector&lt;Op&gt;;

   Ops forward() { 
     <span class="kw">auto</span> op = [=](){ 
       <span class="co">// Open up rhs, apply intended function.</span>
       <span class="co">// write to value.  </span>
     }; 
     <span class="cf">return</span> { op }; 
   }

   <span class="dt">float</span> *grad; <span class="co">// Same size as value, holds gradient</span>

   <span class="co">// Operates on grad, after receiving gradients from Expr(s) ahead.  </span>
   Ops backward(<span class="dt">float</span> *grad_from_successor_node);  
};</code></pre></div>
<p>An abstraction like <code>Expr</code> forms the basis for autograd frameworks. Since we’re tracing the inference path, we’re not interested in <code>backward</code> and <code>grad</code>.</p>
<p>Consider the expression as an LHS which is obtained by some operation on the rhs operands.</p>
<div class="sourceCode"><pre class="sourceCode cpp"><code class="sourceCode cpp">Expr x = ones(<span class="dv">2</span>, <span class="dv">2</span>);
Expr y = zero(<span class="dv">2</span>, <span class="dv">2</span>);
Expr z = x + y;</code></pre></div>
<p>Consider <code>z</code>, which is a result of <code>+</code> on <code>[x, y]</code>, <code>Expr</code> would be as follows:</p>
<div class="sourceCode"><pre class="sourceCode cpp"><code class="sourceCode cpp"><span class="kw">struct</span> Add: <span class="kw">public</span> Expr {
<span class="kw">public</span>:
  <span class="co">// ...</span>
  Ops forward() {
    <span class="co">// Open up rhs, apply intended function.</span>
    <span class="co">// write to value.</span>
    <span class="co">// x, y are available in rhs.</span>
    Op add = [=](){
      <span class="cf">for</span>(<span class="dt">size_t</span> i = <span class="dv">0</span>; i &lt; size; i++){
          value[i] = rhs[<span class="dv">0</span>].value[i] + rhs[<span class="dv">1</span>].value[i];
      }
    };
    <span class="cf">return</span> { add };
  }
};</code></pre></div>
<p>Note that we’re only recording that so and so operations must be done using so and so storage locations - <a href="https://en.wikipedia.org/wiki/Thunk">thunks</a>. We’ve not actually executed them yet. Execution would look as follows:</p>
<div class="sourceCode"><pre class="sourceCode cpp"><code class="sourceCode cpp"><span class="co">// Compute loss</span>
loss = f(rhs1, rhs2, ...);

<span class="co">// Note: Topological order begins from first expr, it is the</span>
<span class="co">// reverse-topological-order that starts with loss. </span>
<span class="bu">std::</span>vector&lt;Expr&gt; order = topological_order(loss); 

<span class="co">// Run forward ops</span>
<span class="cf">for</span>(<span class="kw">auto</span> expr: order){
  forward_ops = expr-&gt;forward();
  <span class="co">// Execute functions, ends up in order of construction.</span>
  <span class="cf">for</span>(<span class="kw">auto</span> &amp;op: forward_ops){
    op();
  }
}</code></pre></div>
<p>Okay.. what’s the point of all this? Turns out <code>NodeOp</code> being used to package the thunk means I can use <code>NodeOp</code> macro to add a pre and post hook to the statements. This means by the following modification, I can inspect the values of <code>lhs</code> (value) before and after, and also inspect the state of <code>rhs</code> (operands) during the op.</p>
<p>The modification I’m looking for looks like:</p>
<div class="sourceCode"><pre class="sourceCode cpp"><code class="sourceCode cpp"><span class="pp">#define WrapStatementInLambda(statement)                            </span>\
<span class="pp">  [=]() {                                                           </span>\
<span class="pp">    // Open up and inspect value (Before op)                        </span>\
<span class="pp">    // (Not usually required.)                                      </span>\
<span class="pp">                                                                    </span>\
<span class="pp">    // Extra local information                                      </span>\
<span class="pp">    std::cerr &lt;&lt; </span><span class="ot">__PRETTY_FUNCTION__</span><span class="pp"> ;                              </span>\
<span class="pp">    std::cerr &lt;&lt; &quot; &quot; &lt;&lt; </span><span class="ot">__FILE__</span><span class="pp"> &lt;&lt; &quot;:&quot;;                            </span>\
<span class="pp">    std::cerr &lt;&lt; </span><span class="ot">__LINE__</span><span class="pp"> &lt;&lt; &quot;</span><span class="er">\</span><span class="pp">n&quot;;                                  </span>\
<span class="pp">                                                                    </span>\
<span class="pp">    // Execute the operation                                        </span>\
<span class="pp">    // Just leave the arg to unroll statements wrapped by macro.    </span>\
<span class="pp">                                                                    </span>\
<span class="pp">    statement;                                                      </span>\
<span class="pp">                                                                    </span>\
<span class="pp">    // save value (lhs), rhs[0], rhs[1] ... to disk(?)              </span>\
<span class="pp">  }</span>


<span class="pp">#define NodeOp(op)  WrapStatementInLambda(op)</span></code></pre></div>
<p>The rich-version I eventually ended up using is available in <a href="https://github.com/jerinphilip/slimt/blob/main/scripts/marian-trace-gen.h">slimt/marian-trace-gen.h</a>. I was also able to extract shape metadata at runtime, some name and unique-identifier information that was stored in the values. The unique-id meant I could conditionally stop during execution based on the identifier value. The macro-modification is a one-off throwaway creation, but can be refined to trace the exact final operations executed by a marian forward pass and backward-pass if need be. If I want to take advantage of MLIR provisions to optimize these <code>Op</code> primitives to any (supported) target hardware, this could be a viable route - but I digress. There were a few <code>Expr</code>s not using <code>NodeOp</code>, but were <a href="https://github.com/jerinphilip/marian/compare/dev...jerinphilip:marian:tracing">easy to tame</a>.</p>
<p>My traces looked like below:</p>
<div class="sourceCode"><pre class="sourceCode yaml"><code class="sourceCode yaml"><span class="fu">file:</span><span class="at"> </span><span class="st">&quot;/home/jerin/code/bergamot-translator/3rd_party/marian-dev/src/graph/node_operators_binary.h&quot;</span>
<span class="fu">line:</span><span class="at"> 836</span>
<span class="fu">fn:</span><span class="at"> </span><span class="st">&quot;marian::PlusNodeOp::forwardOps()::&lt;lambda()&gt;&quot;</span>
<span class="fu">op:</span><span class="at"> </span><span class="kw">{</span> Element(_1 = _2 + _3, val_, child(0)-&gt;val(), child(1)-&gt;val()) <span class="kw">}</span>
<span class="fu">before:</span><span class="at"> var_45 float32 [2x8x4x4]</span>
<span class="fu">after:</span><span class="at"> var_45 float32 [2x8x4x4] var_45-PlusNodeOp-float32_2x8x4x4-lhs.bin</span>
<span class="fu">operands:</span><span class="at"> </span>
  <span class="kw">-</span> var_44 float32 <span class="kw">[</span>2x8x4x4<span class="kw">]</span> var_45-PlusNodeOp-float32_2x8x4x4-rhs0-float32_2x8x4x4.bin
  <span class="kw">-</span> var_16 float32 <span class="kw">[</span>2x1x1x4<span class="kw">]</span> var_45-PlusNodeOp-float32_2x8x4x4-rhs1-float32_2x1x1x4.bin


<span class="fu">file:</span><span class="at"> </span><span class="st">&quot;/home/jerin/code/bergamot-translator/3rd_party/marian-dev/src/graph/node_operators_unary.h&quot;</span>
<span class="fu">line:</span><span class="at"> 425</span>
<span class="fu">fn:</span><span class="at"> </span><span class="st">&quot;marian::SoftmaxNodeOp::forwardOps()::&lt;lambda()&gt;&quot;</span>
<span class="fu">op:</span><span class="at"> </span><span class="kw">{</span> Softmax(val_, child(0)-&gt;val()) <span class="kw">}</span>
<span class="fu">before:</span><span class="at"> var_46 float32 [2x8x4x4]</span>
<span class="fu">after:</span><span class="at"> var_46 float32 [2x8x4x4] var_46-SoftmaxNodeOp-float32_2x8x4x4-lhs.bin</span>
<span class="fu">operands:</span><span class="at"> </span>
  <span class="kw">-</span> var_45 float32 <span class="kw">[</span>2x8x4x4<span class="kw">]</span> var_46-SoftmaxNodeOp-float32_2x8x4x4-rhs0-float32_2x8x4x4.bin</code></pre></div>
<p>The full execution trace is available <a href="https://gist.github.com/jerinphilip/e3ff5a29c55a554849c0e5a3ed4ca3fa">here</a>.</p>
<p>Notice, how I had the LHS and RHS for the ops saved onto-disk under unique names. This meant I could even unit-test my ops. The trace was <em>linear</em> unlike the <em>nested</em> functions I’d been hopping through back and forth, context switching. The linear nature made the underlying operations easier to reason with. With some domain knowledge it’s easy to recognize the above code as the softmax in attention after addition of mask for pad-tokens.</p>
<p>At this point, I knew what I wanted was realizable at a pace I was happy with. The problem was more or less solved inside my head. I had all the missing pieces, and a really small chance of failure. Note that I hadn’t completed the solution yet, I’ve just figured out the solution.</p>
<h2 id="finishing-up">Finishing up</h2>
<p>I had made the process mechanical. I traversed the trace porting code step-by-step, checking LHS and RHS tensors matched what I computed using my ported code. I built some verification convenience functions to check as I progressed as well, which looked within source as follows.</p>
<div class="sourceCode"><pre class="sourceCode cpp"><code class="sourceCode cpp">Tensor &amp;encoder_out = x;
VERIFY_MATCH(encoder_out,
             <span class="st">&quot;var_394-LayerNormalizationOp-float32_1x2x4x256-lhs.bin&quot;</span>);
<span class="cf">return</span> <span class="va">decoder_</span>.decode(encoder_out, mask, batch.words());</code></pre></div>
<p>I hit some hiccups at 8-bit matrix multiply using intgemm (and ruy later on) in marian. But the saved tensor input/output pairs I left for myself via the tracing helped a lot.</p>
<p>That I was familiar with the components help speed things up a bit. Some corners were cut, but no problem - we can fix it slowly if need be. There is a lot more room or optimizations. I am currently trying my hands at compilers and parallel-programming, and weak-baselines should be opportunity to learn more things on the way.</p>
<p>Changing <code>Node.h</code> and recompiling I’d estimate take 20+ minutes on my laptop, which is enough time to walk away elsewhere while developing tracing scripts - so the new more powerful PC helped a bit.</p>
<p>The source-code is <a href="https://github.com/jerinphilip/slimt">made public</a> on achieving bare-minimum functionality on <code>x86_64</code>, and have <a href="https://github.com/jerinphilip/slimt/pull/2">a PR open</a> to support <code>aarch64</code>. Some code that I wrote for <a href="https://github.com/jerinphilip/MozIntGemm">ARM support for Mozilla</a> back in the day and the experience ended up helping. As of now I am aware of KDE using bergamot’s models in <a href="https://invent.kde.org/libraries/ktextaddons/-/tree/master/texttranslator/translator/plugins/bergamot">KTextAddons</a>. A refined version of this could be useful to Mozilla, who I know to be using only tiny11 models.</p>
<p>This post mostly deals with the development process. I hope to write in the future about the actual technical and math content surrounding these models.</p>
<h2 id="references" class="unnumbered">References</h2>
<div id="refs" class="references">
<div id="ref-kim2019research">
<p>Young Jin Kim, Marcin Junczys-Dowmunt, Hany Hassan Awadalla, Alham Fikri Aji, Kenneth Heafield, Roman Grundkiewicz, and Nikolay Bogoychev. 2019. From research to production and back: Ludicrously fast neural machine translation. In <em>Proceedings of the 3rd workshop on neural generation and translation</em>, pages 280–288.</p>
</div>
</div></div>
</div>


<div class="row">
    <div class="col">
        <p class="text-muted font-italic"> (Comments disabled. Email me instead.) </p>
    </div>
</div>

                    </div>
                </div>

                <div class="row">
                    <div class="col">
                        
<footer>
    <small>Site generated using <a href="http://jaspervdj.be/hakyll">Hakyll</a></small>
</footer>

                    </div>
                </div>
            </div>
        <script type="text/javascript" src="../static/js/init.js"></script>
    </body>
</html>
]]></summary>
</entry>
<entry>
    <title>Alignment manipulations for pivoting in MT</title>
    <link href="http://jerinphilip.github.io/posts/alignment-manipulations-pivoting-mt.html" />
    <id>http://jerinphilip.github.io/posts/alignment-manipulations-pivoting-mt.html</id>
    <published>2023-07-24T00:00:00Z</published>
    <updated>2023-07-24T00:00:00Z</updated>
    <summary type="html"><![CDATA[<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta property="og:title" content="Alignment manipulations for pivoting in MT" />
        <meta property="og:url" content="http://jerinphilip.github.io/posts/alignment-manipulations-pivoting-mt.html" />
        <title>Alignment manipulations for pivoting in MT</title>
        <link rel="shortcut icon" href="../static/images/favicon.ico" type="image/x-icon">
        <link rel="stylesheet" href="../static/css/hack.css" />
        <link rel="stylesheet" href="../static/css/open-sans.css">
        <link rel="stylesheet" href="../static/css/font-awesome.min.css">
        <link rel="stylesheet" href="../static/css/tether.min.css" />
        <link rel="stylesheet" href="../static/css/bootstrap.min.css" />
        <link rel="stylesheet" href="../static/css/custom.css" />
        <link rel="stylesheet" href="../static/css/kate.css" />
        <link rel="stylesheet" href="../static/css/ekko-lightbox.css" />
        <script type="text/javascript" src="../static/js/jquery.min.js"></script>
        <script type="text/javascript" src="../static/js/tether.min.js"></script>
        <script type="text/javascript" src="../static/js/anchor.min.js"></script>
        <script type="text/javascript" src="../static/js/ekko-lightbox.min.js"></script>
        <script type="text/javascript" src="../static/js/bootstrap.min.js"></script>
        <script type="text/x-mathjax-config" src="../static/js/mathjax-config.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML"></script>
    </head>
    <body>
            <div class="container">
                <div class="row">
                    <div class="col">
                        <header>
    <span><a href="../">/home/jerin</a> </span>
    <!--
    <span><a href="/archive.html">posts</a></span>,
    <span><a href="/contact.html">contact</a></span>
    -->
</header>

                    </div>
                </div>
                <div class="row">
                    <div class="col">
                        <h1>Alignment manipulations for pivoting in MT</h1>
                        <div class="row mb-4">
    <div class="post-info col">
        <div>Jul 24, 2023</div>

         

         
            <div><a href="../tags/posts/mt.html">mt</a>, <a href="../tags/posts/ml.html">ml</a>, <a href="../tags/posts/bergamot.html">bergamot</a></div>
         
    </div>
</div>

<div class="row">
    <div class="toc col-md-4 col-sm-12 order-md-second"><h6>Outline</h6><ul>
<li><a href="#attention">Attention</a></li>
<li><a href="#pivoting">Pivoting</a><ul>
<li><a href="#same-vocabulary">Same vocabulary</a></li>
<li><a href="#different-vocabularies">Different vocabularies</a></li>
</ul></li>
<li><a href="#validation">Validation</a></li>
<li><a href="#references">References</a></li>
</ul></div><div class="col-md-8 col-sm-12 post-content order-md-first"><p>While working on <a href="https://github.com/browsermt/bergamot-translator">bergamot-translator</a>, one feature I was tasked with implementing was a translation flow using pivoting. This post is an account of the implementation of the pivoting feature - traversing math I’m to date still not certain of, hacking one thing after another together effectively engineering a feature shipped and running in about <a href="https://addons.mozilla.org/en-US/firefox/addon/firefox-translations/">300k installations</a> now.</p>
<p>The idea is simple - given a source language <span class="math inline">\(ss\)</span> translate to a target language <span class="math inline">\(tt\)</span>, through a pivot language <span class="math inline">\(pp\)</span>. Given how history put us in an <em>anglocentric</em> position, there happens to be a lot of parallel-data between English and other languages of the world, than between other pairs. Sentence aligned parallel data aligned drives machine-translation and this consequently meant the existence of a lot of <span class="math inline">\(ss \rightarrow en\)</span> models and <span class="math inline">\(en \rightarrow tt\)</span> models. Consequently pivoting through English to obtain <span class="math inline">\(ss \rightarrow tt\)</span> remains a prevalent strategy in the field of machine-translation. At the time, the Bergamot Project stood in agreement with its model inventory.</p>
<p>The text part of pivoting is straight-forward. However, one critical-piece to keeping a user-facing HTML translation feature functional was obtaining alignments between the source and target properly. Critical, because the HTML translation feature relied on working alignment information to place tags correctly when matching-tokens in source and target moved around. HTML translation feature was ready with vanilla-translation without pivoting and using alignments. For the pivoting case, attention matrices providing alignments for source to pivot and pivot to target was available separately.</p>
<p>Using these to obtain source to target alignments wasn’t straightforward (at least to me, back then). So I’ve decided this warrants a post, albeit a bit late.</p>
<h2 id="attention">Attention</h2>
<!--
@luong2015effective formulates attention as follows:

\begin{align}
    \mathbf{a} &= \mathrm{align}(\mathbf{h}_t, \mathbf{h}_s) \\
               &= \dfrac
                                {\exp \left(\mathrm{score}\left(\mathbf{h}_t, \mathbf{h}_s\right)\right)}
                                {\sum_{s'}{\exp\left(\mathrm{score}\left(\mathbf{h}_t, \mathbf{h}_s'\right)\right)}}
\end{align}
-->
<p>Marian, the library bergamot-translator is built on top of <a href="https://github.com/marian-nmt/marian-dev/blob/c29cc83dc4d234f0e3a00a46a729053132b408b8/src/models/costs.h#L86">uses</a> an additional loss formulated using attention to additionally learn <em>alignments</em> between source and target tokens. During training, a guided alignment loss is added to the objective that uses alignment information as a training signal. A tool matching tokens in source to tokens in target from raw-corpus like <a href="https://github.com/clab/fast_align">fastalign</a> can provide alignments that can be used as ground-truths. At inference, the attention values will predict the expected alignments. Note that this is different from learning to align, the network is forced to learn to align to certain ground truths from alignment data here. More on this process can be found in <span class="citation">Chen et al. (<a href="#ref-chen2016guided">2016</a>)</span>.</p>
<p>Illustrations visualizing attention are often attached as qualitative samples demonstrating attention’s efficacy. The render below comes from something <a href="https://github.com/jerinphilip/bergamot-translator/pull/88">I repurposed</a> with borrowed source from <a href="https://distill.pub/2016/augmented-rnns/">distill.pub</a>.</p>
<div class="figure">
<img src="../static/images/pivoting-de-en.png" alt="Translating German to English: Alignments via attention" />
<p class="caption">Translating German to English: Alignments via attention</p>
</div>
<p>The above illustration also provide hints to underlying data, and data-structures. The initiated should immediately recognize the tokens (on source and target) can be modelled as nodes and the arrows modelled as weighted edges between source and target tokens.</p>
<p>In code, we have an adjacency-matrix describing the probabilities / scores matching a source-token with a target-token.</p>
<h2 id="pivoting">Pivoting</h2>
<p>As mentioned before, the idea is simple - given a source language <span class="math inline">\(ss\)</span> translate to a target language <span class="math inline">\(tt\)</span>, through a pivot language <span class="math inline">\(pp\)</span>. To get a hang of the elements involved in a translation from German to Italian via English as pivot, see illustrations below.</p>
<div class="figure">
<img src="../static/images/pivoting-de-en.png" alt="German to English" />
<p class="caption">German to English</p>
</div>
<div class="figure">
<img src="../static/images/pivoting-en-it.png" alt="English to Italian" />
<p class="caption">English to Italian</p>
</div>
<p>We have two adjacency matrices in-play here, one with scores for source-pivot pair and the other with scores for pivot-target pair. For simplicity’s sake, we’ll first try to come up with a formulation and algorithm for the case when the pivot tokens match (<em>i.e</em> same vocabulary) and matrix multiplication is straighforward.</p>
<h3 id="same-vocabulary">Same vocabulary</h3>
<p>Let the tokens involved in pivoting be <span class="math inline">\(S, P, T\)</span> denoting source, pivot and target respectively.</p>
<span class="math display">\[\begin{align*}
    S = \{s_i\} &amp;= \{s_1, s_2, \dots \} \\
    P = \{q_j\} &amp;= \{q_1, q_2, \dots \} \\
    T = \{t_k\} &amp;= \{t_1, t_2, \dots \} 
\end{align*}\]</span>
<p>These tokens do not necessarily correspond to the notion of <em>words</em>. Note that I am using <span class="math inline">\(q_j\)</span> to represent the pivot sequence <span class="math inline">\(P\)</span> so as to not confuse with probabilities used in this document, denoted by <span class="math inline">\(p(\cdot)\)</span>.</p>
<p>From alignments coming out of the decoding pipeline, we obtain a probability for each source-token <span class="math inline">\(s_i\)</span> over the target token <span class="math inline">\(t_j\)</span>. We will use <span class="math inline">\(p(s_i | t_j)\)</span> to denote this in this post. For each target-token <span class="math inline">\(t_j\)</span> we have a probability distribution spread over source-tokens <span class="math inline">\(S\)</span>.</p>
<p>We know the values <span class="math inline">\(p(s_i | q_j)\)</span>, <span class="math inline">\(p(q_j | t_k)\)</span> at inference as some form of attention/alignment from the constituent neural network. I will cook up the math below to get the required <span class="math inline">\(p(s_i | t_k)\)</span>:</p>
<span class="math display">\[\begin{align}
p(s_i | t_k)  &amp;= \sum_{j}{p(s_i, q_j| t_k)}  \label{eq:marginalize-pivot} &amp; \text{Marginalization(?)}  \\
              &amp;= \sum_{j}{{p(s_i| q_j,  t_k) \cdot p(q_i | t_k) }}        &amp; \text{Bayes rule(?)}       \\
p(s_i | t_k)  &amp;= \sum_{j}{{p(s_i | q_j)\cdot p(q_j | t_k) }}              &amp; \text{Independence(?)}
\end{align}\]</span>
<p>In an ideal case, if we assume the pivot tokens constituting the pivot sentence are same, we have a <span class="math inline">\(|S| \times |P|\)</span> matrix and a <span class="math inline">\(|P| \times |T|\)</span> matrix. The above formulation in implementation translates to a matrix multiplication, of matrices containing attention values coming out of the source to pivot and pivot to target translation processes. Not sure if the above math is sound, I’m mostly working backwards from a gut feeling that I have two attention matrices, multiplying them should give me the required probabilities.</p>
<p>This matrix-multiplication is implemented in bergamot-translator <a href="https://github.com/jerinphilip/bergamot-translator/blob/4fed75af1deb3ede67d9ade0354b87b0806a0ad3/src/translator/response.cpp#L127-L137">here</a>. The implementation makes an additional hop, due to the vocabularies being different. We will discuss this in detail next.</p>
<h3 id="different-vocabularies">Different vocabularies</h3>
<p>In reality, it’s not as simple as above. Due to historical reasons, the <span class="math inline">\(ss \rightarrow pp\)</span> and <span class="math inline">\(pp \rightarrow tt\)</span> models happen to be be using different sets of vocabularies. If we take a closer look at the diagrams above, we see <span class="math inline">\(P\)</span> and <span class="math inline">\(P'\)</span> are different. See an extract below. The tokens are space separated.</p>
<div class="sourceCode">
<pre class="sourceCode">
<code class="sourceCode">[S ] Der heutige Artikel in Wikipedia , der freie En zy klo pä die .
[P ] To day ' s article in Wikipedia , the free en cycl o pedia .
[P'] Today ' s article in Wikipedia , the free e ncy clo pedia .
[T ] L ' articolo di oggi su Wikipedia , l ' en ciclo pedia libera .</code>
</pre>
</div>
<p>The previous formulation was convenient in our application of NMT case when the vocabulary used to represent the language <span class="math inline">\(pp\)</span> is consistent giving us <span class="math inline">\(S \leftarrow P\)</span> and <span class="math inline">\(P \leftarrow T\)</span>. To obtain the probabilities in the inconsistent case, we can use the knowledge that vocabularies match at character or byte level. Both vocabularies describe the same underlying text-surface.</p>
<p>Updating the formulation to include inconsistent pivot vocabularies, we get:</p>
<span class="math display">\[\begin{align*}
    S  = \{s_i    \} &amp;= \{s_1, s_2, \dots   \}    \\
    P  = \{q_j    \} &amp;= \{q_1, q_2, \dots   \}    \\
    P' = \{q'_{j'}\} &amp;= \{q'_1, q'_2, \dots \}    \\
    T  = \{t_k    \} &amp;= \{t_1, t_2, \dots   \}    \\
\end{align*}\]</span>
<p>The old math remains valid, but requires some reinterpretation. We will start from the formulation we already have.</p>
<span class="math display">\[\begin{align}
p(s_i | t_k)  &amp;= \sum_{j}{{p(s_i | q_j)\cdot p(q_j | t_k) }}  \\
\end{align}\]</span>
<p>Both <span class="math inline">\(q'_{j'}\)</span> and <span class="math inline">\(q_j\)</span> describe a surface in the same underlying string, which overlaps to some extent. We can use this information to proportionately assign probabilities of <span class="math inline">\(q'_{j'}\)</span> to the characters, and reinterpret them in terms of <span class="math inline">\(q_j\)</span>.</p>
<span class="math display">\[\begin{align*}
    p(q_j | t_j) &amp;= \sum_{q'_{j'}}{\mathrm{overlap}(q_j, q'_{j'}) \cdot  p(q'_{j'} | t_j)} \\
    \mathrm{overlap}(q_j, q'_{j'}) &amp;= \dfrac{\lvert q_j \cap q'_{j'} \rvert}{\lvert q'_{j'} \rvert} \\
\end{align*}\]</span>
<h2 id="validation">Validation</h2>
<p>I have cooked up a lot of math, now how do I validate it? Thankfully this is grounded in a real use-case. I can try and do German to English to Italian, but the weird thing is I don’t speak/read the source and target languages. I came up with the not-so-standard but useful use-case of translating English to Estonian to English doing the round-trip.</p>
<p>The above process is textbook definition of <em>lost in translation</em>. When translating through an intermediate language, some information is lost (or added). Some corruption to the tokens happen. However, should the alignment formulations and engineering be sound the scores should correspond for the tokens surviving <em>lost in translation</em>.</p>
<p>Armed with the above, I filtered out the top-scores and printed them on the console during development. Find some output from the time of development below (click to expand).</p>
<p><details> <summary>Sample #1</summary></p>
<pre><code>&gt; The Bergamot project will add and improve client-side machine translation in a web browser.
&lt; The Bergamot project will add and improve the translation of the client-side machine into a web browser.

The The=0.955146
 Berg  Berg=0.826679
amo amo=0.995598
t t=0.975599
 project  project=0.955401
 will  will=0.912722
 add  add=0.623312
 and  and=0.941392
 improve  improve=0.710752
 translation  the=0.21632
 translation  translation=0.636088
-  of=0.396329
 machine  the=0.685785
 machine  client=0.437611
 client -=0.627738
 client side=0.621546
 machine  machine=0.720943
 in  into=0.888125
 a  a=0.951628
 web  web=0.778772
row  b=0.541725
ser row=0.273472
ser ser=0.293319
. .=0.925082
 will =0.0982262</code></pre>
<p></details></p>
<p><details> <summary>Sample #2</summary></p>
<pre><code>&gt; Unlike current cloud-based options, running directly on users’ machines empowers citizens to preserve their privacy and increases the uptake of language technologies in Europe in various sectors that require confidentiality.
&lt; Unlike current cloud-based options, working directly on user machines allows citizens to preserve their privacy and increases the adoption of language technologies in Europe in various sectors that require confidentiality.

Unlike Unlike=0.695362
 options  current=0.526343
 cloud  cloud=0.808333
based -=0.519486
based based=0.494906
 options  options=0.726565
, ,=0.953748
 running  working=0.639273
 directly  directly=0.927166
 on  on=0.712787
 users  user=0.304554
 machines  machines=0.624575
 empower  allows=0.385191
 citizens  citizens=0.503892
 to  to=0.443355
 preserve  preserve=0.797836
 their  their=0.776323
 privacy  privacy=0.942544
 and  and=0.947178
 increases  increases=0.786974
 the  the=0.646595
take  adoption=0.835365
 of  of=0.510325
 language  language=0.873498
 technologies  technologies=0.815092
 in  in=0.853544
 Europe  Europe=0.7521
 in  in=0.87099
 various  various=0.948102
 sectors  sectors=0.864905
 that  that=0.706083
 require  require=0.929663
 confidentiality  confidentiality=0.754831
. .=0.937042
 options =0.068332</code></pre>
<p></details></p>
<p><details> <summary>Sample #3</summary></p>
<pre><code>&gt; Free software integrated with an open-source web browser, such as Mozilla Firefox, will enable bottom-up adoption by non-experts, resulting in cost savings for private and public sector users who would otherwise procure translation or operate monolingually.
&lt; Free software integrated with an open source web browser, such as Mozilla Firefox, will allow the adoption from the bottom up by non-experts, resulting in cost savings for public and private sector users who would otherwise acquire translation or operate monolinguily.

Free Free=0.56728
 software  software=0.62599
 integrated  integrated=0.883837
 with  with=0.947031
 an  an=0.839987
 open  open=0.754714
source  source=0.690299
 web  web=0.729925
row  b=0.353977
ser row=0.299766
ser ser=0.309285
, ,=0.813261
 as  such=0.704488
 as  as=0.557725
 Mo  Mo=0.860583
z z=0.997161
illa illa=0.978077
 Fire  Fire=0.983289
fo fo=0.996755
x x=0.99419
, ,=0.851676
 enable  will=0.72535
 enable  allow=0.251865
 adoption  the=0.261452
 adoption  adoption=0.643473
 bottom  from=0.282512
 bottom  the=0.456695
 bottom  bottom=0.460874
up  up=0.47468
 by  by=0.623741
 non  non=0.832823
 non -=0.305707
expert expert=0.71779
 non s=0.252237
, ,=0.891577
 resulting  resulting=0.386231
 in  in=0.745363
 cost  cost=0.685577
 savings  savings=0.798135
 for  for=0.787879
 private  public=0.50413
 private  and=0.594041
 private  private=0.719888
 users  sector=0.415775
 users  users=0.790084
 who  who=0.679675
 would  would=0.659394
 otherwise  otherwise=0.823563
 procure  acquire=0.834951
 translation  translation=0.743358
 or  or=0.935836
 operate  operate=0.720217
 mono  mono=0.744872
ling ling=0.626815
ual u=0.684935
ly ily=0.676535
. .=0.69808j
ly =0.0632002</code></pre>
<p></details></p>
<p><details> <summary>Sample #4</summary></p>
<pre><code>&gt; Bergamot is a consortium coordinated by the University of Edinburgh with partners Charles University in Prague, the University of Sheffield, University of Tartu, and Mozilla.
&lt; Bergamot is a consortium coordinated by the University of Edinburgh with partners from Charles University in Prague, the University of Sheffield, the University of Tartu and Mozilla.

Berg Berg=0.994895
amo amo=0.991532
t t=0.967724
 is  is=0.888633
 a  a=0.894048
 consortium  consortium=0.868016
 coordinated  coordinated=0.773978
 by  by=0.935519
 the  the=0.738964
 University  University=0.929871
 of  of=0.946889
 Edinburgh  Edinburgh=0.936051
 with  with=0.817898
 partners  partners=0.867468
 Charles  from=0.216679
 Charles  Charles=0.731952
 University  University=0.624898
 in  in=0.875768
 Prague  Prague=0.87894
, ,=0.938541
 the  the=0.589038
 University  University=0.910463
 of  of=0.902571
 She  She=0.881999
f f=0.992118
field field=0.992631
, ,=0.842823
 University  the=0.517793
 University  University=0.835048
 of  of=0.89574
 Tar  Tar=0.918662
tu tu=0.947869
 and  and=0.821724
 Mo  Mo=0.884175
z z=0.972944
illa illa=0.993525
. .=0.926998
 University =0.0469722</code></pre>
<p></details></p>
<p>Turns out, the tokens match most of the time strong when they’re same. The implementation works as intended!</p>
<p>The implementation of the above reinterpretation for vocabulary mismatch is available <a href="https://github.com/jerinphilip/bergamot-translator/blob/4fed75af1deb3ede67d9ade0354b87b0806a0ad3/src/translator/response.cpp#L13-L97">here</a>. This code in action, through the alignments visualization pipeline I get the following render:</p>
<div class="figure">
<img src="../static/images/pivoting-de-it.png" alt="German to Italian: alignments after corrections following pivoting." />
<p class="caption">German to Italian: alignments after corrections following pivoting.</p>
</div>
<p>Arrows appear to be pointing in the right direction as well. <em>libera</em> corresponds to <em>freie</em> - this is one case where corresponding tokens have moved around to a different position in translation. The force looks strong between the nodes in the cluster forming <em>enciclopedia</em> and <em>Enzyklopädie</em>. <em>Artikel</em> and <em>articolo</em>, <em>Wikipedia</em> and <em>Wikipedia</em> looks strong as well.</p>
<p>The test-in-the wild for this piece of code is transferring links and formatting in inline-text. So if you find yourself using Mozilla Firefox’s <a href="https://addons.mozilla.org/en-US/firefox/addon/firefox-translations/">offline translation addon</a> and the links and formatting like bold/italic etc transferring from source HTML to target HTML for non-English pairs accurately, this post is an excuse for an explanation why.</p>
<h2 id="references" class="unnumbered">References</h2>
<div id="refs" class="references">
<div id="ref-chen2016guided">
<p>Wenhu Chen, Evgeny Matusov, Shahram Khadivi, and Jan-Thorsten Peter. 2016. Guided alignment training for topic-aware neural machine translation. <em>arXiv preprint arXiv:1607.01628</em>.</p>
</div>
</div></div>
</div>


<div class="row">
    <div class="col">
        <p class="text-muted font-italic"> (Comments disabled. Email me instead.) </p>
    </div>
</div>

                    </div>
                </div>

                <div class="row">
                    <div class="col">
                        
<footer>
    <small>Site generated using <a href="http://jaspervdj.be/hakyll">Hakyll</a></small>
</footer>

                    </div>
                </div>
            </div>
        <script type="text/javascript" src="../static/js/init.js"></script>
    </body>
</html>
]]></summary>
</entry>
<entry>
    <title>Notes on Cross-Entropy in autograd</title>
    <link href="http://jerinphilip.github.io/posts/cross-entropy-derivative.html" />
    <id>http://jerinphilip.github.io/posts/cross-entropy-derivative.html</id>
    <published>2023-07-22T00:00:00Z</published>
    <updated>2023-07-22T00:00:00Z</updated>
    <summary type="html"><![CDATA[<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta property="og:title" content="Notes on Cross-Entropy in autograd" />
        <meta property="og:url" content="http://jerinphilip.github.io/posts/cross-entropy-derivative.html" />
        <title>Notes on Cross-Entropy in autograd</title>
        <link rel="shortcut icon" href="../static/images/favicon.ico" type="image/x-icon">
        <link rel="stylesheet" href="../static/css/hack.css" />
        <link rel="stylesheet" href="../static/css/open-sans.css">
        <link rel="stylesheet" href="../static/css/font-awesome.min.css">
        <link rel="stylesheet" href="../static/css/tether.min.css" />
        <link rel="stylesheet" href="../static/css/bootstrap.min.css" />
        <link rel="stylesheet" href="../static/css/custom.css" />
        <link rel="stylesheet" href="../static/css/kate.css" />
        <link rel="stylesheet" href="../static/css/ekko-lightbox.css" />
        <script type="text/javascript" src="../static/js/jquery.min.js"></script>
        <script type="text/javascript" src="../static/js/tether.min.js"></script>
        <script type="text/javascript" src="../static/js/anchor.min.js"></script>
        <script type="text/javascript" src="../static/js/ekko-lightbox.min.js"></script>
        <script type="text/javascript" src="../static/js/bootstrap.min.js"></script>
        <script type="text/x-mathjax-config" src="../static/js/mathjax-config.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML"></script>
    </head>
    <body>
            <div class="container">
                <div class="row">
                    <div class="col">
                        <header>
    <span><a href="../">/home/jerin</a> </span>
    <!--
    <span><a href="/archive.html">posts</a></span>,
    <span><a href="/contact.html">contact</a></span>
    -->
</header>

                    </div>
                </div>
                <div class="row">
                    <div class="col">
                        <h1>Notes on Cross-Entropy in autograd</h1>
                        <div class="row mb-4">
    <div class="post-info col">
        <div>Jul 22, 2023</div>

         

         
            <div><a href="../tags/posts/ml.html">ml</a>, <a href="../tags/posts/autograd.html">autograd</a></div>
         
    </div>
</div>

<div class="row">
    <div class="toc col-md-4 col-sm-12 order-md-second"><h6>Outline</h6><ul>
<li><a href="#notations">Notations</a></li>
<li><a href="#cross-entropy">Cross Entropy</a><ul>
<li><a href="#derivative">Derivative</a></li>
</ul></li>
<li><a href="#matrix-and-vector-notations">Matrix and vector notations</a></li>
<li><a href="#numerical-stability">Numerical Stability</a></li>
<li><a href="#references">References</a></li>
</ul></div><div class="col-md-8 col-sm-12 post-content order-md-first"><p>The cross-entropy loss is a commonly used loss-function in neural-network training. One of the key pieces of building an autograd is writing functions that know how to do derivatives of output w.r.t inputs (See minitorch’s <a href="https://minitorch.github.io/module1/chainrule/">backward</a>). There are already a number of good articles on the web on how to derive this for cross-entropy loss, this one is just me working this out all over again and leaving a note to my future self.</p>
<h1 id="notations">Notations</h1>
<p>This article considers the scenario where there are <span class="math inline">\(d\)</span> output classes. A neural network or something generates <span class="math inline">\(d\)</span> dimensional logits at the output layer, on which the softmax activation is applied to generate probabilities.</p>
<p>In the derivations ahead, I will use the following notations at times to simplify writing. The softmax function is denoted by <span class="math inline">\(\mathbf{\sigma}(\mathbf{x}): \mathbb{R}^d \rightarrow \mathbb{R}^d\)</span> for <span class="math inline">\(\mathbf{x} \in \mathbb{R}^d\)</span>. Softmax converts logits <span class="math inline">\(x_i\)</span> to probabilities <span class="math inline">\(p_i\)</span>.</p>
<span class="math display">\[\begin{align*}
    \mathbf{\sigma}(\mathbf{x}) &amp;= \{ p_i \}_{i=1}^{d} \\
    p_i &amp;= \dfrac{e^{x_i}}{\sum_{j=0}^{d}{e^{x_j}}}
\end{align*}\]</span>
<h1 id="cross-entropy">Cross Entropy</h1>
<p>The cross-entropy loss for multi-class classification is formulated as follows, applying a few more operations on the output of softmax:</p>
<span class="math display">\[\begin{align*}
    \mathrm{CE}(\mathbf{x}, \mathbf{y}) 
                    &amp;= - \sum_{i}^{d}{y_i \log p_i} \\
                    &amp;= -\left[ y_c \log p_c  + \sum_{ i=0, i\neq c}^{d}{y_i \log p_i} \right]\\
                    &amp; = -y_c \log p_c \\
                    &amp;= - y_c \log \left(\dfrac{e^{x_c}}{\sum_{j=0}^{d}{e^{x_j}}}\right) \\
\end{align*}\]</span>
<h2 id="derivative">Derivative</h2>
<p>The partial derivative w.r.t a component of <span class="math inline">\(\mathbf{x}\)</span> represented by <span class="math inline">\(x_k\)</span> can be computed as below. <span class="math inline">\(p_c\)</span> and <span class="math inline">\(y_c\)</span> denotes the probability predicted and the label respectively of the label (<span class="math inline">\(c\)</span>). By design, it holds <span class="math inline">\(y_c = 1\)</span> since it’s for the true label/class, but is denoted as <span class="math inline">\(y_c\)</span> for better readability in text here.</p>
<span class="math display">\[\begin{align*}
    \dfrac{\partial\mathrm{CE}(\mathbf{x}, \mathbf{y})}{\partial{x_k}} 
       &amp;= - y_c \dfrac{\partial{\log p_c }}{x_k} \\
       &amp;= - y_c \left(\dfrac{\partial{\log p_c }}{\partial p_c}\right) \left(\dfrac{\partial p_c }{ \partial x_k}\right) \\
        &amp;= - y_c \left(\dfrac{1}{p_c}\right) \left(\dfrac{\partial p_c}{\partial x_k}\right) \\
       % &amp;= - y_c \dfrac{1}{p_i} p_i \cdot (1 - p_j) \\
       % &amp;= - \sum_{i=1}^{N}{y_i \cdot (1 - p_j)} \\
    \end{align*}\]</span>
<p>Next is expanding <span class="math inline">\(\partial pc/\partial x_k\)</span>. It is worthwhile to note that <span class="math inline">\(p_c\)</span> is the output of the softmax function - so, we also happen to be computing the derivative of softmax function on vector inputs here.</p>
<p>There are two cases for the derivative, for when <span class="math inline">\(k = c\)</span> and <span class="math inline">\(k \neq c\)</span>. This is because in one case the numerator has to be considered as a variable requiring the application of the product / quotient rule for derivatives and in the other the numerator can be considered a constant.</p>
<p>For the case when <span class="math inline">\(k = c\)</span>, we have on applying the product rule:</p>
<span class="math display">\[\begin{align*}
    \dfrac{\partial p_c}{\partial x_c} &amp;= e^{x_c} \dfrac{-1}{\left(\sum_{j=0}^{d}{e^{x_j}}\right)^2} \cdot e^{x_c} + e^{x_{c}} \left(\dfrac{1}{\sum_{j=0}^{d}{e^{x_j}}}\right) \\
    &amp;= \dfrac{e^{x_c}}{\left(\sum_{j=0}^{d}{e^{x_j}}\right)} \left[ 1 - \dfrac{e^{x_c}}{\left(\sum_{j=0}^{d}{e^{x_j}}\right)}  \right] \\
    &amp;= p_c \cdot (1 - p_c) \\
\end{align*}\]</span>
<p>In the case when <span class="math inline">\(k \neq c\)</span> we obtain:</p>
<span class="math display">\[\begin{align*}
    \dfrac{\partial p_c}{\partial x_k} &amp;={e^{x_c}} \cdot \dfrac{-1}{\left(\sum_{j=0}^{d}{e^{x_j}}\right)^2} \cdot e^{x_k} \\
            &amp;= \dfrac{e^{x_c}}{\left(\sum_{j=0}^{d}{e^{x_j}}\right)} \dfrac{-e^{x_k}}{\left(\sum_{j=0}^{d}{e^{x_j}}\right)} \\
            &amp;= - p_c \cdot p_k
\end{align*}\]</span>
<p>We can consolidate the result as:</p>
<span class="math display">\[\begin{align*}
 \dfrac{\partial\mathrm{p_c}(\mathbf{x}, \mathbf{y})}{\partial{x_k}} &amp;= \begin{cases}
    p_c (1 - p_c) &amp; k = c \\
    - p_c p_k &amp; k \neq c
\end{cases}
\end{align*}\]</span>
<span class="math display">\[\begin{align*}
 \dfrac{\partial\mathrm{CE}(\mathbf{x}, \mathbf{y})}{\partial{x_k}} &amp;= \begin{cases}
    (p_k - 1) &amp; k = c \\
    p_k &amp; k \neq c
\end{cases}
\end{align*}\]</span>
For computational convenience without branching, we can consolidate this further as:
<span class="math display">\[\begin{align*}
 \dfrac{\partial\mathrm{CE}(\mathbf{x}, \mathbf{y})}{\partial{x_k}} &amp;= (p_k - \mathbb{I}[k=c])
\end{align*}\]</span>
<h1 id="matrix-and-vector-notations">Matrix and vector notations</h1>
<p>Looking closely, one can observe that derivatives above can be written in a vector/matrix notation. The cross-entropy function is from a vector input to a scalar value (loss). <em>i.e</em>, <span class="math inline">\(\mathrm{CE}: \mathbb{R}^d \rightarrow \mathbb{R}\)</span>. Because of this, the derivative can be represented as a <span class="math inline">\(d \times 1\)</span> matrix, which is only really a vector. In literature this can be denoted by prefixing a <span class="math inline">\(\nabla\)</span>.</p>
<span class="math display">\[\begin{align*}
\nabla_{\mathbb{x}}{\mathrm{CE}} &amp;=  \left[ p_k - o_k\right]_{k=1}^{d}, &amp; o_k = \mathbb{I}[k == c]
\end{align*}\]</span>
<p>The derivative of the softmax function w.r.t its inputs form a matrix of <span class="math inline">\(d \times d\)</span>, since it is a vector valued function of a vector. <em>i.e</em>, <span class="math inline">\(\mathbb{\sigma}_{\mathbb{x}}: \mathbb{R}^d \rightarrow \mathbb{R}^d\)</span>. The matrix of partial derivatives of one output component w.r.t another input component forms the Jacobian, denoted often by <span class="math inline">\(\mathbf{J}\)</span>. <span class="math inline">\(J\)</span> doesn’t appear much pleasant to unroll here, but from the two-indices in the equation above, it should be evident this forms a matrix.</p>
<p>This notation is what you’ll find in Eli Bendersky’s <a href="https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/">post</a> and CS224n’s <a href="https://web.stanford.edu/class/cs224n/readings/gradient-notes.pdf">Vectorized Gradients</a>, both of which I found useful. I just preferred at the time of writing this post to do things by hand using even more basic math (the one I learned in school) due to the lack of familiarity with multivariate calculus vocabulary used in places.</p>
<h1 id="numerical-stability">Numerical Stability</h1>
<p>While doing the implementation, one has to be mindful of the numerical stability. This is why some computations of the softmax function looks slightly more complicated. Take a look at marian’s <a href="https://github.com/marian-nmt/marian-dev/blob/master/src/tensors/cpu/tensor_operators.cpp#L950-L984">CrossEntropy backward</a>, which computes the probabilities from softmax for the derivative, for example.</p>
<p>The usual trick applied is to multiply the numerator and denominator in <span class="math inline">\(p_i\)</span> with a constant, making <span class="math inline">\(e^{x}\)</span> more amenable to floating point computations.</p>
<span class="math display">\[\begin{align*}
    p_i &amp;= \dfrac{e^{x_i}}{\sum_{j=0}^{d}{e^{x_j}}} 
        &amp;= \dfrac{e^{x_i}}{\sum_{j=0}^{d}{e^{x_j}}} \times \dfrac{e^{-M}}{e^{-M}} 
        &amp;= \dfrac{e^{(x_i - M)}}{\sum_{j=0}^{d}{e^{(x_j - M)}}} 
\end{align*}\]</span>
<p>If we choose <span class="math inline">\(M\)</span> as follows as the max among <span class="math inline">\(x_i\)</span>, we get less troubles of overflow and the likes:</p>
<span class="math display">\[\begin{align*}
M = \max \{ x_i \}
\end{align*}\]</span>
<p>My own reference implementation looks something like below:</p>
<div class="sourceCode"><pre class="sourceCode cpp"><code class="sourceCode cpp"><span class="dt">void</span> cross_entropy_with_logits_grad(<span class="dt">float</span> *logits, <span class="dt">int</span> *labels,
                                    <span class="dt">size_t</span> batch_size, <span class="dt">size_t</span> num_classes,
                                    <span class="dt">float</span> *grad_out) {
  <span class="cf">for</span> (<span class="dt">size_t</span> i = <span class="dv">0</span>; i &lt; batch_size; i++) {
    <span class="dt">size_t</span> offset = i * num_classes;

    <span class="dt">float</span> *x = logits + offset;
    <span class="dt">float</span> *dce = grad_out + offset;
    <span class="kw">auto</span> label = <span class="kw">static_cast</span>&lt;<span class="dt">size_t</span>&gt;(labels[i]);

    <span class="co">// Find maximum among x-s</span>
    <span class="dt">float</span> max_value = <span class="bu">std::</span>numeric_limits&lt;<span class="dt">float</span>&gt;::lowest();
    <span class="cf">for</span> (<span class="dt">size_t</span> j = <span class="dv">0</span>; j &lt; num_classes; j++) {
      max_value = <span class="bu">std::</span>max&lt;<span class="dt">float</span>&gt;(max_value, x[j]);
    }

    <span class="co">// Find sumexp after subtracting max-value.</span>
    <span class="dt">float</span> sumexp = <span class="dv">0</span>;
    <span class="cf">for</span> (<span class="dt">size_t</span> j = <span class="dv">0</span>; j &lt; num_classes; j++) {
      sumexp += <span class="bu">std::</span>exp(x[j] - max_value);
    }

    <span class="co">// Compute gradients using predicted probability.</span>
    <span class="cf">for</span> (<span class="dt">size_t</span> j = <span class="dv">0</span>; j &lt; num_classes; j++) {
      <span class="dt">float</span> p = <span class="bu">std::</span>exp(x[j] - max_value) / sumexp;
      <span class="kw">auto</span> o = <span class="kw">static_cast</span>&lt;<span class="dt">float</span>&gt;(j == label);
      dce[j] = (p - o);
    }
  }
}
</code></pre></div>
<h1 id="references">References</h1>
<ol style="list-style-type: decimal">
<li><a href="https://web.stanford.edu/class/cs224n/readings/gradient-notes.pdf">CS224n: Gradient Notes</a></li>
<li><a href="https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/">Eli Bendersky: The Softmax function and its derivative</a></li>
<li><a href="https://www.mldawn.com/back-propagation-with-cross-entropy-and-softmax/">MLDawn: Backprop, xent and softmax</a></li>
</ol></div>
</div>


<div class="row">
    <div class="col">
        <p class="text-muted font-italic"> (Comments disabled. Email me instead.) </p>
    </div>
</div>

                    </div>
                </div>

                <div class="row">
                    <div class="col">
                        
<footer>
    <small>Site generated using <a href="http://jaspervdj.be/hakyll">Hakyll</a></small>
</footer>

                    </div>
                </div>
            </div>
        <script type="text/javascript" src="../static/js/init.js"></script>
    </body>
</html>
]]></summary>
</entry>
<entry>
    <title>Force integrated graphics</title>
    <link href="http://jerinphilip.github.io/posts/always-egpu.html" />
    <id>http://jerinphilip.github.io/posts/always-egpu.html</id>
    <published>2023-06-12T00:00:00Z</published>
    <updated>2023-06-12T00:00:00Z</updated>
    <summary type="html"><![CDATA[<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta property="og:title" content="Force integrated graphics" />
        <meta property="og:url" content="http://jerinphilip.github.io/posts/always-egpu.html" />
        <title>Force integrated graphics</title>
        <link rel="shortcut icon" href="../static/images/favicon.ico" type="image/x-icon">
        <link rel="stylesheet" href="../static/css/hack.css" />
        <link rel="stylesheet" href="../static/css/open-sans.css">
        <link rel="stylesheet" href="../static/css/font-awesome.min.css">
        <link rel="stylesheet" href="../static/css/tether.min.css" />
        <link rel="stylesheet" href="../static/css/bootstrap.min.css" />
        <link rel="stylesheet" href="../static/css/custom.css" />
        <link rel="stylesheet" href="../static/css/kate.css" />
        <link rel="stylesheet" href="../static/css/ekko-lightbox.css" />
        <script type="text/javascript" src="../static/js/jquery.min.js"></script>
        <script type="text/javascript" src="../static/js/tether.min.js"></script>
        <script type="text/javascript" src="../static/js/anchor.min.js"></script>
        <script type="text/javascript" src="../static/js/ekko-lightbox.min.js"></script>
        <script type="text/javascript" src="../static/js/bootstrap.min.js"></script>
        <script type="text/x-mathjax-config" src="../static/js/mathjax-config.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML"></script>
    </head>
    <body>
            <div class="container">
                <div class="row">
                    <div class="col">
                        <header>
    <span><a href="../">/home/jerin</a> </span>
    <!--
    <span><a href="/archive.html">posts</a></span>,
    <span><a href="/contact.html">contact</a></span>
    -->
</header>

                    </div>
                </div>
                <div class="row">
                    <div class="col">
                        <h1>Force integrated graphics</h1>
                        <div class="row mb-4">
    <div class="post-info col">
        <div>Jun 12, 2023</div>

         

         
            <div><a href="../tags/posts/arch.html">arch</a>, <a href="../tags/posts/linux.html">linux</a>, <a href="../tags/posts/graphics.html">graphics</a></div>
         
    </div>
</div>

<div class="row">
    <div class="col-md-8 col-sm-12"><p>As of now, applications which use graphics tend to use NVIDIA.</p>
<details> <summary> <code>$ nvidia-smi </code> </summary>
<pre>
Mon Jun 12 14:26:03 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 530.41.03              Driver Version: 530.41.03    CUDA Version: 12.1     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 3060         Off| 00000000:01:00.0  On |                  N/A |
|  0%   40C    P8               12W / 170W|   1284MiB / 12288MiB |     11%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      1299      G   /usr/lib/Xorg                               523MiB |
|    0   N/A  N/A      1391      G   /usr/bin/gnome-shell                        108MiB |
|    0   N/A  N/A      1592      G   /usr/bin/gnome-software                      20MiB |
|    0   N/A  N/A      1817      G   /usr/lib/xdg-desktop-portal-gnome            69MiB |
|    0   N/A  N/A      2794      G   /usr/bin/kitty                                3MiB |
|    0   N/A  N/A      8396    C+G   ...4175876,13528862819532032333,262144      552MiB |
+---------------------------------------------------------------------------------------+`

</pre>
<p></details></p>
<p>I was thinking of a use-case to always allocate the GPU VRAM to Machine Learning models. This should be possible, but weird. Given recent uptick in deep-learning queries on the internet, someone or the other should have run into the same problem.</p>
<p>On looking for an adaptation of <a href="https://gist.github.com/wangruohui/bc7b9f424e3d5deb0c0b8bba990b1bc5">an ubuntu script</a> for <a href="../posts/buildapc.html">the newly installed ArchLinux</a>, I received the following pointers from the <a href="https://app.element.io/#/room/#archlinux:archlinux.org">matrix channel</a>:</p>
<ol style="list-style-type: decimal">
<li><a href="https://aur.archlinux.org/packages/hyprland-nvidia">hyprland-nvidia</a></li>
<li><a href="https://www.reddit.com/r/linux_gaming/comments/vh0f03/possible_to_use_intel_igpu_on_wayland_but_nvidia/">r/linux_gaming/…/possible_to_use_intel_igpu_on_wayland_but_nvidia</a></li>
<li><a href="https://github.com/ewagner12/all-ways-egpu">gh/ewagner12/all-ways-egpu</a></li>
</ol>
<p>I haven’t yet felt the need to do walk this path for now. This post will be updated with the details if I get to execution. For now, this will remain a link stash.</p>
<h2 id="workaround">Workaround</h2>
<p>Coincidental, but relative of mine needed more VRAM space for ML experiments (they’re all the rage it seems, I figure). Between our discussions, the following workaround is nice if you have a second machine and can use the GPU machine as a headless one without display.</p>
<p>It’s possible to reconnect to the motherboard display-port/HDMI to use the integrated graphics, and disable display. This allows NVIDIA driver to work, while display rendering does not use the GPU and the VRAM remains available.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">systemctl</span> disable gdm --now </code></pre></div>
<p>To revert, it’s always possible to use:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">systemctl</span> enable gdm --now </code></pre></div>
<p>Since I still have my ThinkPad X1C, I think I should be able to use the method if it comes to that. The above assumes GNOME is the default. It is the case for me and the person I’m corresponding with.</p></div>
</div>


<div class="row">
    <div class="col">
        <p class="text-muted font-italic"> (Comments disabled. Email me instead.) </p>
    </div>
</div>

                    </div>
                </div>

                <div class="row">
                    <div class="col">
                        
<footer>
    <small>Site generated using <a href="http://jaspervdj.be/hakyll">Hakyll</a></small>
</footer>

                    </div>
                </div>
            </div>
        <script type="text/javascript" src="../static/js/init.js"></script>
    </body>
</html>
]]></summary>
</entry>
<entry>
    <title>Building a PC</title>
    <link href="http://jerinphilip.github.io/posts/pcbuild.html" />
    <id>http://jerinphilip.github.io/posts/pcbuild.html</id>
    <published>2023-06-10T00:00:00Z</published>
    <updated>2023-06-10T00:00:00Z</updated>
    <summary type="html"><![CDATA[<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta property="og:title" content="Building a PC" />
        <meta property="og:url" content="http://jerinphilip.github.io/posts/pcbuild.html" />
        <title>Building a PC</title>
        <link rel="shortcut icon" href="../static/images/favicon.ico" type="image/x-icon">
        <link rel="stylesheet" href="../static/css/hack.css" />
        <link rel="stylesheet" href="../static/css/open-sans.css">
        <link rel="stylesheet" href="../static/css/font-awesome.min.css">
        <link rel="stylesheet" href="../static/css/tether.min.css" />
        <link rel="stylesheet" href="../static/css/bootstrap.min.css" />
        <link rel="stylesheet" href="../static/css/custom.css" />
        <link rel="stylesheet" href="../static/css/kate.css" />
        <link rel="stylesheet" href="../static/css/ekko-lightbox.css" />
        <script type="text/javascript" src="../static/js/jquery.min.js"></script>
        <script type="text/javascript" src="../static/js/tether.min.js"></script>
        <script type="text/javascript" src="../static/js/anchor.min.js"></script>
        <script type="text/javascript" src="../static/js/ekko-lightbox.min.js"></script>
        <script type="text/javascript" src="../static/js/bootstrap.min.js"></script>
        <script type="text/x-mathjax-config" src="../static/js/mathjax-config.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML"></script>
    </head>
    <body>
            <div class="container">
                <div class="row">
                    <div class="col">
                        <header>
    <span><a href="../">/home/jerin</a> </span>
    <!--
    <span><a href="/archive.html">posts</a></span>,
    <span><a href="/contact.html">contact</a></span>
    -->
</header>

                    </div>
                </div>
                <div class="row">
                    <div class="col">
                        <h1>Building a PC</h1>
                        <div class="row mb-4">
    <div class="post-info col">
        <div>Jun 10, 2023</div>

         

         
            <div><a href="../tags/posts/build.html">build</a>, <a href="../tags/posts/hardware.html">hardware</a></div>
         
    </div>
</div>

<div class="row">
    <div class="col-md-8 col-sm-12"><p>I got my first PC sometime in 2004. It had a CRT Monitor, 256MB DDR1 RAM, Pentium IV Processor. I don’t remember how much storage the machine had, but it sure was a mechanical hard-drive. I didn’t even know what a computer was back then, my dad must’ve been a visionary who got me one in my remote corner of the world. This machine was the beginning of the path that led me into programming and computer science.</p>
<p>I’ve been wanting to build my own machine a while, but been procrastinating it for long. Come to think of it, what held me back was the lack of stability over the past few years. I was graduating, moving countries, being on visa. If I had to uproot my life again quickly, the overhead of moving PC components would be an added woe.</p>
<p>2 decades and 3 computers later, I have managed to end up with some time to myself, and some stability back home. Some things were already in place. Last May when I came to India, I purchased and assembled a <a href="https://www.amazon.in/TEKAVO-computer-Computer-Workstation-Reversible/dp/B09B6DQYXH">nice table</a> that could support the build. A basic <a href="https://www.amazon.in/Featherlite-Ergonomic-Adjustable-Support-Armrest/dp/B09DNZPTJ8">featherlite chair</a> was also purchased and kept, and I have an extra from my Bangalore setup.</p>
<p>The first-laptop I got for college is still lying around in my room, waiting for some restoration. The ThinkPad X1C7 I upgraded to is what I’m writing this post from. The laptop is a super-portable machine, but it just wasn’t cutting it for certain heavy compile and some light ML training workloads I want to take on.</p>
<h2 id="build">Build</h2>
<p>The machine I want is something that supports a lot of heavy-compilations and some prototyping on the GPU. As of now, I do not want to do training workloads. For a usable model, this should require heavier GPUs and more power-draw. My short term interests are only to learn GPU/CUDA Programming using the new toy. My experience with compile jobs are <code>make -j</code> likes more workers (CPU cores) and more memory (RAM).</p>
<p>My good-friend Amaljith has been tolerating my chatterbox on a vision to build a PC maxing out every component for years now. Having built a gaming PC for himself already, I consider him an expert in the field, even more so than me. In theory I should know better because of my computer science background and sysadmin work, but I’ve been busy with other stuff. The original build had multiple 4090s planned, but for all the cheap talk I did and how I scaled it down so much, I think he reserves every right to shame for life. Our good-friend Aurobindo also offered help and some inputs.</p>
<p>Once the decision to buy was in-place and use-cases were covered where thought about, components got decided fast. The final list of components are below:</p>
<table>
<thead>
<tr class="header">
<th>Component</th>
<th>Model</th>
<th>Specs</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Processor</td>
<td>AMD Ryzen 9 7950X</td>
<td>4.5GHz, 16 cores x 2 threads</td>
</tr>
<tr class="even">
<td>Motherboard</td>
<td>MSI Pro X670-P Wifi</td>
<td>X670</td>
</tr>
<tr class="odd">
<td>RAM</td>
<td>Crucial CT32G48C40U5</td>
<td>64GB (32GBx2) DDR5 4800MHz</td>
</tr>
<tr class="even">
<td>SSD</td>
<td>Kingston NVME INTERNAL SSD (SNV2S/1000G)</td>
<td>1TB NV2 M.2 2280 PCIE 4.0</td>
</tr>
<tr class="odd">
<td>GPU</td>
<td>INNO3D GeForce RTX 3060</td>
<td>12GB VRAM</td>
</tr>
<tr class="even">
<td>CPU Cabinet</td>
<td>Corsair 4000D Black</td>
<td>Mid-Tower</td>
</tr>
<tr class="odd">
<td>CPU Cooler</td>
<td>Noctua NH-D15S Chromax Black</td>
<td>Air Cooler, Silent</td>
</tr>
<tr class="even">
<td>PSU</td>
<td>EVGA SuperNOVA 1000 GT</td>
<td>1000W 80+ Gold Fully Modular</td>
</tr>
<tr class="odd">
<td>Monitor</td>
<td>Samsung LU32J590UQW</td>
<td>80.1cm (31.5“) UHD 4k QLED</td>
</tr>
<tr class="even">
<td>Keyboard</td>
<td>Anne Pro 2</td>
<td>Bluetooth 60%</td>
</tr>
<tr class="odd">
<td>Mouse</td>
<td>Logitech M185</td>
<td>Wireless</td>
</tr>
</tbody>
</table>
<p>I do not think the build is particulary fancy, I cheaped out on plenty of components. The power-supply is an overkill (1000W), but let’s hope I can sneak in a few more GPUs and other enhancements in the future. This is perhaps far-fetched, but if a mistake, this is not too costly.</p>
<p>I did not purchase a UPS. My home has a UPS Inverter + Battery already installed that powers a whole lot of devices. Back when it was being setup, I made sure the sockets in the intended office room had power delivered via the inverter. After some correspondence with the local technician who maintains the setup and expected power-draw from my machine, we concluded the inverter is enough, no need for an additional UPS.</p>
<h2 id="procurement">Procurement</h2>
<p>Edinburgh spoiled me with 4K screens, so I had already got one when I joined a new job in Bengaluru (sometime in August 2022). The Anne Pro 2 was purchased while in Edinburgh (circa October 2020). Mouse was a random purchase while in Edinburgh, don’t exactly remember when.</p>
<p>I had to buy the rest, and also ensure these got delivered to the middle-of-nowhere. I used <a href="pcpricetracker.in" class="uri">pcpricetracker.in</a> to scout cheapest vendors to procure my required components from. Most of the argmin on price on my requirements came from <a href="https://www.vedantcomputers.com/">Vedant Computers</a>. There were a few that were cheaper on other websites, but in some cases a delivery/credit-card surcharge offset it. In the end I purchased the RAM from <a href="https://www.theitdepot.com/">ITDepot</a>, PSU from <a href="www.pcstudio.in">PCStudio</a>.</p>
<p>I ordered the cabinet first to test delivery. Turns out it was sent via Delhivery and I had <a href="https://twitter.com/jerinphilip_/status/1664470235305459713">troubles getting it in time</a>. I didn’t wait, and went ahead and ordered all remaining components on June 01, 2023 - expecting to assemble as soon as possible. Delhivery held my cabinet package for nearly a week more than the expected time, at which point all components had arrived at the final-delivery hub. I somehow troubled customer care to the point they told me the (wrong) address to the final delivery center, which turned out to be a drive away. After clicking buttons on the delhiver portal I found the hub and picked up 3 packages that had arrived via Delhivery. RAM was shipped via Amazon Shipping, it took another day to arrive.</p>
<p>Around June 08, I had all required components, and was ready to assemble. I made unboxing videos. These were required in case I wanted to return and get a replacement within the stipulated time.</p>
<h2 id="assembly">Assembly</h2>
<p>In the past I have opened up more expensive server-equipment and maintained them - swapped out a few components. I have never before assembled a PC on my own. Given there were fragile components of high value, this endeavour had me worried.</p>
<p>I only watched a few component specific videos. In general, I consume text faster than videos and drawn out assembly videos are painful. I was aware I could mess-up the CPU were I not delicate from browsing forums like <a href="https://www.reddit.com/r/buildapc/">r/buildapc</a> and reading the wiki. I found the text-guides in <a href="reddit.com/r/buildapc/wiki/beginnersguide">Beginners Guide</a> particularly useful.</p>
<p>I had a sense of direction inside my head - put CPU in, plant CPU cooler on top. Insert RAM - I had done this before and is easy. Insert NVME SSD on M.2. This was new, I had to watch a few videos. If I connect this to the Front Panel controls and the power-supply I could boot into BIOS if all worked out. This meant I kept the GPU and a spare RAM aside, in case I fried the components by wrong connections. I also didn’t connect the body fans in the beginning, just the CPU Cooler Fan was connected.</p>
<p>The power-supply had asymmetric tabs on both ends. When they were symmetric - it meant both sides were compatible. This helped my fear of blowing up any parts connecting the wires wrong. It was mentioned somewhere in the forums such a component frying possibility existed.</p>
<p>I found connecting the CPU power-supply socket on the motherboard to the power-supply cables more difficult than expected. Once the motherboard was screwed in to the case, the connector was in a corner I could not reach easily. To get around this, I had to remove the motherboard and insert cable, then put it back in. Given a heavy cooler, this risked bending motherboard, I realized quickly.</p>
<p>Another hiccup along the route was that the power-supply, since it was rated 1000W came with a power-socket male plug (16A). However, all sockets in the room where the machine is intended to be kept is 6A normal plug. Since this is India and <em>jugaad</em> runs in the blood, I went to the local electrical shop and got a 6A to 16A adapter. I think this would be unavailable due to safety rules in western countries I have stayed before.</p>
<p>To kill a few more birds with one stone of a town-visit, I bought small stuff that could improve quality-of-life. These included small zip-lock bags to keep the leftover screws and that sort, one transparent box to keep all of these in, price tag stickers which I will repurpose as labels for screws.</p>
<h2 id="software">Software</h2>
<p>Software is what I’m good at.</p>
<p>There was a plan of doing some mild-gaming on this machine - it’s capable of gaming after all. However, I got fronted with an install driver window when attempting to install Windows 11. After reading a few forums and getting reminders of what kind of a debugging/fixing hell windows was, I decided to chuck Windows ideas and go only Linux.</p>
<p>I proceeded to install my favourite distro - ArchLinux. I have to do some deep-learning work. Ubuntu could’ve been a sensible choice considering support. But I felt confident enough to make do the same stuff with ArchLinux.</p>
<pre>
<span style="font-weight:bold;color:blue;">
               +                OS:</span> Arch Linux x86_64
<span style="font-weight:bold;color:blue;">               #                Hostname:</span> vty
<span style="font-weight:bold;color:blue;">              ###               Kernel Release:</span> 6.3.6-arch1-1
<span style="font-weight:bold;color:blue;">             #####              Uptime:</span> 1 day, 19:53
<span style="font-weight:bold;color:blue;">             ######             WM:</span> None
<span style="font-weight:bold;color:blue;">            ; #####;            DE:</span> GNOME
<span style="font-weight:bold;color:blue;">           +##.#####            Packages:</span> 1108
<span style="font-weight:bold;color:blue;">          +##########           RAM:</span> <span style="color:blue;"></span><span style="font-weight:bold;color:green;">8326 MB</span> / 63450 MB
<span style="font-weight:bold;color:blue;">         ######</span><span style="color:blue;">#####</span><span style="font-weight:bold;color:blue;">##;         Processor Type:</span> AMD Ryzen 9 7950X 16-Core Processor
<span style="font-weight:bold;color:blue;">        ###</span><span style="color:blue;">############</span><span style="font-weight:bold;color:blue;">+        $EDITOR:</span> vim
<span style="font-weight:bold;color:blue;">       #</span><span style="color:blue;">######   #######        </span><span style="font-weight:bold;color:blue;">Root:</span> <span style="color:blue;"></span><span style="font-weight:bold;color:green;">217G</span> / 916G (23%) (ext4)
<span style="color:blue;">     .######;     ;###;`&quot;.      
    .#######;     ;#####.       
    #########.   .########`     
   ######'           '######    
  ;####                 ####;   
  ##'                     '##   
 #'                         `#  
</span>
</pre>
<p>A four-years ago me would’ve went ahead and configured every detail, but I got no time for that much these days. Just installed GNOME on the base system, defaults are nice. I’ll switch to a tiling WM if the workflow necessitates it at some point in the future.</p>
<p>I expected GNOME would come with <code>network-manager</code>, but turned out it did not. So I had to boot into the live-disk again, setup internet, <code>arch-chroot</code> and then install <code>networkmanager</code>. I have made this mistake before, but some things you keep doing again and again.</p>
<p>I encountered a few more issues at configuring the graphics card with the proprietary driver. Turns out <code>wayland</code>, <code>sway</code> etc does not play nice with the proprietary driver. But I need the driver for CUDA programming.</p>
<h2 id="afterthoughts">Afterthoughts</h2>
<p>I see value in adding more RAM. I tried to do <code>make -j</code> on some LLVM source code and the compile OOM-ed out at some point (or so I think). Motherboard supports a maximum of 128GB. I definitely made a bad bet on storage. I am better off with a 2TB SSD, and more SATA HDDs to store lazy stuff like movies, music and that sort. I downloaded a few machine-learning models and datasets and I’m already at some 200GB (see <code>archey3</code> output somewhere above). Good thing about a PC Build is I can add more parts to upgrade. So when I have funds, and if the stay at home sticks I’ll incrementally upgrade the machine.</p>
<p>The old 2004 PC once had a lizard crawl into the power-supply and create a short-circuit. Scared the hell out of me, all the explosions back then. I thought I destroyed the entire computer gaming. The Corsair 4000D’s orifices to allow ventilation allows certain insects, so I slightly worry about possible pest attacks. One of the tradeoff of living in the middle of beautiful lush green.</p>
<p>There’s a looming concern of how much longer I’d be able to play with this new toy. At some point, I’ll have to look out for a job. From the direction the sentiment towards work from home is moving, chances are I will need to move.</p></div>
</div>


<div class="row">
    <div class="col">
        <p class="text-muted font-italic"> (Comments disabled. Email me instead.) </p>
    </div>
</div>

                    </div>
                </div>

                <div class="row">
                    <div class="col">
                        
<footer>
    <small>Site generated using <a href="http://jaspervdj.be/hakyll">Hakyll</a></small>
</footer>

                    </div>
                </div>
            </div>
        <script type="text/javascript" src="../static/js/init.js"></script>
    </body>
</html>
]]></summary>
</entry>
<entry>
    <title>Speeding up builds with ccache</title>
    <link href="http://jerinphilip.github.io/posts/ccache.html" />
    <id>http://jerinphilip.github.io/posts/ccache.html</id>
    <published>2022-03-19T00:00:00Z</published>
    <updated>2022-03-19T00:00:00Z</updated>
    <summary type="html"><![CDATA[<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta property="og:title" content="Speeding up builds with ccache" />
        <meta property="og:url" content="http://jerinphilip.github.io/posts/ccache.html" />
        <title>Speeding up builds with ccache</title>
        <link rel="shortcut icon" href="../static/images/favicon.ico" type="image/x-icon">
        <link rel="stylesheet" href="../static/css/hack.css" />
        <link rel="stylesheet" href="../static/css/open-sans.css">
        <link rel="stylesheet" href="../static/css/font-awesome.min.css">
        <link rel="stylesheet" href="../static/css/tether.min.css" />
        <link rel="stylesheet" href="../static/css/bootstrap.min.css" />
        <link rel="stylesheet" href="../static/css/custom.css" />
        <link rel="stylesheet" href="../static/css/kate.css" />
        <link rel="stylesheet" href="../static/css/ekko-lightbox.css" />
        <script type="text/javascript" src="../static/js/jquery.min.js"></script>
        <script type="text/javascript" src="../static/js/tether.min.js"></script>
        <script type="text/javascript" src="../static/js/anchor.min.js"></script>
        <script type="text/javascript" src="../static/js/ekko-lightbox.min.js"></script>
        <script type="text/javascript" src="../static/js/bootstrap.min.js"></script>
        <script type="text/x-mathjax-config" src="../static/js/mathjax-config.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML"></script>
    </head>
    <body>
            <div class="container">
                <div class="row">
                    <div class="col">
                        <header>
    <span><a href="../">/home/jerin</a> </span>
    <!--
    <span><a href="/archive.html">posts</a></span>,
    <span><a href="/contact.html">contact</a></span>
    -->
</header>

                    </div>
                </div>
                <div class="row">
                    <div class="col">
                        <h1>Speeding up builds with ccache</h1>
                        <div class="row mb-4">
    <div class="post-info col">
        <div>Mar 19, 2022</div>

         

         
            <div><a href="../tags/posts/cpp.html">cpp</a>, <a href="../tags/posts/ci.html">ci</a>, <a href="../tags/posts/github-actions.html">github-actions</a></div>
         
    </div>
</div>

<div class="row">
    <div class="toc col-md-4 col-sm-12 order-md-second"><h6>Outline</h6><ul>
<li><a href="#ccache">ccache</a></li>
<li><a href="#local-builds">Local builds</a></li>
<li><a href="#github-actions">GitHub Actions</a></li>
<li><a href="#outcome">Outcome</a></li>
</ul></div><div class="col-md-8 col-sm-12 post-content order-md-first"><p><a href="https://github.com/marian-nmt/marian-dev">marian-dev</a> has builds which takes &gt; 30mins. When I first tried to build marian-dev to edit something in sentencepiece on my personal laptop, a Lenovo ThinkPad X1 carbon - it took ages. Often I had to remove the built files and run a clean build once again. Sometimes I had to build <code>Release</code>, other times <code>Debug</code>. These days I develop on an 80-core Intel Xeon Phi, so the build times are not as much an issue. But still every now and then some noob tries to build the project on their local machine without the know-hows and often takes very very long to finish.</p>
<p>The same was the case across Windows, Linux and MacOS and cross-compilation targetting WebAssembly via emscripten when I started working for the bergamot-project - all of which had a CI build running. <a href="https://github.com/browsermt/bergamot-translator">bergamot-translator</a> uses a <a href="https://github.com/browsermt/marian-dev">fork</a> of marian-dev and the situation is pretty much the same.</p>
<div class="figure">
<img src="https://imgs.xkcd.com/comics/compiling.png" alt="My code is compiling" />
<p class="caption">My code is compiling</p>
</div>
<p>This was a point of frustration when I started, and over weekends, outside officially assigned tasks I have successfully managed to bring down the time required for each one by one.</p>
<h2 id="ccache">ccache</h2>
<p><a href="https://github.com/ccache/ccache">ccache</a> speeds up compilation by using previous compilations. The principle is quite simple - each compilation unit can be associated with <code>(source-file, compiler, compilation-args)</code>. If we hash all 3 and store the cached result somewhere, we will safely be able to reuse it in future compilations.</p>
<p>ccache, at the time of writing this post, supports most of Linux and gcc/clang, MacOS and AppleClang. It <a href="https://github.com/ccache/ccache/pull/506">recently managed support for MSVC on Windows</a>, although bergamot-translator still uses the fork with a release (We should switch soon, when I have free time). emscripten compiler (<code>emcc</code>) running on any platform <a href="https://github.com/emscripten-core/emscripten/pull/13681">has some form of support</a>. That’s pretty much all our builds - so all that’s left was to slowly add support one-by-one.</p>
<h2 id="local-builds">Local builds</h2>
<p>ccache is quite easy to set up for local builds. Chances are ccache is available in your operating system’s official package manager. The following example works with Ubuntu.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="fu">sudo</span> apt-get install ccache 
$ <span class="fu">cmake</span> <span class="va">$BUILD_DIRECTORY</span>                        \
    -DCMAKE_CXX_COMPILER_LAUNCHER=ccache        \
    -DCMAKE_C_COMPILER_LAUNCHER=ccache          \
    -DCMAKE_CUDA_COMPILER_LAUNCHER=ccache  </code></pre></div>
<p>From there-on, compilation results are going to be cached and we can rely on ccache. Most of my development happens on a Linux system, so I’m sorted. The library, however, is intended to be cross-platform (Windows, Mac, Linux, now Android). Due to Mozilla’s decisions, we also have a WebAssembly target. There’s no way I’m building everything while I local-test unless I am testing parts relevant to the platform. For that, we have GitHub CI.</p>
<h2 id="github-actions">GitHub Actions</h2>
<p>bergamot-translator uses GitHub Actions for CI. Not much documentation for GitHub actions existed when I started using it for bergamot-translator, although I found the integrated offering quite convenient. The repository was originally developed in private, but my setting up CI exhausted the private repository minutes (using the more expensive MacOS Runners) in under two days. The solution was to make the development public - no worries, it was meant to be open-sourced anyway. But we were still using more resources than necessary and adding more items to the matrix would have been difficult.</p>
<p>bergamot-translator compiles with <code>-march=native</code> for some performance reasons. This led to rather fragmented compiler flags as a function of hardware. This is not a problem when I am on my development machine and the hardware remains the same. But GitHub runners, we’ve discovered are not uniform - some have <code>avx512</code> capabilities while others have <code>avx2</code> capabilities.</p>
<p>The general skeleton on optimizing build turnaround time with ccache on GitHub actions is the same across platforms. I use the environment to store a bunch of variables, these extend to <code>$GITHUB_ENV</code>, but I’d want to reuse the variable store in a matrix as well so the structure looks like the following:</p>
<div class="sourceCode"><pre class="sourceCode yaml"><code class="sourceCode yaml"><span class="fu">env:</span>
  <span class="fu">ccache_basedir:</span><span class="at"> ${{ github.workspace }}</span>
  <span class="fu">ccache_dir:</span><span class="at"> </span><span class="st">&quot;${{ github.workspace }}/.ccache&quot;</span>
  <span class="fu">ccache_compilercheck:</span><span class="at"> content</span>
  <span class="fu">ccache_compress:</span><span class="at"> </span><span class="st">'true'</span>
  <span class="fu">ccache_compresslevel:</span><span class="at"> 9</span>
  <span class="fu">ccache_maxsize:</span><span class="at"> 200M</span>
  <span class="fu">ccache_cmake:</span><span class="at"> -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DCMAKE_C_COMPILER_LAUNCHER=ccache</span></code></pre></div>
<p>The place to store <code>$CCACHE_DIR</code> is GitHub and needs to sustain across builds. The following generates variables to sort the lookup by recency on the working PR.</p>
<div class="sourceCode"><pre class="sourceCode yaml"><code class="sourceCode yaml"><span class="kw">-</span> <span class="fu">name:</span><span class="at"> Generate ccache_vars for ccache based on machine</span>
  <span class="fu">shell:</span><span class="at"> bash</span>
  <span class="fu">id:</span><span class="at"> ccache_vars</span>
  <span class="fu">run:</span><span class="at"> |-</span>
    <span class="fu">echo &quot;:</span><span class="at">:set-output name=hash::$(echo ${{ env.ccache_compilercheck }})&quot;</span>
    <span class="fu">echo &quot;:</span><span class="at">:set-output name=timestamp::$(date '+%Y-%m-%dT%H.%M.%S')&quot;</span></code></pre></div>
<p>If the first commit, we may alternatively look into the last built <code>main</code> branch.</p>
<div class="sourceCode"><pre class="sourceCode yaml"><code class="sourceCode yaml"><span class="kw">-</span> <span class="fu">name:</span><span class="at"> Cache-op for build-cache through ccache</span>
  <span class="fu">uses:</span><span class="at"> actions/cache@v2</span>
  <span class="fu">with:</span>
    <span class="fu">path:</span><span class="at"> ${{ env.ccache_dir }}</span>
    <span class="fu">key:</span><span class="at"> ccache-${{ matrix.identifier }}-${{ steps.ccache_vars.outputs.hash }}-${{ github.ref }}-${{ steps.ccache_vars.outputs.timestamp }}</span>
    <span class="fu">restore-keys:</span><span class="at"> |-</span>
      ccache-$<span class="kw">{</span>{ matrix.identifier <span class="kw">}</span>}-$<span class="kw">{</span>{ steps.ccache_vars.outputs.hash <span class="kw">}</span>}-$<span class="kw">{</span>{ github.ref <span class="kw">}</span>}
      ccache-$<span class="kw">{</span>{ matrix.identifier <span class="kw">}</span>}-$<span class="kw">{</span>{ steps.ccache_vars.outputs.hash <span class="kw">}</span>}
      ccache-$<span class="kw">{</span>{ matrix.identifier <span class="kw">}</span>}</code></pre></div>
<p>The following is redundant and over-engineered, but I like to keep things this way for swappability of <code>env.var</code> and <code>matrix.var</code>.</p>
<div class="sourceCode"><pre class="sourceCode yaml"><code class="sourceCode yaml"><span class="kw">-</span> <span class="fu">name:</span><span class="at"> ccache environment setup</span>
  <span class="fu">run:</span><span class="at"> |-</span>
    echo <span class="st">&quot;CCACHE_COMPILER_CHECK=${{ env.ccache_compilercheck }}&quot;</span> &gt;&gt; $GITHUB_ENV
    echo <span class="st">&quot;CCACHE_BASEDIR=${{ env.ccache_basedir }}&quot;</span> &gt;&gt; $GITHUB_ENV
    echo <span class="st">&quot;CCACHE_COMPRESS=${{ env.ccache_compress }}&quot;</span> &gt;&gt; $GITHUB_ENV
    echo <span class="st">&quot;CCACHE_COMPRESSLEVEL=${{ env.ccache_compresslevel }}&quot;</span> &gt;&gt; $GITHUB_ENV
    echo <span class="st">&quot;CCACHE_DIR=${{ env.ccache_dir }}&quot;</span> &gt;&gt; $GITHUB_ENV
    echo <span class="st">&quot;CCACHE_MAXSIZE=${{ env.ccache_maxsize }}&quot;</span> &gt;&gt; $GITHUB_ENV</code></pre></div>
<p>I often leave a prolog and epolog step to diagnose over CI whether the cache is working as intended.</p>
<div class="sourceCode"><pre class="sourceCode yaml"><code class="sourceCode yaml"><span class="kw">-</span> <span class="fu">name:</span><span class="at"> ccache prolog</span>
  <span class="fu">run:</span><span class="at"> |-</span>
    ccache -s <span class="co"># Print current cache stats</span>
    ccache -z <span class="co"># Zero cache entry</span>

<span class="co"># Build commands go here.</span>

<span class="kw">-</span> <span class="fu">name:</span><span class="at"> ccache epilog</span>
  <span class="fu">run:</span><span class="at"> |</span>
    ccache -s <span class="co"># Print current cache stats</span></code></pre></div>
<p>With the above skeleton, turns out it is actually quite easy to set it all up. Ignoring the countless hours spent debugging how a container rolled out in a machine somewhere with feedback turnaround absurd high until the cache started working, of course. Now I get to copy-paste the above and speed up compilations across my projects.</p>
<p><strong>Linux / MacOS</strong> Linux/MacOS both worked quite out of the box with the above setup, and both had the bash shell.</p>
<p><strong>Python</strong> The python shared library via pybind11 used the gcc or clang under Linux to build, so getting this one was as simple as copying over the Linux YAML lines and adding a bunch of python keys.</p>
<p><strong>Android cross-compilation</strong> Android cross-compilation is used as “it builds” check on CI for ARM backend, which I’m pursuing at the time of writing this post. Since CMake has nice integrations as visible above, cross-compiling with a toolchain allowed me to use ccache with minimal changes required.</p>
<p><strong>Windows</strong> Windows was the odd one. Compiling things on Windows with MSVC especially has never been a fun experience. I don’t think much of the developer crowd like this either.</p>
<p>Most of the implementation followed <a href="https://cristianadam.eu/20200113/speeding-up-c-plus-plus-github-actions-using-ccache/">Speeding up C++ GitHub Actions using ccache</a>. It took some time and searching and trial and error to get it to work, and the functionality is integrated now - <a href="https://github.com/browsermt/bergamot-translator/pull/308">bergamot-translator#308</a>. Because <code>bash</code> wasn’t available, <code>cmake</code> was used to generate timestamps and such required.</p>
<div class="sourceCode"><pre class="sourceCode yaml"><code class="sourceCode yaml"><span class="kw">-</span> <span class="fu">name:</span><span class="at"> Download ccache</span>
  <span class="fu">shell:</span><span class="at"> cmake -P {0}</span>
  <span class="fu">run:</span><span class="at"> |</span>
    <span class="fu">set(ccache_url &quot;https:</span><span class="at">//github.com/cristianadam/ccache/releases/download/v${{ env.ccache_version }}/${{ runner.os }}.tar.xz&quot;)</span>
    file(DOWNLOAD <span class="st">&quot;${ccache_url}&quot;</span> ./ccache.tar.xz SHOW_PROGRESS)
    execute_process(COMMAND $<span class="kw">{</span>CMAKE_COMMAND<span class="kw">}</span> -E tar xvf ./ccache.tar.xz)
    if(ret AND NOT ret EQUAL 0)
      message( FATAL_ERROR <span class="st">&quot;Bad exit status&quot;</span>)
    endif()</code></pre></div>
<div class="sourceCode"><pre class="sourceCode yaml"><code class="sourceCode yaml"><span class="kw">-</span> <span class="fu">name:</span><span class="at"> Generate ccache_vars for ccache based on machine</span>
  <span class="fu">shell:</span><span class="at"> cmake -P {0}</span>
  <span class="fu">id:</span><span class="at"> ccache_vars</span>
  <span class="fu">run:</span><span class="at"> |-</span>
    string(TIMESTAMP current_date <span class="st">&quot;%Y-%m-%d-%H;%M;%S&quot;</span> UTC)
    <span class="fu">message(&quot;:</span><span class="at">:set-output name=timestamp::${current_date}&quot;)</span>
    <span class="fu">message(&quot;:</span><span class="at">:set-output name=hash::${{ env.ccache_compilercheck }}&quot;)</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode yaml"><code class="sourceCode yaml"><span class="kw">-</span> <span class="fu">name:</span><span class="at"> ccache prolog</span>
  <span class="fu">run:</span><span class="at"> |-</span>
    $<span class="kw">{</span>{github.workspace<span class="kw">}</span>}\ccache.exe -sv <span class="co"># Print current cache stats</span>
    $<span class="kw">{</span>{github.workspace<span class="kw">}</span>}\ccache.exe -z <span class="co"># Print current cache stats</span>

<span class="co"># Insert build command here.</span>

<span class="kw">-</span> <span class="fu">name:</span><span class="at"> ccache epilog</span>
  <span class="fu">run:</span><span class="at"> |-</span>
    $<span class="kw">{</span>{github.workspace<span class="kw">}</span>}\ccache.exe -sv <span class="co"># Print current cache stats</span></code></pre></div>
<p>Some MSVC flags like <code>/Zi</code> where unfriendly to cache, so had to get rid of that (it was debug information, most likely).</p>
<p>Few dependencies (<code>pcre2</code>, <code>protobuf</code>) comes via <code>vcpkg</code> and are slower than what I’d want at the moment. We will look into speeding this up eventually.</p>
<p><strong>emscripten</strong> The emscripten ccache mostly referred to <a href="https://github.com/pyodide/pyodide/pull/1805">pyiodide implementation</a>. Weird flex, but <code>emcc</code> uses <code>ccache</code> compiled onto WebAssembly target and then uses it further in compilation. Since WebAssembly is intended to be a portable target - I made a choice the ccache builds cached.</p>
<p><strong>Further optimizations</strong> Originally marian-dev provided builds with debug info (<code>-DCMAKE_BUILD_TYPE=RelWithDebInfo</code>), which was inherited by bergamot-translator. This meant the compiled units had information on which lines which instructions correspond to and the information increases the size on the disk. Larger object files meant longer to compile and also getting into trouble with GitHub’s free limits.</p>
<h2 id="outcome">Outcome</h2>
<p>Compilation turnaround times we reduced as follows (in minutes):</p>
<ol style="list-style-type: decimal">
<li>Linux: 25m ➔ 5m</li>
<li>MacOS: 30m ➔ 6m</li>
<li>WebAssembly: 15m ➔ 5m (2m if optimized further)</li>
<li>Python: 30m ➔ 6m</li>
<li>Windows: 30m ➔ 10m (depending on <code>vcpkg</code> being nice).</li>
</ol>
<div class="figure">
<img src="https://imgs.xkcd.com/comics/the_general_problem.png" alt="It has indeed saved time in the long run." />
<p class="caption">It has indeed saved time in the long run.</p>
</div>
<p>Good enough to be picked up by downstream repositories as well, turns out: <a href="https://github.com/XapaJIaMnu/translateLocally/commit/a4e3e3b40e1baf955198763e99480b62495cde16">XapaJIaMnu/translateLocally@a4e3e3b</a>.</p>
<p>While this has served to reduce the compute footprint, turnaround time for developers, the ability gained by ccache has also encouraged me to add more builds - most certainly an instance of <a href="https://en.wikipedia.org/wiki/Jevons_paradox">Jevons Paradox</a>.</p>
<p>Cache Invalidation is a potential problem. If at some point in the future some bug corrupts a cache entry, builds can fail. The assumption is that this does not happen often, even if it does, we can just edit a flag to recache and then the builds will go back to work.</p>
<p>Functional ccache builds for all these can be found in <a href="https://github.com/browsermt/bergamot-translator">browsermt/bergamot-translator</a>.</p></div>
</div>


<div class="row">
    <div class="col">
        <p class="text-muted font-italic"> (Comments disabled. Email me instead.) </p>
    </div>
</div>

                    </div>
                </div>

                <div class="row">
                    <div class="col">
                        
<footer>
    <small>Site generated using <a href="http://jaspervdj.be/hakyll">Hakyll</a></small>
</footer>

                    </div>
                </div>
            </div>
        <script type="text/javascript" src="../static/js/init.js"></script>
    </body>
</html>
]]></summary>
</entry>
<entry>
    <title>Lemonade IME</title>
    <link href="http://jerinphilip.github.io/posts/lemonade.html" />
    <id>http://jerinphilip.github.io/posts/lemonade.html</id>
    <published>2022-03-12T00:00:00Z</published>
    <updated>2022-03-12T00:00:00Z</updated>
    <summary type="html"><![CDATA[<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta property="og:title" content="Lemonade IME" />
        <meta property="og:url" content="http://jerinphilip.github.io/posts/lemonade.html" />
        <title>Lemonade IME</title>
        <link rel="shortcut icon" href="../static/images/favicon.ico" type="image/x-icon">
        <link rel="stylesheet" href="../static/css/hack.css" />
        <link rel="stylesheet" href="../static/css/open-sans.css">
        <link rel="stylesheet" href="../static/css/font-awesome.min.css">
        <link rel="stylesheet" href="../static/css/tether.min.css" />
        <link rel="stylesheet" href="../static/css/bootstrap.min.css" />
        <link rel="stylesheet" href="../static/css/custom.css" />
        <link rel="stylesheet" href="../static/css/kate.css" />
        <link rel="stylesheet" href="../static/css/ekko-lightbox.css" />
        <script type="text/javascript" src="../static/js/jquery.min.js"></script>
        <script type="text/javascript" src="../static/js/tether.min.js"></script>
        <script type="text/javascript" src="../static/js/anchor.min.js"></script>
        <script type="text/javascript" src="../static/js/ekko-lightbox.min.js"></script>
        <script type="text/javascript" src="../static/js/bootstrap.min.js"></script>
        <script type="text/x-mathjax-config" src="../static/js/mathjax-config.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML"></script>
    </head>
    <body>
            <div class="container">
                <div class="row">
                    <div class="col">
                        <header>
    <span><a href="../">/home/jerin</a> </span>
    <!--
    <span><a href="/archive.html">posts</a></span>,
    <span><a href="/contact.html">contact</a></span>
    -->
</header>

                    </div>
                </div>
                <div class="row">
                    <div class="col">
                        <h1>Lemonade IME</h1>
                        <div class="row mb-4">
    <div class="post-info col">
        <div>Mar 12, 2022</div>

         

         
            <div><a href="../tags/posts/mt.html">mt</a>, <a href="../tags/posts/ui.html">ui</a>, <a href="../tags/posts/linux.html">linux</a>, <a href="../tags/posts/ime.html">ime</a>, <a href="../tags/posts/cpp.html">cpp</a>, <a href="../tags/posts/bergamot.html">bergamot</a></div>
         
    </div>
</div>

<div class="row">
    <div class="toc col-md-4 col-sm-12 order-md-second"><h6>Outline</h6><ul>
<li><a href="#lemonade-ime">Lemonade IME</a><ul>
<li><a href="#verifiying-machine-generated-translations">Verifiying machine-generated translations</a></li>
<li><a href="#screencasts">Screencasts</a></li>
</ul></li>
<li><a href="#what-next">What next?</a><ul>
<li><a href="#uiux">UI/UX</a></li>
<li><a href="#development">Development</a></li>
</ul></li>
<li><a href="#references">References</a></li>
</ul></div><div class="col-md-8 col-sm-12 post-content order-md-first"><p><small> This post is an account of the implementation of an Input Method Engine (IME) for translation through Intelligent Input Bus (iBus) - a software available on modern Linux desktop environments. </small></p>
<p>Most of my work in the last years have been in the vicinity of building a library for on-device machine translation. In one exchange over GitHub, I was tasked with implementing the underlying library requirements for <em><a href="https://docs.google.com/presentation/d/15ah2n58GfbP8B97nUrfl9HdKSP3Vh71-W6vZNr37eOk/">Outbound Translation</a></em> . In essence, it refers to the concept of user enter in a source language which the user knows and a software layer intercepts it to provide the target language content.</p>
<p>This problem immediately resonated with me. At some point during my internship at NAVER LABS Europe when I stayed in France, I had to contact La Poste customer care. Calling them up was out of the question - because my processing power for French audio over phone was worse. Somehow I managed to find this accessibility chat interface where I could “chat” with customer support, using text. What bothered me as a user was that the medium is French and I’m sitting with multiple tabs of Google Translate manually copying and translating content I receive, then translating the content I want to send out from English to French.</p>
<p>I have been typing my mother tongue - <em>Malayalam</em>, which uses a non-Latin alphabet and has a script of it’s own using an English (US) keyboard since high school. The technology which enabled me to do this at the time was <a href="https://swanalekha.smc.org.in/">Swanalekha</a>. Learning the <a href="https://en.wikipedia.org/wiki/InScript_keyboard">InScript Keyboard</a> looked like a hard effort, and just typing out weird combinations of the alphabet to create the intended alphabet in Malayalam felt like an easier thing to learn. The technology is enabled by iBus - which one can find today in modern Linux based operating systems with <a href="https://help.gnome.org/misc/release-notes/3.6/i18n-ibus.html.en">tight integration to the GNOME Desktop</a> - and enjoys widespread use in inputting non-Latin script by means of a Latin keyboard layout (e.g: English (US)) while providing software layers for non-Latin keyboards.</p>
<p>In a 1:1 with <a href="https://kheafield.com/">Kenneth Heafield</a>, I bring up the idea of the alternative of the entire outbound translation concept from browser-only to system-wide using the Intelligent Input Bus (iBus). While the know-hows of connecting iBus to the library was not straightforward, the possibility of the solution using both was acknowledged. However, Bergamot Project was more focused on attempting cross-platform and in the browser (on operating systems more than linux), so a pitch for a keyboard layer in the operating system (Linux specific) turned out to be a downside.</p>
<p>My counterparties at Mozilla collosally delayed the extension’s implementation of Outbound translation, leaving me plenty idle time - some of which could be redirected towards this idea. Since the tools were decided, the solution was not all that complicated. Lemonade iwould implemented in C++ as an engine that implements the <a href="https://ibus.github.io/docs/ibus-1.5/index.html">iBus interface</a>, that connects to the <a href="https://github.com/browsermt/bergamot-translator">bergamot-translator</a> C++ library. Together with the ecosystem (models, fast-nmt engine) built by the Bergamot project, lemonade manages to run the translations completely locally, providing the privacy benefits intended to be achieved by the Bergamot Project. For purposes of building an IME, I found <a href="https://github.com/epico/ibus-libzhuyin">ibus-libzhuyin</a> which I could modify and connect to the Bergamot C++ library to reach a minimum viable product. Non traditional applications like <a href="https://mike-fabian.github.io/ibus-typing-booster/">ibus-typing-booster</a> - further improved my confidence in using iBus.</p>
<h2 id="lemonade-ime">Lemonade IME</h2>
<p>The user interacts with iBus through two elements - (1) a panel available system-wide and (2) an input UI in the vicinity of the text area the user intends to input the translated text.</p>
<p><strong>Panel</strong> The panel, often available in the top-right corner for GNOME allows to choose from available input methods.</p>
<div class="figure">
<img src="../static/images/bergamot/lemonade-activated-dropdown.png">
<p class="caption">
Lemonade as an iBus engine
</p>
</div>
<p>It also allows the user to switch source language, target language and allows to configure a verify option. For now, <code>xx-&gt;xx</code> is configured to be a passthrough.</p>
<div class="figure">
<img src="../static/images/bergamot/lemonade-source-lang-selection.png" width="45%"> <img src="../static/images/bergamot/lemonade-target-lang-selection.png" width="45%">
<p class="caption">
Language selection
</p>
</div>
<p><strong>Input UI</strong> The input UI inverts the traditional usage. The existing implementation shows translation as pre-edit text, which is underlined text that is almost entered into the target text area. A commit action by the user inserts the pre-edit text into the text area. The candidate list is used to show the text that is entered in by the user before committing.</p>
<div class="figure">
<img src="../static/images/bergamot/libreoffice-without-verify.png" width="100%">
<p class="caption">
Using Lemonade IME in LibreOffice
</p>
</div>
<p>While we only have <code>xx-&gt;en</code> and <code>en-&gt;yy</code> models internally, pivoting feature allows for entering <code>xx-&gt;yy</code> by using the models involving English in sequence.</p>
<h3 id="verifiying-machine-generated-translations">Verifiying machine-generated translations</h3>
<p>Okay, now that the user is potentially trusting a machine-learning system to intercept and translate the content being put in. <em>Lost in translation</em> is a thing, sometimes with dangerous consequences - <a href="https://www.theguardian.com/technology/2017/oct/24/facebook-palestine-israel-translates-good-morning-attack-them-arrest">including getting detained</a>. How does one boost the users’ confidence in the translated text?</p>
<p><span class="citation">Zouhar et al. (<a href="#ref-zouhar2021backtranslation">2021</a>)</span> studied this as part of the Bergamot Project and came up with the UI recommendation of providing the backtranslated content additionally to the user. In this setting, we take the translated text and try to translate it back to the source language, which the user understands. If the backtranslated text match, we can be more confident that the text sent in is correct.</p>
<div class="figure">
<img src="../static/images/bergamot/lemonade-verify-backtranslation.png" alt="UI controls for verify" />
<p class="caption">UI controls for verify</p>
</div>
<!--
<div class="figure">
<img src="/static/images/bergamot/libreoffice-with-verify.png" width=100%>
<p class="caption">LibreOffice with verification</p>
</div>

<div class="figure">
<img src="/static/images/bergamot/deutche-post-form-firefox.png"  width=100%>
<p class="caption"></p>
</div>
-->
<h3 id="screencasts">Screencasts</h3>
<p>In the below screencast, I use lemonade (system-level) for outbound translation in conjunction with a local-translation browser extension - <a href="https://github.com/jelmervdl/firefox-translations">jelmervdl/firefox-translations</a>.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/JMY4ANSAKPU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write;
encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<p>Lemonade also works on other applications, pretty much any text-area by intercepting the keyboard and input method. See different controls being configured on a word-processor.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Lsmpx_A_7Y8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write;
encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<h2 id="what-next">What next?</h2>
<p>I am grateful to Kenneth and the UI group in Bergamot to have received attention and feedback for what is a hobby horse side-project. Feedback I have received so-far notes that this is particularly useful in a chat setting, but limited when richer editing requirements are involved.</p>
<h3 id="uiux">UI/UX</h3>
<p>Since I managed a few interactions with the UI (Research) team, a lot of the problems highlighted I perceived to be quite hard.</p>
<p><strong>UI Limitations</strong> The inability to control the UI elements (primarily because of my lack of understanding of iBus) impede complex UI mechanisms. For example, once the pre-edit text is committed, there is no way to backtrack it to the original source text that the user input. This was deemed to be useful when we want complex editing workflows that are quite common on the web. This is however a constraint due to sticking to the iBus specified interface. I am keeping keeping open a <a href="https://github.com/jerinphilip/lemonade/issues/56">web-based</a> input method to gain more development capabilities.</p>
<p><strong>Flickering</strong> There is an increased instability in the text during translations. This is a necessary evil, as translations are not monotonic in nature and larger contexts lead to drastically different word orderings in the translated text. The modified translation is perhaps more suitable than an incremental one. This is a problem shared by interactive translation research and some speech-translation which requires stability as transcribed speech translations progress.</p>
<p><strong>Edit workflows</strong> Queries often arose about being able to edit/verify at word levels rather than the sentence levels after an initial draft translation was committed in. Word level editing appears to be quite hard, especially when the signals we have during inference are faint.</p>
<div class="figure">
<img src="https://imgs.xkcd.com/comics/tasks.png" alt="xkcd: Tasks" />
<p class="caption">xkcd: Tasks</p>
</div>
<h3 id="development">Development</h3>
<p>In the current setting, the implementation uses hardcoded file paths and is reliant on the bergamot python package to fetch and inventory the models. A better position is to eventually connect to <a href="https://github.com/XapaJIaMnu/translateLocally">translateLocally</a>. translateLocally’s vision is perhaps as a cross-platform GUI application - and I’m trying to convince the authors to separate out the application library out so lemonade can pick it up. The pursuit of a <a href="https://developer.mozilla.org/en-US/docs/Mozilla/Add-ons/WebExtensions/Native_messaging">Native Messaging</a> extension in translateLocally brings the features closer to the requirement of lemonade.</p>
<p>This could also be done using the Python Interface iBus allows for, but at the time Python package for bergamot was not very mature.</p>
<p>Lemonade source currently sits in <a href="https://github.com/jerinphilip/lemonade">jerinphilip/lemonade</a> under a permissive license. It has a lot of rough edges, which are expected to be smoothened over free time. If you’d like to help out with development, please feel free to drop by the GitHub issues/discussions or even contact me via email.</p>
<h2 id="references" class="unnumbered">References</h2>
<div id="refs" class="references">
<div id="ref-zouhar2021backtranslation">
<p>Vilém Zouhar, Michal Novák, Matúš Žilinec, Ondřej Bojar, Mateo Obregón, Robin L. Hill, Frédéric Blain, Marina Fomicheva, Lucia Specia, and Lisa Yankovskaya. 2021. Backtranslation feedback improves user confidence in MT, not quality. In <em>Proceedings of the 2021 conference of the north american chapter of the association for computational linguistics: Human language technologies</em>, pages 151–161, Online, June. Association for Computational Linguistics.</p>
</div>
</div></div>
</div>


<div class="row">
    <div class="col">
        <p class="text-muted font-italic"> (Comments disabled. Email me instead.) </p>
    </div>
</div>

                    </div>
                </div>

                <div class="row">
                    <div class="col">
                        
<footer>
    <small>Site generated using <a href="http://jaspervdj.be/hakyll">Hakyll</a></small>
</footer>

                    </div>
                </div>
            </div>
        <script type="text/javascript" src="../static/js/init.js"></script>
    </body>
</html>
]]></summary>
</entry>

</feed>
