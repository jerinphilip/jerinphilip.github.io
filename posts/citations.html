<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>Jerin Philip</title>
        <link href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,600,600i,700,700i,800" rel="stylesheet">
        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
        <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hack-font@3/build/web/hack.css">
        <link rel="stylesheet" href="../static/css/tether.min.css" />
        <link rel="stylesheet" href="../static/css/bootstrap.min.css" />
        <link rel="stylesheet" href="../static/css/custom.css" />
        <link rel="stylesheet" href="../static/css/kate.css" />
        <link rel="stylesheet" href="../static/css/ekko-lightbox.css" />
        <script type="text/javascript" src="../static/js/jquery.min.js"></script>
        <script type="text/javascript" src="../static/js/tether.min.js"></script>
        <script type="text/javascript" src="../static/js/anchor.min.js"></script>
        <script type="text/javascript" src="../static/js/ekko-lightbox.min.js"></script>
        <script type="text/javascript" src="../static/js/bootstrap.min.js"></script>
        <script type="text/x-mathjax-config" src="../static/js/mathjax-config.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML"></script>
    </head>
    <body>
            <div class="container">
                <div class="row">
                    <div class="col">
                        <header>
    <span><a href="../">/home/jerin</a> </span>
    <!--
    <span><a href="/archive.html">posts</a></span>,
    <span><a href="/contact.html">contact</a></span>
    -->
</header>

                    </div>
                </div>
                <div class="row">
                    <div class="col">
                        <h1>Citations Test</h1>
                        <div class="row">
    <div class="toc col-md-4 col-sm-12 push-md-8"><h6>Outline</h6></div><div class="col-md-8 col-sm-12 post-content"><p>In this document, we’ll test a newly added citations feature, with a global <code>.bib</code> file.</p>
<ul>
<li><code>@sennrich2015neural</code> - <span class="citation">Sennrich et al. (<a href="#ref-sennrich2015neural">2015</a>)</span><br />
</li>
<li><code>@neubig2018rapid</code> - <span class="citation">Neubig and Hu (<a href="#ref-neubig2018rapid">2018</a>)</span><br />
</li>
<li><code>@vaswani2017attention</code> - <span class="citation">Vaswani et al. (<a href="#ref-vaswani2017attention">2017</a>)</span><br />
</li>
<li><code>@jain2019attention</code> - <span class="citation">Jain and Wallace (<a href="#ref-jain2019attention">2019</a>)</span><br />
</li>
<li><code>@white1994arpa</code> - <span class="citation">White (<a href="#ref-white1994arpa">1994</a>)</span><br />
</li>
<li><code>@edunov2018understanding</code> - <span class="citation">Edunov et al. (<a href="#ref-edunov2018understanding">2018</a>)</span><br />
</li>
<li><code>@johnson2017google</code> - <span class="citation">Johnson et al. (<a href="#ref-johnson2017google">2017</a>)</span><br />
</li>
<li><code>@sennrich2016improving</code> - <span class="citation">Sennrich et al. (<a href="#ref-sennrich2016improving">2016</a>)</span><br />
</li>
<li><code>@googletranslate</code> - <span class="citation">Google ( )</span><br />
</li>
<li><code>@bingtranslator</code> - <span class="citation">Microsoft ( )</span><br />
</li>
<li><code>@jha2010tdil</code> - <span class="citation">Jha (<a href="#ref-jha2010tdil">2010</a>)</span><br />
</li>
<li><code>@kunchukuttan2018iit</code> - <span class="citation">Kunchukuttan et al. (<a href="#ref-kunchukuttan2018iit">2018</a>)</span><br />
</li>
<li><code>@zoph2016transfer</code> - <span class="citation">Zoph et al. (<a href="#ref-zoph2016transfer">2016</a>)</span><br />
</li>
<li><code>@petsiuk2018rise</code> - <span class="citation">Petsiuk et al. (<a href="#ref-petsiuk2018rise">2018</a>)</span><br />
</li>
<li><code>@aljundi2018selfless</code> - <span class="citation">Aljundi et al. (<a href="#ref-aljundi2018selfless">2018</a>)</span><br />
</li>
<li><code>@sutskever2014sequence</code> - <span class="citation">Sutskever et al. (<a href="#ref-sutskever2014sequence">2014</a>)</span><br />
</li>
<li><code>@bahdanau2014neural</code> - <span class="citation">Bahdanau et al. (<a href="#ref-bahdanau2014neural">2014</a>)</span><br />
</li>
<li><code>@luong2015effective</code> - <span class="citation">Luong et al. (<a href="#ref-luong2015effective">2015</a>)</span><br />
</li>
<li><code>@gehring2017convolutional</code> - <span class="citation">Gehring et al. (<a href="#ref-gehring2017convolutional">2017</a>)</span><br />
</li>
<li><code>@wangenglish</code> - <span class="citation">Wang et al. ( )</span><br />
</li>
<li><code>@philip2018cvitmt</code> - <span class="citation">Philip et al. (<a href="#ref-philip2018cvitmt">2018</a>)</span><br />
</li>
<li><code>@Kunchukuttan2014ShataAnuvadakTM</code> - <span class="citation">Kunchukuttan et al. (<a href="#ref-Kunchukuttan2014ShataAnuvadakTM">2014</a>)</span></li>
<li><code>@he2016dual</code> - <span class="citation">He et al. (<a href="#ref-he2016dual">2016</a>)</span><br />
</li>
<li><code>@garje2013survey</code> - <span class="citation">Garje and Kharate (<a href="#ref-garje2013survey">2013</a>)</span><br />
</li>
<li><code>@khan2017machine</code> - <span class="citation">Khan et al. (<a href="#ref-khan2017machine">2017</a>)</span><br />
</li>
<li><code>@pathak2019case</code> - <span class="citation">Pathak et al. (<a href="#ref-pathak2019case">2019</a>)</span><br />
</li>
<li><code>@samparktdil</code> - <span class="citation">TDIL-Sampark ( )</span><br />
</li>
<li><code>@nakazawa2018overview</code> - <span class="citation">Nakazawa et al. (<a href="#ref-nakazawa2018overview">2018</a>)</span><br />
</li>
<li><code>@post2018call</code> - <span class="citation">Post (<a href="#ref-post2018call">2018</a>)</span><br />
</li>
<li><code>@aharoni2019massively</code> - <span class="citation">Aharoni et al. (<a href="#ref-aharoni2019massively">2019</a>)</span><br />
</li>
<li><code>@sennrich2011iterative</code> - <span class="citation">Sennrich and Volk (<a href="#ref-sennrich2011iterative">2011</a>)</span><br />
</li>
<li><code>@papineni2002bleu</code> - <span class="citation">Papineni et al. (<a href="#ref-papineni2002bleu">2002</a>)</span><br />
</li>
<li><code>@banerjee2018multi</code> - <span class="citation">Banerjee et al. (<a href="#ref-banerjee2018multi">2018</a>)</span><br />
</li>
<li><code>@sen2018iitp</code> - <span class="citation">Sen et al. (<a href="#ref-sen2018iitp">2018</a>)</span><br />
</li>
<li><code>@chaudhury2010anusaaraka</code> - <span class="citation">Chaudhury et al. (<a href="#ref-chaudhury2010anusaaraka">2010</a>)</span><br />
</li>
<li><code>@sinha1995anglabharti</code> - <span class="citation">Sinha et al. (<a href="#ref-sinha1995anglabharti">1995</a>)</span><br />
</li>
<li><code>@sinhal2014pure</code> - <span class="citation">Sinhal and Gupta (<a href="#ref-sinhal2014pure">2014</a>)</span><br />
</li>
<li><code>@wikipediastats</code> - <span class="citation">Wikipedia ( )</span><br />
</li>
<li><code>@kudo2018subword</code> - <span class="citation">Kudo (<a href="#ref-kudo2018subword">2018</a>)</span></li>
</ul>
<div id="refs" class="references">
<div id="ref-aharoni2019massively">
<p>Roee Aharoni, Melvin Johnson, and Orhan Firat. 2019. Massively multilingual neural machine translation. <em>arXiv preprint arXiv:1903.00089</em>.</p>
</div>
<div id="ref-aljundi2018selfless">
<p>Rahaf Aljundi, Marcus Rohrbach, and Tinne Tuytelaars. 2018. Selfless sequential learning. <em>arXiv preprint arXiv:1806.05421</em>.</p>
</div>
<div id="ref-bahdanau2014neural">
<p>Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. Neural machine translation by jointly learning to align and translate. <em>arXiv preprint arXiv:1409.0473</em>.</p>
</div>
<div id="ref-banerjee2018multi">
<p>Tamali Banerjee, Anoop Kunchukuttan, and Pushpak Bhattacharyya. 2018. Multilingual indian language translation system at wat 2018: Many-to-one phrase-based smt. In December.</p>
</div>
<div id="ref-chaudhury2010anusaaraka">
<p>Sriram Chaudhury, Ankitha Rao, and Dipti M Sharma. 2010. Anusaaraka: An expert system based machine translation system. In <em>Proceedings of the 6th international conference on natural language processing and knowledge engineering (nlpke-2010)</em>, pages 1–6. IEEE.</p>
</div>
<div id="ref-edunov2018understanding">
<p>Sergey Edunov, Myle Ott, Michael Auli, and David Grangier. 2018. Understanding Back-Translation at Scale. In <em>Proceedings of the 2018 conference on empirical methods in natural language processing</em>, pages 489–500.</p>
</div>
<div id="ref-garje2013survey">
<p>GV Garje and GK Kharate. 2013. Survey of machine translation systems in india.</p>
</div>
<div id="ref-gehring2017convolutional">
<p>Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N Dauphin. 2017. Convolutional sequence to sequence learning. In <em>Proceedings of the 34th international conference on machine learning-volume 70</em>, pages 1243–1252. JMLR. org.</p>
</div>
<div id="ref-googletranslate">
<p>Google. Google Translate.</p>
</div>
<div id="ref-he2016dual">
<p>Di He, Yingce Xia, Tao Qin, Liwei Wang, Nenghai Yu, Tie-Yan Liu, and Wei-Ying Ma. 2016. Dual learning for machine translation. In <em>Advances in neural information processing systems</em>, pages 820–828.</p>
</div>
<div id="ref-jain2019attention">
<p>Sarthak Jain and Byron C. Wallace. 2019. Attention is not explanation.</p>
</div>
<div id="ref-jha2010tdil">
<p>Girish Nath Jha. 2010. The TDIL Program and the Indian Language Corpora Intitiative (ILCI). In <em>LREC</em>.</p>
</div>
<div id="ref-johnson2017google">
<p>Melvin Johnson, Mike Schuster, Quoc V Le, Maxim Krikun, Yonghui Wu, Zhifeng Chen, Nikhil Thorat, Fernanda Viégas, Martin Wattenberg, Greg Corrado, and others. 2017. Google’s multilingual neural machine translation system: Enabling zero-shot translation. <em>Transactions of the Association for Computational Linguistics</em>, 5:339–351.</p>
</div>
<div id="ref-khan2017machine">
<p>Nadeem Jadoon Khan, Waqas Anwar, and Nadir Durrani. 2017. Machine translation approaches and survey for indian languages. <em>arXiv preprint arXiv:1701.04290</em>.</p>
</div>
<div id="ref-kudo2018subword">
<p>Taku Kudo. 2018. Subword regularization: Improving neural network translation models with multiple subword candidates. In <em>Proceedings of the 56th annual meeting of the association for computational linguistics (volume 1: Long papers)</em>, volume 1, pages 66–75.</p>
</div>
<div id="ref-kunchukuttan2018iit">
<p>Anoop Kunchukuttan, Pratik Mehta, and Pushpak Bhattacharyya. 2018. The IIT Bombay English-Hindi Parallel Corpus. In <em>Proceedings of the eleventh international conference on language resources and evaluation (lrec-2018)</em>.</p>
</div>
<div id="ref-Kunchukuttan2014ShataAnuvadakTM">
<p>Anoop Kunchukuttan, Abhijit Mishra, Rajen Chatterjee, Ritesh M. Shah, and Pushpak Bhattacharyya. 2014. Shata-anuvadak: Tackling multiway translation of indian languages. In <em>LREC</em>.</p>
</div>
<div id="ref-luong2015effective">
<p>Minh-Thang Luong, Hieu Pham, and Christopher D Manning. 2015. Effective approaches to attention-based neural machine translation. <em>arXiv preprint arXiv:1508.04025</em>.</p>
</div>
<div id="ref-bingtranslator">
<p>Microsoft. Bing Translator.</p>
</div>
<div id="ref-nakazawa2018overview">
<p>Toshiaki Nakazawa, Katsuhito Sudoh, Shohei Higashiyama, Chenchen Ding, Raj Dabre, Hideya Mino, Isao Goto, Win Pa Pa, Anoop Kunchukuttan, and Sadao Kurohashi. 2018. Overview of the 5th workshop on asian translation. In <em>Proceedings of the 5th workshop on asian translation (wat2018)</em>.</p>
</div>
<div id="ref-neubig2018rapid">
<p>Graham Neubig and Junjie Hu. 2018. Rapid adaptation of neural machine translation to new languages. In <em>Proceedings of the 2018 conference on empirical methods in natural language processing</em>, pages 875–880.</p>
</div>
<div id="ref-papineni2002bleu">
<p>Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. BLEU: A method for automatic evaluation of machine translation. In <em>Proceedings of the 40th annual meeting on association for computational linguistics</em>, pages 311–318. Association for Computational Linguistics.</p>
</div>
<div id="ref-pathak2019case">
<p>Aditya Kumar Pathak, Priyankit Acharya, and Rakesh Chandra Balabantaray. 2019. A case study of hindi–english example-based machine translation. In <em>Innovations in soft computing and information technology</em>, pages 7–16. Springer, editions.</p>
</div>
<div id="ref-petsiuk2018rise">
<p>Vitali Petsiuk, Abir Das, and Kate Saenko. 2018. RISE: Randomized input sampling for explanation of black-box models. <em>arXiv preprint arXiv:1806.07421</em>.</p>
</div>
<div id="ref-philip2018cvitmt">
<p>Jerin Philip, Vinay P. Namboodiri, and C. V. Jawahar. 2018. CVIT-MT Systems for WAT-2018. In <em>5th Workshop on Asian Translation (WAT2018)</em>.</p>
</div>
<div id="ref-post2018call">
<p>Matt Post. 2018. A call for clarity in reporting bleu scores. In <em>Proceedings of the third conference on machine translation: Research papers</em>, pages 186–191.</p>
</div>
<div id="ref-sen2018iitp">
<p>Sukanta Sen, Kamal Kumar Gupta, Asif Ekbal, and Pushpak Bhattacharyya. 2018. IITP-mt at wat2018: Transformer-based multilingual indic-english neural machine translation system. In <em>Proceedings of the 5th workshop on asian translation (wat2018)</em>.</p>
</div>
<div id="ref-sennrich2011iterative">
<p>Rico Sennrich and Martin Volk. 2011. Iterative, mt-based sentence alignment of parallel texts. In <em>Proceedings of the 18th nordic conference of computational linguistics (nodalida 2011)</em>, pages 175–182.</p>
</div>
<div id="ref-sennrich2015neural">
<p>Rico Sennrich, Barry Haddow, and Alexandra Birch. 2015. Neural machine translation of rare words with subword units. <em>arXiv preprint arXiv:1508.07909</em>.</p>
</div>
<div id="ref-sennrich2016improving">
<p>Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016. Improving neural machine translation models with monolingual data. In <em>Proceedings of the 54th annual meeting of the association for computational linguistics (volume 1: Long papers)</em>, volume 1, pages 86–96.</p>
</div>
<div id="ref-sinha1995anglabharti">
<p>RMK Sinha, K Sivaraman, Aditi Agrawal, Renu Jain, Rakesh Srivastava, and Ajai Jain. 1995. ANGLABHARTI: A multilingual machine aided translation project on translation from english to indian languages. In <em>1995 ieee international conference on systems, man and cybernetics. intelligent systems for the 21st century</em>, volume 2, pages 1609–1614. IEEE.</p>
</div>
<div id="ref-sinhal2014pure">
<p>Ruchika A Sinhal and Kapil O Gupta. 2014. A pure ebmt approach for english to hindi sentence translation system. <em>International Journal of Modern Education and Computer Science</em>, 6(7):1.</p>
</div>
<div id="ref-sutskever2014sequence">
<p>Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014. Sequence to sequence learning with neural networks. In <em>Advances in neural information processing systems</em>, pages 3104–3112.</p>
</div>
<div id="ref-samparktdil">
<p>TDIL-Sampark. Sampark Translation System.</p>
</div>
<div id="ref-vaswani2017attention">
<p>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In <em>Advances in neural information processing systems</em>, pages 5998–6008.</p>
</div>
<div id="ref-wangenglish">
<p>Rui Wang, Chenchen Ding, Masao Utiyama, and Eiichiro Sumita. English-myanmar nmt and smt with pre-ordering: NICT’s machine translation systems at wat-2018.</p>
</div>
<div id="ref-white1994arpa">
<p>John White. 1994. The ARPA MT evaluation methodologies: evolution, lessons, and future approaches. In </p>
</div>
<div id="ref-wikipediastats">
<p>Wikipedia. Wikipedia Statistics V2.</p>
</div>
<div id="ref-zoph2016transfer">
<p>Barret Zoph, Deniz Yuret, Jonathan May, and Kevin Knight. 2016. Transfer learning for low-resource neural machine translation. In <em>Proceedings of the 2016 conference on empirical methods in natural language processing</em>, pages 1568–1575.</p>
</div>
</div></div>
</div>
<div class="row">
    <div class="post-info col">
        2019-05-23
        
        by Jerin Philip
        
    </div>
</div>

                    </div>
                </div>

                <div class="row">
                    <div class="col">
                        
<footer>
    <small>Site generated using <a href="http://jaspervdj.be/hakyll">Hakyll</a></small>
</footer>

                    </div>
                </div>
            </div>
        <script type="text/javascript" src="../static/js/init.js"></script>
    </body>
</html>
